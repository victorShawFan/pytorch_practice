{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1769c146",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# hand-written d2l BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132720eb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a25201",
   "metadata": {
    "hidden": true
   },
   "source": [
    "注意力就是利用query与key-value对搜索的方式来决定权重，注意力分数是query和key的相似度，注意力权重是分数的softmax结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e02903",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Attention的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "251cdff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:56:05.578245Z",
     "start_time": "2021-08-30T03:56:05.555242Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n",
    "                  cmap='Reds'):\n",
    "    d2l.use_svg_display()\n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    fig, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize,\n",
    "                                 sharex=True, sharey=True, squeeze=False)\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "399ddad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:56:11.436803Z",
     "start_time": "2021-08-30T03:56:11.156779Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"156.35625pt\" version=\"1.1\" viewBox=\"0 0 193.35825 156.35625\" width=\"193.35825pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-08-30T11:56:11.378798</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M -0 156.35625 \r\n",
       "L 193.35825 156.35625 \r\n",
       "L 193.35825 0 \r\n",
       "L -0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 34.240625 118.8 \r\n",
       "L 145.840625 118.8 \r\n",
       "L 145.840625 7.2 \r\n",
       "L 34.240625 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#p84342d81d7)\">\r\n",
       "    <image height=\"112\" id=\"image75bdf99e2e\" transform=\"scale(1 -1)translate(0 -112)\" width=\"112\" x=\"34.240625\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAYAAADG4PRLAAABc0lEQVR4nO3dsW3CUBhGURPRJSNkPxgpA2YAGmqnpfRDMnnXnFO7sHT1N58s+bTeb+vCVK6f35uf/djxPXgBAeMEjBMwTsA4AeMEjBMwTsA4AePO//0C72JkHvu5/25+1gXGCRgnYJyAcQLGCRgnYJyAcQLGCRhnSnvSyDS2LGPz2AgXGCdgnIBxAsYJGCdgnIBxAsYJGCdgnIBxttAHe336tycXGCdgnIBxAsYJGCdgnIBxAsYJGCdg3OGntOI8NsIFxgkYJ2CcgHECxgkYJ2CcgHECxgkYl5zSjj6PjXCBcQLGCRgnYJyAcQLGCRgnYJyAcQLGTTOlmcee4wLjBIwTME7AOAHjBIwTME7AOAHjBIzbbUqb5b8KR+cC4wSMEzBOwDgB4wSMEzBOwDgB4wSMEzBuaAv16d98XGCcgHECxgkYJ2CcgHECxgkYJ2CcgHGny/K1bn3YPDYfFxgnYJyAcQLGCRgnYJyAcQLGCRgnYNwfkEghRAiKZdAAAAAASUVORK5CYII=\" y=\"-6.8\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m74c44ca7e4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.820625\" xlink:href=\"#m74c44ca7e4\" y=\"118.8\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(36.639375 133.398438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.620625\" xlink:href=\"#m74c44ca7e4\" y=\"118.8\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(92.439375 133.398438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_3\">\r\n",
       "     <!-- Keys -->\r\n",
       "     <g transform=\"translate(78.371094 147.076563)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 628 4666 \r\n",
       "L 1259 4666 \r\n",
       "L 1259 2694 \r\n",
       "L 3353 4666 \r\n",
       "L 4166 4666 \r\n",
       "L 1850 2491 \r\n",
       "L 4331 0 \r\n",
       "L 3500 0 \r\n",
       "L 1259 2247 \r\n",
       "L 1259 0 \r\n",
       "L 628 0 \r\n",
       "L 628 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-4b\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3597 1894 \r\n",
       "L 3597 1613 \r\n",
       "L 953 1613 \r\n",
       "Q 991 1019 1311 708 \r\n",
       "Q 1631 397 2203 397 \r\n",
       "Q 2534 397 2845 478 \r\n",
       "Q 3156 559 3463 722 \r\n",
       "L 3463 178 \r\n",
       "Q 3153 47 2828 -22 \r\n",
       "Q 2503 -91 2169 -91 \r\n",
       "Q 1331 -91 842 396 \r\n",
       "Q 353 884 353 1716 \r\n",
       "Q 353 2575 817 3079 \r\n",
       "Q 1281 3584 2069 3584 \r\n",
       "Q 2775 3584 3186 3129 \r\n",
       "Q 3597 2675 3597 1894 \r\n",
       "z\r\n",
       "M 3022 2063 \r\n",
       "Q 3016 2534 2758 2815 \r\n",
       "Q 2500 3097 2075 3097 \r\n",
       "Q 1594 3097 1305 2825 \r\n",
       "Q 1016 2553 972 2059 \r\n",
       "L 3022 2063 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2059 -325 \r\n",
       "Q 1816 -950 1584 -1140 \r\n",
       "Q 1353 -1331 966 -1331 \r\n",
       "L 506 -1331 \r\n",
       "L 506 -850 \r\n",
       "L 844 -850 \r\n",
       "Q 1081 -850 1212 -737 \r\n",
       "Q 1344 -625 1503 -206 \r\n",
       "L 1606 56 \r\n",
       "L 191 3500 \r\n",
       "L 800 3500 \r\n",
       "L 1894 763 \r\n",
       "L 2988 3500 \r\n",
       "L 3597 3500 \r\n",
       "L 2059 -325 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2834 3397 \r\n",
       "L 2834 2853 \r\n",
       "Q 2591 2978 2328 3040 \r\n",
       "Q 2066 3103 1784 3103 \r\n",
       "Q 1356 3103 1142 2972 \r\n",
       "Q 928 2841 928 2578 \r\n",
       "Q 928 2378 1081 2264 \r\n",
       "Q 1234 2150 1697 2047 \r\n",
       "L 1894 2003 \r\n",
       "Q 2506 1872 2764 1633 \r\n",
       "Q 3022 1394 3022 966 \r\n",
       "Q 3022 478 2636 193 \r\n",
       "Q 2250 -91 1575 -91 \r\n",
       "Q 1294 -91 989 -36 \r\n",
       "Q 684 19 347 128 \r\n",
       "L 347 722 \r\n",
       "Q 666 556 975 473 \r\n",
       "Q 1284 391 1588 391 \r\n",
       "Q 1994 391 2212 530 \r\n",
       "Q 2431 669 2431 922 \r\n",
       "Q 2431 1156 2273 1281 \r\n",
       "Q 2116 1406 1581 1522 \r\n",
       "L 1381 1569 \r\n",
       "Q 847 1681 609 1914 \r\n",
       "Q 372 2147 372 2553 \r\n",
       "Q 372 3047 722 3315 \r\n",
       "Q 1072 3584 1716 3584 \r\n",
       "Q 2034 3584 2315 3537 \r\n",
       "Q 2597 3491 2834 3397 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-4b\"/>\r\n",
       "      <use x=\"60.576172\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"122.099609\" xlink:href=\"#DejaVuSans-79\"/>\r\n",
       "      <use x=\"181.279297\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m1640b60437\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m1640b60437\" y=\"12.78\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(20.878125 16.579219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m1640b60437\" y=\"35.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 2 -->\r\n",
       "      <g transform=\"translate(20.878125 38.899219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m1640b60437\" y=\"57.42\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 4 -->\r\n",
       "      <g transform=\"translate(20.878125 61.219219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2419 4116 \r\n",
       "L 825 1625 \r\n",
       "L 2419 1625 \r\n",
       "L 2419 4116 \r\n",
       "z\r\n",
       "M 2253 4666 \r\n",
       "L 3047 4666 \r\n",
       "L 3047 1625 \r\n",
       "L 3713 1625 \r\n",
       "L 3713 1100 \r\n",
       "L 3047 1100 \r\n",
       "L 3047 0 \r\n",
       "L 2419 0 \r\n",
       "L 2419 1100 \r\n",
       "L 313 1100 \r\n",
       "L 313 1709 \r\n",
       "L 2253 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m1640b60437\" y=\"79.74\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 6 -->\r\n",
       "      <g transform=\"translate(20.878125 83.539219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2113 2584 \r\n",
       "Q 1688 2584 1439 2293 \r\n",
       "Q 1191 2003 1191 1497 \r\n",
       "Q 1191 994 1439 701 \r\n",
       "Q 1688 409 2113 409 \r\n",
       "Q 2538 409 2786 701 \r\n",
       "Q 3034 994 3034 1497 \r\n",
       "Q 3034 2003 2786 2293 \r\n",
       "Q 2538 2584 2113 2584 \r\n",
       "z\r\n",
       "M 3366 4563 \r\n",
       "L 3366 3988 \r\n",
       "Q 3128 4100 2886 4159 \r\n",
       "Q 2644 4219 2406 4219 \r\n",
       "Q 1781 4219 1451 3797 \r\n",
       "Q 1122 3375 1075 2522 \r\n",
       "Q 1259 2794 1537 2939 \r\n",
       "Q 1816 3084 2150 3084 \r\n",
       "Q 2853 3084 3261 2657 \r\n",
       "Q 3669 2231 3669 1497 \r\n",
       "Q 3669 778 3244 343 \r\n",
       "Q 2819 -91 2113 -91 \r\n",
       "Q 1303 -91 875 529 \r\n",
       "Q 447 1150 447 2328 \r\n",
       "Q 447 3434 972 4092 \r\n",
       "Q 1497 4750 2381 4750 \r\n",
       "Q 2619 4750 2861 4703 \r\n",
       "Q 3103 4656 3366 4563 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m1640b60437\" y=\"102.06\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 8 -->\r\n",
       "      <g transform=\"translate(20.878125 105.859219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 2216 \r\n",
       "Q 1584 2216 1326 1975 \r\n",
       "Q 1069 1734 1069 1313 \r\n",
       "Q 1069 891 1326 650 \r\n",
       "Q 1584 409 2034 409 \r\n",
       "Q 2484 409 2743 651 \r\n",
       "Q 3003 894 3003 1313 \r\n",
       "Q 3003 1734 2745 1975 \r\n",
       "Q 2488 2216 2034 2216 \r\n",
       "z\r\n",
       "M 1403 2484 \r\n",
       "Q 997 2584 770 2862 \r\n",
       "Q 544 3141 544 3541 \r\n",
       "Q 544 4100 942 4425 \r\n",
       "Q 1341 4750 2034 4750 \r\n",
       "Q 2731 4750 3128 4425 \r\n",
       "Q 3525 4100 3525 3541 \r\n",
       "Q 3525 3141 3298 2862 \r\n",
       "Q 3072 2584 2669 2484 \r\n",
       "Q 3125 2378 3379 2068 \r\n",
       "Q 3634 1759 3634 1313 \r\n",
       "Q 3634 634 3220 271 \r\n",
       "Q 2806 -91 2034 -91 \r\n",
       "Q 1263 -91 848 271 \r\n",
       "Q 434 634 434 1313 \r\n",
       "Q 434 1759 690 2068 \r\n",
       "Q 947 2378 1403 2484 \r\n",
       "z\r\n",
       "M 1172 3481 \r\n",
       "Q 1172 3119 1398 2916 \r\n",
       "Q 1625 2713 2034 2713 \r\n",
       "Q 2441 2713 2670 2916 \r\n",
       "Q 2900 3119 2900 3481 \r\n",
       "Q 2900 3844 2670 4047 \r\n",
       "Q 2441 4250 2034 4250 \r\n",
       "Q 1625 4250 1398 4047 \r\n",
       "Q 1172 3844 1172 3481 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_9\">\r\n",
       "     <!-- Queries -->\r\n",
       "     <g transform=\"translate(14.798437 82.307031)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 2522 4238 \r\n",
       "Q 1834 4238 1429 3725 \r\n",
       "Q 1025 3213 1025 2328 \r\n",
       "Q 1025 1447 1429 934 \r\n",
       "Q 1834 422 2522 422 \r\n",
       "Q 3209 422 3611 934 \r\n",
       "Q 4013 1447 4013 2328 \r\n",
       "Q 4013 3213 3611 3725 \r\n",
       "Q 3209 4238 2522 4238 \r\n",
       "z\r\n",
       "M 3406 84 \r\n",
       "L 4238 -825 \r\n",
       "L 3475 -825 \r\n",
       "L 2784 -78 \r\n",
       "Q 2681 -84 2626 -87 \r\n",
       "Q 2572 -91 2522 -91 \r\n",
       "Q 1538 -91 948 567 \r\n",
       "Q 359 1225 359 2328 \r\n",
       "Q 359 3434 948 4092 \r\n",
       "Q 1538 4750 2522 4750 \r\n",
       "Q 3503 4750 4090 4092 \r\n",
       "Q 4678 3434 4678 2328 \r\n",
       "Q 4678 1516 4351 937 \r\n",
       "Q 4025 359 3406 84 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 544 1381 \r\n",
       "L 544 3500 \r\n",
       "L 1119 3500 \r\n",
       "L 1119 1403 \r\n",
       "Q 1119 906 1312 657 \r\n",
       "Q 1506 409 1894 409 \r\n",
       "Q 2359 409 2629 706 \r\n",
       "Q 2900 1003 2900 1516 \r\n",
       "L 2900 3500 \r\n",
       "L 3475 3500 \r\n",
       "L 3475 0 \r\n",
       "L 2900 0 \r\n",
       "L 2900 538 \r\n",
       "Q 2691 219 2414 64 \r\n",
       "Q 2138 -91 1772 -91 \r\n",
       "Q 1169 -91 856 284 \r\n",
       "Q 544 659 544 1381 \r\n",
       "z\r\n",
       "M 1991 3584 \r\n",
       "L 1991 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2631 2963 \r\n",
       "Q 2534 3019 2420 3045 \r\n",
       "Q 2306 3072 2169 3072 \r\n",
       "Q 1681 3072 1420 2755 \r\n",
       "Q 1159 2438 1159 1844 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1341 3275 1631 3429 \r\n",
       "Q 1922 3584 2338 3584 \r\n",
       "Q 2397 3584 2469 3576 \r\n",
       "Q 2541 3569 2628 3553 \r\n",
       "L 2631 2963 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 3500 \r\n",
       "L 1178 3500 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 3500 \r\n",
       "z\r\n",
       "M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 4134 \r\n",
       "L 603 4134 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-75\"/>\r\n",
       "      <use x=\"142.089844\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"203.613281\" xlink:href=\"#DejaVuSans-72\"/>\r\n",
       "      <use x=\"244.726562\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"272.509766\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"334.033203\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 34.240625 118.8 \r\n",
       "L 34.240625 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 145.840625 118.8 \r\n",
       "L 145.840625 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 34.240625 118.8 \r\n",
       "L 145.840625 118.8 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 34.240625 7.2 \r\n",
       "L 145.840625 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_2\">\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path d=\"M 152.815625 103.77 \r\n",
       "L 156.892625 103.77 \r\n",
       "L 156.892625 22.23 \r\n",
       "L 152.815625 22.23 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path clip-path=\"url(#p7509101002)\" d=\"M 152.815625 103.77 \r\n",
       "L 152.815625 103.451484 \r\n",
       "L 152.815625 22.548516 \r\n",
       "L 152.815625 22.23 \r\n",
       "L 156.892625 22.23 \r\n",
       "L 156.892625 22.548516 \r\n",
       "L 156.892625 103.451484 \r\n",
       "L 156.892625 103.77 \r\n",
       "L 156.892625 103.77 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n",
       "   </g>\r\n",
       "   <image height=\"81\" id=\"imagefed83718d4\" transform=\"scale(1 -1)translate(0 -81)\" width=\"4\" x=\"153\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAAQAAABRCAYAAAD1sgc6AAAAnklEQVR4nJ2Suw7CQAwEjZT//1QqCnR+0XKzJxmSLqPx7krJo1/Ptq/nsgzbQRVBDqBH4wCkhTtkWDhqR8OSIHjii6H/Z2jtaLD2EDpm3DCkNvldftgB0GJIqM/TBfAfE+AAJcaSpZJRg1Fs0QyCjN5BRA0gkycEmTyRFhox7simsb/blSbGDWCDcdgB4MxwGu8CWAJ4shgqJ9IiBms/jwXJt9gA8G4AAAAASUVORK5CYII=\" y=\"-22\"/>\r\n",
       "   <g id=\"matplotlib.axis_3\"/>\r\n",
       "   <g id=\"matplotlib.axis_4\">\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 3.5 0 \r\n",
       "\" id=\"mee4424f7c4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mee4424f7c4\" y=\"103.77\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 0.00 -->\r\n",
       "      <g transform=\"translate(163.892625 107.569219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 684 794 \r\n",
       "L 1344 794 \r\n",
       "L 1344 0 \r\n",
       "L 684 0 \r\n",
       "L 684 794 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_7\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mee4424f7c4\" y=\"83.385\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 0.25 -->\r\n",
       "      <g transform=\"translate(163.892625 87.184219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_8\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mee4424f7c4\" y=\"63\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 0.50 -->\r\n",
       "      <g transform=\"translate(163.892625 66.799219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_9\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mee4424f7c4\" y=\"42.615\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- 0.75 -->\r\n",
       "      <g transform=\"translate(163.892625 46.414219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 525 4666 \r\n",
       "L 3525 4666 \r\n",
       "L 3525 4397 \r\n",
       "L 1831 0 \r\n",
       "L 1172 0 \r\n",
       "L 2766 4134 \r\n",
       "L 525 4134 \r\n",
       "L 525 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-37\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_10\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mee4424f7c4\" y=\"22.23\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_14\">\r\n",
       "      <!-- 1.00 -->\r\n",
       "      <g transform=\"translate(163.892625 26.029219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"LineCollection_1\"/>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path d=\"M 152.815625 103.77 \r\n",
       "L 152.815625 103.451484 \r\n",
       "L 152.815625 22.548516 \r\n",
       "L 152.815625 22.23 \r\n",
       "L 156.892625 22.23 \r\n",
       "L 156.892625 22.548516 \r\n",
       "L 156.892625 103.451484 \r\n",
       "L 156.892625 103.77 \r\n",
       "z\r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p84342d81d7\">\r\n",
       "   <rect height=\"111.6\" width=\"111.6\" x=\"34.240625\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p7509101002\">\r\n",
       "   <rect height=\"81.54\" width=\"4.077\" x=\"152.815625\" y=\"22.23\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 180x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 我们使用一个简单的例子进行演示。在本例子中，仅当查询和键相同时，注意力权重为1，否则为0。\n",
    "attention_weights = torch.eye(10).reshape((1, 1, 10, 10))\n",
    "show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb962c38",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### masked softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8df10fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:10:05.227953Z",
     "start_time": "2021-08-29T16:10:01.085643Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667af112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:10:05.275957Z",
     "start_time": "2021-08-29T16:10:05.262957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 遮蔽softmax操作：填充的东西不去算softmax，后面填充的无效位置\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上遮蔽元素来执行 softmax 操作\"\"\"\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03dbc704",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:10:07.466119Z",
     "start_time": "2021-08-29T16:10:07.436118Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4095, 0.5905, 0.0000, 0.0000],\n",
      "         [0.4538, 0.5462, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2160, 0.5174, 0.2666, 0.0000],\n",
      "         [0.3727, 0.3274, 0.2999, 0.0000]]])\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.4149, 0.2577, 0.3274, 0.0000]],\n",
      "\n",
      "        [[0.7058, 0.2942, 0.0000, 0.0000],\n",
      "         [0.2516, 0.3179, 0.1826, 0.2480]]])\n"
     ]
    }
   ],
   "source": [
    "# how masked_softmax work\n",
    "print(masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3])))\n",
    "\n",
    "print(masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fe3ac",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Additive Attention"
   ]
  },
  {
   "attachments": {
    "image-4.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/YAAAF7CAYAAAB4qRB7AAAgAElEQVR4AezdB5Q0RfU2cP2bc84RzJgjKoKKCQMCKqKYMSsKYs6KCTEhiphAVMSAKJjFnLNiThhQURRzzv2dX3vufvU2M7MzG97dWZ46p7dnZ7orPHWr+j733qo+TZcUBIJAEAgCQSAIBIEgEASCQBAIAkEgCMwtAqeZ25qn4kEgCASBIBAEgkAQCAJBIAgEgSAQBIJAF2IfIQgCQSAIBIEgEASCQBAIAkEgCASBIDDHCITYz3HnpepBIAgEgSAQBIJAEAgCQSAIBIEgEARC7CMDQSAIBIEgEASCQBAIAkEgCASBIBAE5hiBEPs57rxUPQgEgSAQBIJAEAgCQSAIBIEgEASCQIh9ZCAIBIEgEASCQBAIAkEgCASBIBAEgsAcIxBiP8edl6oHgSAQBIJAEAgCQSAIBIEgEASCQBAIsY8MBIEgEASCQBAIAkEgCASBIBAEgkAQmGMEQuznuPNS9SAQBIJAEAgCQSAIBIEgEASCQBAIAiH2kYEgEASCQBAIAkEgCASBIBAEgkAQCAJzjECI/Rx3XqoeBIJAEAgCQSAIBIEgEASCQBAIAkEgxD4yEASCQBAIAkEgCASBIBAEgkAQCAJBYI4RCLGf485L1YNAEAgCQSAIBIEgEASCQBAIAkEgCITYRwaCQBAIAkEgCASBIBAEgkAQCAJBIAjMMQIh9nPceal6EAgCQSAIBIEgEASCQBAIAkEgCASBEPvIQBAIAkEgCASBIBAEgkAQCAJBIAgEgTlGIMR+jjsvVQ8CQSAIBIEgEASCQBAIAkEgCASBIBBiHxkIAkEgCASBIBAEgkAQCAJBIAgEgSAwxwiE2M9x56XqQSAIBIEgEASCQBAIAkEgCASBIBAEQuwjA0EgCASBIBAEgkAQCAJBIAgEgSAQBOYYgRD7Oe68VD0IBIEgEASCQBAIAkEgCASBIBAEgkCIfWQgCASBIBAEgkAQCAJBIAgEgSAQBILAHCMQYj/HnZeqB4EgEASCQBAIAkEgCASBIBAEgkAQCLGPDASBIBAEgkAQCAJBIAgEgSAQBIJAEJhjBELs57jzUvUgEASCQBAIAkEgCASBIBAEgkAQCAIh9pGBIBAEgkAQCAJBIAgEgSAQBIJAEAgCc4xAiP0cd16qHgSCQBAIAkEgCASBIBAEgkAQCAJBIMQ+MhAEgkAQCAJBIAgEgSAQBIJAEAgCQWCOEQixn+POS9WDQBAIAkEgCASBIBAEgkAQCAJBIAiE2EcGgkAQCAJBIAgEgSAQBIJAEAgCQSAIzDECIfZr2Hn//ve/uz//+c+bHH/5y1+6f/3rX6tWq//+97/dX//6103KVIe///3vY8t0T5v8P/yu/X2lP08qa9JvK12P5BcENgIC48aM78f9thHanTYEgSAQBIJAEAgCQWAjIxBiv0a9i9Qfd9xx3QMf+MDubne7W3/c/e537/bee+/uM5/5zIrXqhT23/3ud90+++zT7b777gvHve51r+6ggw4aW6a6Oo4//vju3e9+d3f44Yd3H/7wh7s//OEPY+9ZyR/U/Z///Gf3jW98ozvmmGO6t73tbd0XvvCF3gCymkaQlWxD8goC6wkBhrzvf//73Xve855+TH3xi1/sx3PNE+uprqlLEAgCQSAIBIEgEASCwOIIhNgvjtGqXIGoIqnnOc95utOc5jT9cdrTnrY73/nO1732ta9d8TJLYf/5z3/eXeYyl1koU9lnOtOZepI/qlCE/o9//GN35JFHdte97nW7c53rXN1ZznKW7lKXulT3iEc8ovvVr3416rYV/Y4B4WUve1l3hStcoTvDGc7Q19fnAw44YGKkwYpWIpktikDJ2KIX5oJlIzDEevj/pAJ++9vfdq9+9au7q1zlKt2Zz3zmfkxttdVW3X777deP51nymlROfgsCQSAIBIEgEASCQBDYfAicKog9cvrLX/6y+8lPftIfP/3pTzuH/08++eTNh3ZTEmJ/9NFH90QeoXf83//9X3f+85+/V7qbS1f04y9+8YvuSle6Une6051u4TjrWc/a8dqPSv/5z3+6H/zgB93222/f1089T3/60/efL37xi/eEe9R9K/UdnD7xiU/0pL4MIM7qrx3vf//7V6qoDZ+PvvzTn/60IPsnnHBC5zAOfvazn3WWgSwnyR8pXCoxnHTfpN+WU+d5vLcwHp6naYs++vSnP91tvfXW/Rg2lmruQfTf+ta3dv/4xz+66stp8sw1QSAIBIEgEASCQBAIAmuPwIYn9pTfE088sdt55527G97wht1NbnKT7vrXv3534xvfuD8e8pCH9GvON3dXtB57hL6U6wtd6ELdIYccsmrVQeyveMUrLpB6BHkSsRfqjlhvscUWC15+9XWc4xzn6Pbaa6/u97///aL1RRSkImh1XuxGZPM1r3lNd+5zn7uvM5yK4J/3vOftDj744H6ZwGL5nNp/h7fIC8sobn7zm3fbbrttt80223Q3uMEN+uM2t7lNd9RRRy0ZJvlXH1cm0/ZxXV/3u6/y8119X9edGs/wYKBssfFZqu+mwcV4etOb3tRd9KIXXRhHxpTDd89+9rN7Aw/MK/9p8s01QSAIBIEgEASCQBAIAmuLwIYn9pThd73rXT0JRQgR0tZLJaT8k5/85GbvhZbYI9fq5XzhC194sxD7IufOQuvvec97jsRAPT/2sY/1ofdFqIsIIPaPfOQje8I48uau69fB/+hHP+o++tGP9uvyP/jBD3Yf//jHu1//+tfjbtnke0Tk0EMP7Yl9lVv1EN1w2GGHhdhvgtjof5C0H//4x9097nGPBaNOyQBcLQl5+MMfPrEvR+f8v29tyPj1r3+97+MPfOAD3fve977uc5/7XB8hMOm+9jdj1VKRD33oQ508jj322F721Dsk838E3niEhz0u4AMnHviTTjqphXLsZxtlMu5c5CIXOQWxv8QlLtE997nP7YTqB++xEOaHIBAEgkAQCAJBIAisSwQ2PLG3SdRDH/rQfl12EUJna7WdkdN99913s3fOWhJ769OL1C1G7HnubLK1yy679CH4wvARQUaIy13ucr33bxJ4Nut70pOetGBQgbmoBPsLTJNEDNhM8GpXu9rCEgB5KP/qV796T2qmyefUfk3hePnLX34TQgdLh34V0fLNb35zZqiQwO9973u9jJCNNr+vfe1rU+dXeylUnZx5kZ///OcveKunzmyDXQhjhyVFz3jGM7qzne1sC/2oT9/4xjdOFdnwt7/9rTcIiNbQ5zDWZ2c84xm7613vev3mmOameOw3mAClOUEgCASBIBAEgsCGR2BDE3uKMG/xNa5xjQUluIgHYlgEdYcddtgsm8C10rTWxF7b67CBFk/uqMSLigx86lOf6nbaaafukpe8ZMezZz3uNJvX8czzBBdZU6b7RVFMm3jtjzjiiO6a17xmf6+1/UjIW97yljVZRjFtvdfTdZZLvPjFL+4JXJE5xM44YOQiAww+wrRnDX0nI7z1t771rXuZkr88kcdZiD1P8fOe97wFssnopK9D7P/nrdcvIhqe8IQn9P1VY+qyl71s9/rXv36qfjMnkoW3v/3t3S1ucYvec3+BC1ygX45h006/6c8i9q5PCgJBIAgEgSAQBIJAEFj/CGxoYo88v/nNb+698kgCRRiRKW+X7xBNYanCzTdnWmtir+3Vfrvie9XeqFSKPUUfSUfwP/KRj/Qbrrm+fh93LyKyxx57LIvYy5vH2YaHX/nKV/rD51kJ6Kg6nlq+s0nene50p4V+MA7Ofvaz98swEHyHfQz23HPPmZc26BuvS7NvBZkqY8GsxJ43+ilPeUqI/QShtNGht1FUxJE5bRZiX1nrM/ttfPazn+0sjxHe7zvj2bgKsS+kcg4CQSAIBIEgEASCwHwgsCGJfRG+emc75RfhoAxf+cpX7t8ZX15KhAaxtbaUYlv3rnb3rSWxt5t8eWsZNiYR++XgAEsRE3e4wx0WCOVSPPaT6jDJsDDpvlPTbzyw1rvbNNE4MB7Oec5z9m86IAv6hDzYa2G77bbrvvvd784ED1m2weK1rnWtZRF7O/NbNqN+6qSu8dj//64g65Y83Pve914YT0sl9v8/11Ma55STcdUilM9BIAgEgSAQBIJAEFj/CGxIYg92iukwDB+BFX4qrJt3sryLPIx2Crcef3OltST2jBsMG9q92sQeEYF5GVeUh6zNEoq/ufpko5bzm9/8pg9nR+b1g0OUylOf+tTufve7X/8/WbDOmvfXWwhmMXAZN+9973u7LbfcciF/8jWrx954tYlj1THEflOJ1Cff+MY3ujvf+c4LGMFqKR77ccS9SP243zetUf4LAkEgCASBIBAEgkAQWC8IbEhiTwHmpbQTO4JRRME64r333rsPQb3qVa+68D2yaUO3r371q51do2chNeM6Uh7eB223cId16sh85V3Evl7jVkaG5eyKTxlXprKsS1cu0lVlqqvw2yL2ylxJYl+koDDRB4iI1wsqS18UsX/nO99Zl23WMyxWg7QM265RJQPD/qiQ583RcHVgXNl11137PjAWkHibEVpn/dKXvrQn9Ei9/jnf+c7XPexhD+tsZNfKzaS6kjPvP3dvjbVpiP2wH2zSKLqDrNSxkh776g/1bcfHavaHNhoHxmGVSx6M02H7J2HsN/lYinL7299+AeeW2Pt92jSubN/XMW1ernOPOU07ta/mHt+NK2uW/Be7tsovjKv8WTBZrIz8HgSCQBAIAkEgCASB9YzAhiX2lEskHpGk/Dp77zkyQ/l8wAMesPCb3xGbxzzmMb3CP2uHtYorwvDlL3+5e8UrXtF7H4U281wiLF4Nh9Baq64OXlWF2CsfkUG4ZiX2yArlFXmzgdaDHvSgzmaAW2+9dR9qfZ/73Kd/Jdx3vvOd/rqTTz65D5kuXJQ9KRRf/oiPNbheq+XVgNbZO+xWj6BUggPceV5tpmbdtQ25kDNtE+6tPP3wrGc9q3/tnVff1SHPb3/72z02laczcmC39mHZrm0Vd5gef/zx/XVCw+v4/Oc/39dL/bSn7a+2nPrsGhu5uU/d5OMsnF24+LhU+aqvur3uda/rQ8ttKidMnSzc7W536572tKf165p/9atfLWRV9y58sQIf5Kl/yJk3GOgDcnbWs5619/rqp/e85z39pnlF7P22/fbbL+yOL49h3eDzxz/+scfa5nj6xU7tQvnJlQOx12b9X/1bZ/38gx/8oDei2YNB337pS1/q3vCGN3TXuc51Fuqprhe84AX7zRdL9vSF8siesv/0pz+NRKrqra6uQYhf/epXdw984AO7m93sZn05IkmEtZNFr4+r/nDvODmpfG0yp06Mh/bnIBsnnnhiXxfXkEtGQnPBS17ykoW5QPuU/5CHPKQ78sgjF/aqGNUI+ZhPjD3LI5Txspe9rGuNksaT8eXNE9pQMu8MZ9giuVK1yxg1X6h3ezBs6tdq46g6Db+rvI466qh+/rzjHe/Yt+8mN7lJv6fD4x//+H7OVR48Zslb29UfxtUuhkLtkY9kzJPjt73tbd0+++zT3fKWt+w31lS+6A94mYvUc5ayh+3M/0EgCASBIBAEgkAQWO8IbEhiT4GjDHsdGsXXgWzY0d2ma4iq10MhH/U70kMpRHxnScqixCMC3/rWt7oHP/jB/Tvf5Vd51xlRQWqRfAYGG1d5nZfvHe6ZhdgrGxmxk7hd6quc4VmkgjcDHHjggT3hZGhor5lE7GFF2UdGvevcxoM2XdMOm6W1u57DgRK94447dpe5zGV6wsGLq/wilXVWJiLYHuc617n6e4fkWRsRBr+rgwNOu+++e28kUa56CjlHJOTtNYbqqb7WliNY0jTKPbKA8ApxRnQd6nmpS12q90zLY1RSB4TeruXuLeNJ9W3978ygQw4sSXBfydCofJfynTqSSftM2FVe/dVDv+sTYfjaqb923nnnfizUvgvGifHRGm3aOiBcRx99dL+TumuRb3i3Mq+NytP3+qA9yLwN4BhOGJ7sxg9bMqXv3Of+yoPRQR/Iqw6ygJh/4QtfaKvWf9Z2eJaRjUHNK+Gq/TCovKuc85///N1uu+3Wve997+sNSafItPkCroimepd8XOxiF+vJtXLLsPPEJz6xHwftWKvyfAeTW93qVj0p1RfDJK/jjjuuJ6hbbbVVP57IfhnIKl95msvgVOMJTuT/Nre5zYKRRv7qzvgF/+oT18JeiD/iPGmMlFyRDaT7yU9+ch/9IY+qz/DsN/MPmXOPdk2TXMsQpq+1S31FK4jsUA/zAuMZQ4m2Dsv1P6zqDR4nnXRSf980ZeeaIBAEgkAQCAJBIAjMGwIbktgjSsPQYAqeXcGRVIo3DyEvZimDlH6KOi9cebim7Uz5veMd7+g9aUWgWgW+ynD2PUWXssl7aAlAkV3naYg95ZxyjKx6BZ0yh2XU/y1JoiAzXiC69bvzJGIPA5gVYZafeiIRPLItsYc7Y0Xlr611vbOyfNeW3X6W501vetNecW+xt3xAO/WhfByUfGSf51SCCY/gIYcc0pOUthxkaP/99++vQwgmJb8z7iAhLVFVtlfs8TSPyoNH0DrzbbfddoFkqEP1bdv+yleeCKeNG7VDG1YyFYljAFFmYVIGCmUhO4973OP6OlddrcVnoILnqEQerMNH6Nv+az8rq472e58ZNWySx8MML99V3XyGVd1b/V3X+N53xpDIAlEho5I6eiPGda973V5WKt/CQR4lT75zGEe84QcddNDYtisLrt4MYZ8C+ToQfB5ihhRROeRYflVeXedcbfBbjSN1HZJ7Y9x8xBCnrsh7i9OoPAsvZ9fDCFmvpO68//ZWqGvlaQ4QWTKO2JN5hzqJZuEhR6jJStXJuT63dau6uBYuXlM5LtKi6umsLowNMKp8b3SjG/UGIfMOGTJfwrEtr/3sPr97xaaoEktMkoJAEAgCQSAIBIEgsBER2JDEntL4qEc9ahOFDxHgsZYoqLzCw7WqrqHUI2nTJqReSO0WW2zRl1eKfCnNpWT632e/l3eNsu7wXR2LEXt15y3jyatN6aqMcedSip2VV//X9YsRe8rwox/96F75r3pqg3XawncrIfa8sHZar7xLsa721/ejzhR4RERobZsQe1EA8pCfQ18h+5Y1lAfQWX0YHNo2IljILdzgNynJA/EZygZSYmkH2ZJHmw8CzMPNMKRc7Ri2z/eFQZ19pz8QxOc85zkzyd2kNtRvZFP4OwNWlanfkCNt1FbtQbRakq5ON7jBDXojRuXVnsmDpSYIeuVb52p3tde5vqvzKGJfv7m+PYb51nUwZhQgb8OEXAu7bw137qs6DfOs72FDrhhbhHCbB0YZW+DGKNFiVriKjiAHVc9R5ypPPYwnRoHb3e52fZ+0cqUcxN4eFXXPqPyG39W1+lFIekvsYfXDH/6wu//979+XrQ4O7TbGRB0N5bv9H6lnPCvj3bBs/yvfUZ/lry7aCidGTZ528jkpjSL27vVKxF122WXBYDOqDm3ZVb55gQFlsXIn1Sm/BYEgEASCQBAIAkFgvSKw4Yg9JVSoJu9qKXeUTB4bazUp6hRmJO9FL3pRr9CWYkj5FLpKeV0sVT6IBWWzlNk6y5Mii8TwkCIZl770pRfCjZVFyS2FtwjzNMTeuuS73vWuI8mD8nmzhQYLB0dSEJDW61XtrfO0xL7yoCirO+8mA0MlmFr7TIEWHeAQoq2N7qny1BHZ9lt7CBFHLiyjaNM4Yo98t8Re3/vfu9gRlSpP+Ty3FY7f5j38rA3HHntsH0lR96uvvrN8QlJOJeHerrchoetdW32qDgw+SJs11Xe/+917bIR9u84BFwcyKP9RRLLKmuVcWFjfrR+UpX7ksfXGu044fq3bVhfXCrHnlR+VEOdXvvKV/TISBg99ODRmyAMOZLHtY5+NReHx1ncbb+qnXmSi5MT9lQfiK9TavVWe0HHRJ9bOt4mRhaENnsZUtUdd5GMckht7bBhD5EJ/1Pgj1+rBS+797m1fVzmjiD1slaGOVXdlK1P+2mxMDn93jYN8MSZIVSZDGWLPyw0fOLVy3con/GHkgJFrRarAF1mvJG9RJ9pf+Ch/ErGve8m6tfQlK9pZdZAH3BipkH5zIhlSH7+1ZcHYHiDkXRvHpZbYy0N56qld5qwqH+7wga9D26u86lf3+16kAqOuPkwKAkEgCASBIBAEgsBGQmDDEXvEzLplil4plJQ768GFHSNOPHGlnLfhtK63EVV5ASnB44iW35DIu9zlLr0SWQquM4WTAm99qBB9xFSZ1vcfdthhfcguBdR1FNRSPp0XI/aWCey33349sR6WiUTx4h9++OHdCSec0If28q4i209/+tN7Zbu9pz5PQ+x5qynQ1T6fKe8tsecJQ/qsT+cZs5mfyAmKPGzrXthY4+u1g8PDGudhmC78kGN5wMxRREQf6CP94UA+LMOgxFf7XK+feXEnEQn5CIm3mVrd64w08Xxamywpp868n1W3aqd6MqYIFUY8ySR5g4+28Fbe8IY37PN1rQMmwo4ZbVYiaQsDFxls20Luhq+zQ3SG70aHn93xhYcXttVmMggLnn6RCqJcrNNvy9Em+yzsu+++/QZ6NtGrwz2WbPzyl7/sPvShD/Xyqk4Pf/jDe8NX5SMPpJhBxL3kyUG+yc373//+fl+FwkvfylfUR0v85INY2/sAydWmkhnrtF/1qlf1ZFU/k+vqD5j4fZj0pXq3Hnsypt51RuhFPZAlYfvKtZmdZRe+V5Zy6jB2rfG3DKSVL+UbEzYWVE+EXN6FkbM5g+EIRrBxrQPOIgva8HN56zvLgMw3ym/Hk3rCpvCpuvjfWGd4c33dp3xtsYZe26yLJx/GoevtzcEQoKzCxr2MAMYNo5LUyljh3RL7do6sfIw3hhpyammAaB0HHCwrgFPVVZnyEP3AwJsUBIJAEAgCQSAIBIGNhsCGJPZFQilylD9eI15KymOrsPIMl6eVgkr5Q7BqPfakzkbSeAYp95TH9kBGKLlInFTKcX2maB9zzDH95n4Iaqu0TiL26m5zNpsClnJbCj4ig8Qhc1VOqywjI5TePfbY4xRev0nEXh4MIvArYq/MUcS+L7j5w5iB4BeJcZ9621dA+6dN44j9bW972964Ip9qq3YiFBWxUfiQAaRoFFFr64FYIxx1nzOSy0BR/VhnRgAbF5IZfUh+HDyVz3zmM3vS6VqEsw71Q3qQNV5h18PE/SIsGIIq/7Zes35GXu2Gj3CVrCiD7CC/bRm83AhzSxj1GWMY4kXuxiW/MVjZg6HFzLjzFoAibuPur+/Vl0zwxlY+6o2Qv+AFL+iNIm2d6772zFBgHbX+INOwlZeIGd7w2o+hvcdn7WcMYqjS7hqPsBJVMEyjiH3VWZk2BzQH2QleghHjjjYi7gg6GWllBl7kgYeerIxqK8LMoCFaocpzJjfIrDnJfe2h/DYvdVEvY6FkTx5lKBtH7I0bsi6qpu7TPwg6OWHMM96rvCqTrL/73e9eMLZocxlP4MTgqF3qVfXuM2nW2OtL9zjcr1zj2ThlYHF/m/QPY6aNCdW1DveKJoBVUhAIAkEgCASBIBAENhoCG4bYU+YohkgohZwSSGGlBPLWUoj97joHRZIieq973WsTJZmCbe025do14xJyzltf5VRZFGSvnBt6nUtpla9E0Ud61a1VPCcRe3kecMABvVJLSVWmQx2E63qlXZUz6qzdP/nJT3oiUPc6L0bsEeuVIvbayhhiV/Vp0yzEXrvJAGLdYuSzJQLD9cZtHfQNQrDlllsuYOs+XkEbolVSBizlhbyW4UI/iBThDbVDf10nX0fJns8InvXYwqb1ATlF2OwyPiQqVe40Z2VK5PPlL39537fV10iYnfiHUQEIobX42q0eVR/LCN70pjeNrY/xUTJlA74qx9k4sga+3VxxUv2NxXHEHk7GS5G/Ufn4zYaY1772tReIuXqQtcc+9rGbePZH3U/GeJf1n/7Ul+61iWIR5rpPm0d57GEnIoLsWc6jn6WhHMAEKVWG8UDGfLZnBc9z3dN/aP4gyTzx44h9YQSL9iiZkJXv7a9gjb2yq7/HEfu6x6v2EHjX16HODKOMQvoPTvJXXh3uJ4uiBxiZzDVkw73KFGEk77q+rWt57IvY132MC96mwFBZxoQGpv6jyKGDDz54k/lVvc23+kcfJgWBIBAEgkAQCAJBYCMhsKGIPWXNzuQ8wpRAij0F0quihExTPItkUSApwkJXXVOkhJLt+lq7O1TqdT7lldKJ+NR9zhRl9/J6lYLaKqw+y089na0xnZbYK9OmcoiZOjqqbOSQ4rxYkgcCY9193eu80Yi9HdF5EC2raNtJLiZ569z30pe+tPf41n3IMM8fIt4mJEtIvegM8qPvHTYOFHItwbvkTZ/7vw7971Vt7XplHnMhxPrIdSVDbbmLfa77GHDucY97bNJ+hEg4urLbpBzh2cNwenLFSIUkjUrK0i5lrTWxRx55wnn89YfxQa7LCz6q/u13vOk8y8a0+5B77fcmDf3R9oU2D4k9eYGvvQNEBri+8Kk+8Z2D0YexArElMzWeed7JVF3f1s/ntSD26mtcHHrooX3Iv3YWsYfPfe97335JheukauPwLDrKUgu4mpsd2s1opt/MxcM0itiXMcDbEIytKnd4r9/0kcgd5cBZvRluRFOMMwgM88n/QSAIBIEgEASCQBCYFwQ2DLEHOOWQdw5Baom911BR3Icky/+URxtXUfyKzAnltbHeOM+pcqwvVgZlse6jdArZpjSW0llKeim69b88hPIjA/IoBX+cxx6Z4OlDytsyKa2UV15YeU9K6iBceaMTe8TVkoUddthhoW/0kXXMQpBhOUywQVB5AmFafYooCu8eEg9E/zGPecyC3Og/4cE2ZOOt1Rclb87K9F31v/KQaWvtlaVPyZPN3BihFuvLYf39L88qx0aB7TITZNf/beRBmwey+exnP7snXtV2beIBZ6galdRReQW+KbEAACAASURBVOuB2KuDdebGvv6Dp/4w9hHTxZJ2MLR4hRvy6ahwb5vNtcm1o4i90HLh6sOkX9pD5A2izGhU495ZxIQ9OCTXD9NyiH3lp89m8di7Dynfa6+9FgxYJR/mEYYy8t3KddvW+mz+Nd+VIbPINqItGmjUEplRxF7/ipQadX2Ll/pYRmGTviqLTJjbycm4ub3NI5+DQBAIAkEgCASBIDBPCGwYYk+BPPHEE/u1nBS58sJTnktZLoJV5McZ0bVpVZErZ/fy1A1DlqtjKeb77LPPAqkrRZcHy8Z9iym56lqK7rTEHlnlhS6DRZWpfZRuXkLtWywtldhThgtTJMTn4eZ5w7IZOIZr7N272qH48EdUhVEj89W3PLEUfR7YYULcP/nJT/YRF2U4cebBtTt6m+SPHLVr8bVLiDRyjIDJrz30n/4pEiQPZNQ+AdWX5FbEh5Dy5SREVhg+YlptJyfCnm2UNyohOhVBUvXRfuvTx0U5aIMxtNbE3ngSls07Ty71hTYg2jzj5LDqqr7Do37Tp/apMMYcSCTjUEXvFG7un0Ts1adN/m8Pa/phSh71eRFPsobwj0trQey1VftFc5CHGhswtqGk5T+V2jYOP5N/kSzeZFDtlZf+snP/8E0Y8hxH7M3X5rFJSfmf+MQnFoh91duYEIWiD5KCQBAIAkEgCASBILCRENgwxJ5yzkMjNLpVHBET64f9XsTKuZR7hBgZKwJUZ2HcrdLadrqwXztmU/x56eseHjchopWGym37/7TE3j0S4uUVY8pqD8YEhgv5aeNiiUI8fM82gmHn8VFJ+Qwc80LsYeBA5hBya54LL8q9TcuQqsJVm31GmmoDuSIBvLY8uDzobSI7iKQ1+5U3ouN6ofjIi/D9cQeyiNA7t/Ujt0KT7WS+nIS8I6hFcJ0ZHRAasqutDjLl8BnRsb8AY021ydnGgXb3d90wwRkWa03sGVD0tYgEGFb/GZu8yvoD1osd9qmwk79+RDiNCzvYDzfQ0+blEHt4WwLE2KK+NV8h9t7cMC65b6lr7Eve9dksHnuEnMELiYeJA76w3XXXXU9hJFPOqEO5Nu0jg9Vecum40Y1udArjCQyWQ+zd7+0m+rSViYraGe6BMg7zfB8EgkAQCAJBIAgEgXlBYMMQe0ROGDwyQvGsA9HnfUdOhHy2ByXT/ze/+c0XwmKL1FBcDzzwwJH9aM2xte6uoTS6h4JqvXS7C/goBbe+m4XYu4dSL8y36ldnhM2GWxRn1y2WZiH2VVeREPCj1CtXm31ejx57ODgYbxBO5KOwchaKa60vr7ZrKjFe2EhRn9b1sLWhmtRii9gx4LRLGsgbGXCu+8edXVcY+lzX+Q6xRBqXktSRXCHoNiqrfNWJEQpJ3XPPPfvXg3lFWB361mZqlhEIla77nJFcm6YxZAwTnNcDsTf2RcpYow7Dtg/gO22/uM/95bFH7C1z8bq6Nq0EsUfQ9UkrB5YEWW8+Lq0VsSePlmS0xL6WOZgb2lRzxvDsGuPRay7hXGPA2SvovA1gmJZL7GtpRSsTiD1Zn2Z5xrA++T8IBIEgEASCQBAIAusZgQ1B7CmRFEy7SiMjFMdWuW+JyqjPRVjbexA8XlUezmGyhhrZafOiPArz9ro59ZGGym37/1KIvR3T2zLVVyi/Tb+mTbMSe+SNB3jeiL16U95f+MIXLoTjww5p03e8ltVPiJrwd97zIoLOvOfelc5r2SYGAa+M8yq26o+SObJEFtp8hp9dW9/V/c7uQ06HRLIte7HPPJHeCc/T3ubtc1tulV9nv/s8vMd3PMleBwfTNq0XYi+agHGrXiFX7ax+8L/PRUwnnYvUu4ZRw5ge9sdyiT1DhLcNIMdVFzgj9qJyxqW1IPaiIWxI6jVxVVd4WhtvvwpzQ40j9W7nuPpc7UHsbS4I45I75+tc5zoj3y2/GLFvy60y2vM4Yn+/+90vxL4FKp+DQBAIAkEgCASBDYHAhiD2FG3vBadsFoGhfA6PIWlpry1Fs66hfFrvXDuct72N2FuvTPFXhnsQByGlNtoqAlSK7ajztMReue6n1D/pSU/ahHipM2I/bkO0ts71eSnE3nvK21D8Iknr0WPfYo2QC6NGSqpfnRH4NrxaGLq1zZY11HW8tXaoZzBC5OVbyf/Ck4febffqE57YpRxCs695zWt23/zmN6uomc7qiGiJRKl2tOfheGj/d13JcnuPzzYQ5Gkd7k2wnol9EXOyql1F2Kc9G9vk4fa3v31v9Gn7fyWIvb0nRI+oj7qSG8uGXvGKV4zt85Uk9tO+xx6xN7caQ7A0LuDJcETO2jcmtGNv+FmjyKYNJ6u9Neci9qOWn4TYjxWF/BAEgkAQCAJBIAgEgVMgsCGIPeUT8aB4FkFpScs0n0vJLFLjf6TZ68+GCbG3cVopue5xvVB8yijCM1Rsh/8j9rygwr3Vz/3qP2pXfPnxSj73uc/tr2vriHQhCfKfJs1K7JGYE044oVfiKeTKVk+fFyP26rwWm+e1WNg923vlSzbUHyl54hOf2IeRu/bXv/51H5aOZBW2+p63n2wN+w6xF+7Ou17XV77C2+3p4N3csxzyq/sQuKWkWg9tnX/JfFu/pX7W18L4vWmgTXAhHyu5xt54qHpqg6iIxd5jzwNuY8k2FN+9xpLlOUgjQ8wsB4OePvEmiuF67JUg9t6qgdgXyVXfzUXsrXU3Jsw5yoW3CKUdd9yxfwOC+abmMPL/gQ98YJNoKNczXO2+++7dSSedtCASw3HS/i8/Rk9Ln5TZlu3NELzrw7QSxN4yK2O/2ikUPx77IdL5PwgEgSAQBIJAENgICMw9sac8Wh/Ng16EwJniaJO47bbbbqqDcmm39jYPyu4ee+zRbyymnErC870j3O+lMDojIaWgtkrtqM8U5qOOOmoqYu9+JJk3T7uqjsrkVfQ9sjlNmpXYU8jhKxS/yLE6TEPsEVQhx7yfVW/n1d4Vv+0rdRiGpjPI2Ikb6UfSEFbLLqp92iZaQwh2EZy2D2EtdJ+nsfrCWcTI4x//+FMQwWn6pb1GmbMm9bP0QCg3o4Q2kA8HAuk1ejZAq8OmYqMO44VhQJ+1bUM6GaLgVUmZRex5YtvrGUm23XbbnhjX9ZPODF3veMc7+rpXPmTFJpb2lmC0qL4Y5lORGVe/+tU3IXEXutCF+lcVLhXPceUtl9hXtI6xu1bEnrcdvuQD3uOIPVm3u7xopOoXZ/Wu3ezJQWHVjpP2s98ZSe585zv3ZVbZyt9+++1HblS6XGJvHwzPhRoL6h1iPxw9+T8IBIEgEASCQBDYKAjMNbEvYmHjrAtc4AKbKJ48SjaoQmQRuMUOO58LN6dwlgLrs83Mhq+7Qhb33XffBcW4lGNK4xFHHNF7eCn/rWI7/IzYWxfM4648ZSGWozz27kUGrKVvvcrK1U4eqKFXcZyAzkLs5aFsbw7wer8ivsqlLC/msYfTG9/4xk2IvXs3B7FXbwnp03/tRnewFlrMCKOO+kFYfduPvJEMGsN+8z+SQl4Yd0pWnBkM7IRv6cLmTuqkXO9tJxP6SjvVCbmx94PIhJNPPrkTcSKEetRBPrz2bhiNwGhh00Fy26Yq19rpFovlEnt9of6WTey///69AaH6oi2/PtszAdFUbvUjHGycaexPkyr/9jzqvpUi9gwu+qnquzk89trWes6rbMTesgNGrmq/tvvMw3/f+963r2ddr68ZUqy/R/7rnnFn49B+FaKa5FHzHbm6z33u08vlEOuVIPbeiBBiP0Q2/weBIBAEgkAQCAIbEYG5JvZIBS/lox/96AVSQWmkLCOdyMy0iXIqbNw655agIOsveclLNtlADblBWJEmSmNdz8vpNWNCg8cpu+pM+aXoIlBF7Kveo4i9NsjP65so/1Ue5Vj5PKwI2zRpFmJfSjpib6mD8pStrtMSe4aOlmy5lyf1mGOOWSADi9Xb2m5LH5TvfgciwsuOrEpV11FnbRZ67L7Cjlf7BS94QW+02G+//RaMFmTHmxS8AlEfjcpPeUixEPFWXuRvAzee7c2d1NXO4nbDL5z0kXe5M0Jpx7SJ0QJJLryctVNYM1LYppUm9rBXnkM7piX2ZES0hHq29WbQMa6lti/bNtTn9vdJeM07sf/Rj37UGzELZ2MCbjvttNNIz7nx84xnPGNhs7/C1zj21gjRRDWvDTGs/41T46WMGfrWWDOfGYfmzGFaCWLP0GYcVJ3jsR+inP+DQBAIAkEgCASBjYLAXBN7SqMNmWw4VoSNAkeR8+qyUTvaj+s4iunwFWbyREp5snjMK1Hsrb+1i3UpjK6lrAr//+hHP7pA7BFyeddRnnxEBHlkHHCvfCi644i9+5EqyneV5XqHdclCsJU1Kfndum/kUx51qMOo99iXUr5UYk9ZF15dbax6I9XeGb9YfastyyH28kA8LAmg1Osjh888hd/5znf6tcWFBeMMeYJT9V3hUGd5Mu5Yu83zX3nqCwYHRghyOWuS/1ITA5d3oNcadfKkLeTRGmmp6u9c8jg8+w0Je+Yzn7lJv2kbA1KR5Kqn+/UPglcYwsP117rWtXpjlGtdNykxTKhnS+y1wXiQN7wn4UPWGMrq/qoLIimywj4Rxp5jVCoc/NbiM6pMeSznPfYVil8kt+aQxTz2tWcFTKp9zsbzAQcc0C8Zqna057YNPjPcCMVXbpWN2O+8884jib36Gse1gZ579LF7hNHbu6DmNeUqoy3TOLJ/hKUfZJJsOMwLlkCVfBb21T/LJfaWy4TYF5o5B4EgEASCQBAIAhsdgbkm9pTJY489dpNXe1E6rV1FdCmZs6Tf/OY33S677LKJ0kyBFY5/3HHHLWRFaUV+7nKXu2wSGk/JRux47ZEd1yEs6lmKtu94ew8++OBuyy237JXb8ihRdscRe/dR7F/84hdv8vo29xQZZVAY12b1sGa8QlNbYrBaxF6ZFHr9UeXB02u+hG4zGEyTlkvs4W99r/dlK5+MwAypOOywwzaJghC+rV8RRYSmJSr6oA71tnEY44A+kK82yhu5tOZ8+I7vUW2VPwMUmVhqkgcvrHDpwtmZXFnnLkRfvce1pdpUZ+227KNd3qJdllA84QlP6Alk1dU9QvsPPPDAhfZXHew5YX+DaQw46uYVgsZa4VhjmdGJDLhmXFIP4fhC791XdfDZmFLv2lPBteMSWan+GHeda9aC2JNJy44YWKp9zjaDFJFiToLR8Gjb4TMDYUWwFFaTiD2sjj/++P7972Wkcx+5Z0hiJCB/baoy9b23PNg0jzGtxorxwsBns0nz7qi0XGLPUBtiPwrZfBcEgkAQCAJBIAhsRATmktiX0siLt/fee2+iyFMcheHz1syaEBph2aW8UpopoJRXHswqV77Kft3rXrcQSl+KtvIRWWudv/rVry4QQfciBDzENqKjSLsW+apy/D+O2CvT/dpV5Ke9T515xHjCeW8rKVco7Wtf+9p+TawIhCKhVedxxF4e7i+Pvfq5h1Kv3outsafUq6/3wdd9ypYPo0brqav6jjovl9hrA1JX+wSov3ogrgw5yHwRHN/Vu8Th7d5xB3mxG3u9P73wlLe1wzzFX/7yl0c1qc9TPyHQNmhkCJglwqQyVTf1QIpr/XJhrS0MKMopsjeuLfW9fF2LVDEKVJucGUN4aHl822R/B/tZkOn2ev9bLoFwL5aUr8wb3/jGfR4wrH6y3p/8MhSNSlV3+yXYbV74flsP+TBKGHdIpn4dJnkgmEceeWRPYEXTjDM8uX8liH1tnleyt5jHXvvt1m+ct+0znkRH8Kprx6i+rvb63RIlr7tTbpWtr8aF4ruXjFk+U2O5LR9BZyjQf20y/hlEybe2VnnO6iwyhvxXndt7fV4JYl+GzGpnQvGHKOf/IBAEgkAQCAJBYKMgMHfEvpRAZx7RbbbZZhMlF+HcYYcdFryts3QUhR1BqnDmUl554e94xzv25FC5Dkqr8m2yhoTUtc6USGRRGLTf7QHwuMc9rrvrXe/aXfva1+5/a6/3WR6U3UnEXlu8c53xgYJaZblPuxEv9yNf1hvbTZy30+7t1aYiTG35k4i9MnmTrbEvI4T2TUPs4eRVaNpddVW+w/1Ce72OjFfXzv5IqP+H+wUsl9hrA9KHtCG76u+AGxzVpf6/2tWutgkZr/4ed+atfs5znrMJcSls5YuUWhbyqle9qieDH/zgB/sNFh/72Mf2b2tQH9chTIjTUhJifeihh/bEWjsKa0SxljyMInvj2uR7GwfycldbKs8tttiiD3l3TSWEUzj29a53vYUIFvXQz/A1Rq3R1s/WU9uE76CDDjrFumoREF5DqF/cXwdjlHKRUQQfluTbuOJJltRHG0Un+I1hpepeMoe8kjmbTcKLUcY72mHEc7z11lv3+z8YR4jyO9/5zpHRBmtF7LWRZxx+rfERTv7nyWe8YnCEEXzgaQxWkgdif//7338BXzgVsf/Wt77V4+g6R5v0z7Oe9azemAlT5ZZcuF/5IlgYRcxRIkgY/8yFZLzucTYuyELrrR+WuVxib3PM2hW/yhYtpF5LMaK1WORzEAgCQSAIBIEgEATWGwJzR+wLQMo1xVvYcynwzkj405/+9P4y5HuWRLFEIttXO1EIEY1Ru+MjNDa0s0GX69p6lNI7/E5ernVQditMvcpZjNhrN8Xcelj3KKfuda7yfG8NL4W/vved/5XhOv87YMa7PC4h9ghDbYLnHnVfzGMvP4T6kEMO6cOF3eOAQdXT5/rfGbEW6dCmlSD2+hYJRN6q3e1ZfZBQ3kVkXSqiMemMTP74xz/uw5G1rdpVZ2Volz6oo/3Ob3BFREV5IE/Kk++0CQlX7+pnZcuz3g9e+U1qx/A3Xn79hpS1bVHPvfba6xReb3VglEGcqo/VR/scvlMnZ3JpuYN72iQKxtIa0Rzuafun8lIXn5XjFX5C06UyXDgbH8hba/yqNji3+fpc31Ud1VN4O0PC0MikLGPQ/gqiACpf+dRGf7Bs0xBb3m9Gplk99vJk2LNfhPmoMKo6OMNG/Y1pBgpeccth2iQUvyX26j4k9nCsete9vrND/p577rlgyGrLrvKrz+usTu3hDRQMW4stVVkJYl/vsVe+dtYYD7GvXs05CASBIBAEgkAQ2CgIzC2xpxzzDFHGW+WSsvyxj32s759xobuTOg8RbT2VlFP5Izi8ha3S7jNv6dFHHz0yRLWtV32mbCPXditHlouQKUdbWmLfltXWGQES4s0TKj8Kq6PKGJ79Rtm3A7/1/3Cj6CrTb6tJ7LXBRnIiHrRbG6vcqnOr9PNgD9+XPonYj/L4KbOOwg0ZE1pth/hh+fBSF33C0+naun/UufKss+t5UkUcVGTEsA8K7ypLHXznf2eEWdj6MJy5yhh3ZrxiXGJkKRy1BYERrVEEZlQ7Jn1nfCGvW2211YJcyVcfCgVnzGiTsWZXfsYEfVx1ca5+rrb6HSm370Gb1Id3meFA/dv7hnj6zRp+m8bBAOnUD87+F3Lv9ZXCxNWhvb/qVHKgPvKr8vzOcHCHO9xhk4iAqqtylkPsrZUfR+xf/vKXbzLHVJl1hhEDlWUFdqUvOVLnOlqcGQBEw5D96u9aL19tdja/jXrdXZXr7H7YWlohgme4UWGLcftZ/uoGZ1EkT3nKU3pSL79JyVjYddddF+YN9zNA7Lbbbv3yosXu57G/2c1u1pddbS2P/bhlFpPqk9+CQBAIAkEgCASBILCeEZg7Yk+Zo1jz9gzXmlIeeajKE+jaxZS/YecgKN5rjuzKrxRUxBhR4jEbJsquEGvrORHtumd49htPIC+S1+VZ+249N7LkUKad9q1XlibVHYGhYPMqIsPDstr/KcQ84Qg9bCw34G3UPgrvYsQeOeSNVUfXyxuhQCYpz4sl/UVJt569Xu8nj8rLZ3WRp99FXNgosDDQ10hv2yZ1FrUwLbGXF4OId2kXIWrzgxGyacMt2JbsjDpXe+u3+p+XWxg0udTPbf6Fdfudz9ohhF04P8JVJLXynCQDrtE3yGAZFApTBqIXvvCFC0YKbVqsXdWeOltLj9y2dZa/MGrEtE3u0Wc86JZ+wNO1RTzbPHwWWi+PofFNPowk1mwPo3HaPOBJ7nmPGX7IWB1Vf7LBGMcAZvy294/6rL76Tfi2TSqNFXlJdfZZOTai5KHXPm11ZhgyxvzepqpP9QGczDElI8p1IL021XTdpERGvvKVr/TzUUUlVHsqL/VxKIOBgwFSUhcee9+5Fo4Oc5N2M7ZUfcfVQftgbjnDdttt1xtBqvw6y1P5VR/y6RWKxkc7ZseV4XtzBoOgfCpf9UTsR0VSDPOqXfHVpe4vYj/N/cP88n8QCAJBIAgEgSAQBNYzAnNH7IFJsbQZmrW0FFTeK4eN9CjyyPdiyvG4TnEfYuEVW9ao8h465G3N+ihiLy/KMAKqfOvqbahGqeZh4jVEUm5961v3v/NK8ogiNcLO5Y84K2///ffvFVptlOekpK4iDHgP5WHzNMSY8krh5wVGaqxl5eFXpnuUb62sNvG8KbeMCaPKQwp40e0TYJM3dXWvPJCEaZL2KJchgxcNHvARYcFggGwj1vqU57dtO8yPOOKIvo3q6hDKiwT5rYjIqHNbN23XR0ib+tupGzG0vlr0BG89jCoN86vvx50RLkSbN5vhRt6MH/qCHGgnYuIzT7jyvT6uMFQ/R7W9yh9Xnu+135IU/UgGtMXBOFKb1smnzbvyXeys3+UNG3V1GGc8rt7A0CZ56WPGE4TMmnqyR/aF3jv09cUvfvG+/40lhgz1GiZ5IX9HHXVUb1iosQRHB0JvDbw+ZFAzBqp9hZ88JH3CQIGE2uvgyle+ci976sNLzbBinDBGwNAGdAj9qHpVPeVtjiD/NTe4Fy7qU2W31/vOIV8yBiOybr28djj0Wcn+MI/Ky9lv2qUOXnG444479pE+2uIgX4i08ST/9773vf1+BvrHoX3kU93rUL59D4yPaZP5i+wefvjh3b3vfe9+CYWyq5/MRfY0gLvx65WD6j2pbW3ZjAf2Zaj5RlvIojdZ6PPCs72n/aydxrRnBNl1v2gsc1k7ztt78jkIBIEgEASCQBAIAvOKwFwSe2BTkJEaXlJkiqLnvFKJAixkVr4OZZUX2W+tckpZlUppdT1vvLW+NhXj1UZq2/BPBEjSjspPnkW++x8X+eNeR+VDKbcLNa8zb5WNsNoyKzv1RNq0SV21a+g5rWud1aswqLN8HS0O7T2jPldb3YdsITef+cxn+roiKfoPLnBvkzLUGTZ+r6OUc/hJrhsebT4+q4P7tVlblNV+bq9fLK/22vrsHslZ3gxQCA0P6+c+97neI4r4ezWZ8oepyqw8hr8P/9ce5TgKX3j4XMnnynfWM9zlDes64Od7R5vkLTmTJ/2sX7/+9a/3bYcBskX22vq1edT98naN8W0pB1m25MBYEmZP1tWr0rh2tfmRd/snuFed5EcG9QdDQmFYeU46q5+6FSbOcClZHN7b1s81JcMli4XxpHHY5llYy0u7tAlGPO7wIXPaSrbV1XXO6umz7+uoMe33WZM+kp98ecFhqR7wtZFh1cE1S0klS/Kv+vrcyvSofAtveBa27oO37wq/UffmuyAQBIJAEAgCQSAIzCMCc0vs1xrseVYM57nua93vKT8ILBWBIptLvb+9byXzavPN5yAQBIJAEAgCQSAIBIH5RCDEfj77LbUOAkEgCASBIBAEgkAQCAJBIAgEgSDQIxBiH0EIAkEgCASBIBAEgkAQCAJBIAgEgSAwxwiE2M9x56XqQSAIBIEgEASCQBAIAkEgCASBIBAEQuwjA0EgCASBIBAEgkAQCAJBIAgEgSAQBOYYgRD7Oe68VD0IBIEgEASCQBAIAkEgCASBIBAEgkCIfWQgCASBIBAEgkAQCAJBIAgEgSAQBILAHCMQYj/HnZeqB4EgEASCQBAIAkEgCASBIBAEgkAQCLGPDASBIBAEgkAQCAJBIAgEgSAQBIJAEJhjBELs57jzUvUgEASCQBAIAkEgCASBIBAEgkAQCAIh9pGBIBAEgkAQCAJBIAgEgSAQBIJAEAgCc4xAiP0cd16qHgSCQBAIAkEgCASBIBAEgkAQCAJBIMQ+MhAEgkAQCAJBIAgEgSAQBIJAEAgCQWCOEQixn+POS9WDQBAIAkEgCASBIBAEgkAQCAJBIAiE2EcGgkAQCAJBIAgEgSAQBIJAEAgCQSAIzDECIfZz3HmpehAIAkEgCASBIBAEgkAQCAJBIAgEgRD7yEAQCAJBIAgEgSAQBIJAEAgCQSAIBIE5RiDEfo47L1UPAkEgCASBIBAEgkAQCAJBIAgEgSAQYh8ZCAJBIAgEgSAQBIJAEAgCQSAIBIEgMMcIhNjPceel6kEgCASBIBAEgkAQCAJBIAgEgSAQBELsIwNBIAgEgSAQBIJAEAgCQSAIBIEgEATmGIEQ+znuvFQ9CASBIBAEgkAQCAJBIAgEgSAQBIJAiH1kIAgEgSAQBIJAEAgCQSAIBIEgEASCwBwjEGI/x52XqgeBIBAEgkAQCAJBIAgEgSAQBIJAEAixjwwEgSAQBIJAEAgCQSAIBIEgEASCQBCYYwRC7Oe481L1IBAEgkAQCAJBIAgEgSAQBIJAEAgCIfaRgSAQBIJAEAgCQSAIBIEgEASCQBAIAnOMQIj9HHdeqh4EgkAQCAJBIAgEgSAQBIJAEAgCQSDEPjIQBIJAEAgCQSAIBIEgEASCQBAIAkFgjhEIsZ/jzkvVg0AQCAJBIAgEgSAQBIJAEAgCQSAIhNhHBoJAEAgCQSAIBIEgEASCQBAIAkEgCMwxAiH2c9x5qXoQCAJBIAgEgSAQBIJAEAgCQSAIBIEQ+8hAEAgCQSAIBIEgEASCQBAIAkEgCASBOUYgxH6OOy9VDwJBIAgEgSAQBIJAEAgCQSAIBIEgEGIfGQgCQSAIBIEgEASCQBAIAkEgCASBIDDHCITYz3HnpepBivlqrgAAIABJREFUIAgEgSAQBIJAEAgCQSAIBIEgEARC7CMDQSAIBIEgEASCQBAIAkEgCASBIBAE5hiBEPs57rxUPQgEgSAQBIJAEAgCQSAIBIEgEASCQIh9ZCAIBIEgEASCQBAIAkEgCASBIBAEgsAcIxBiP8edl6oHgSAQBIJAEAgCQSAIBIEgEASCQBAIsY8MBIEgEASCQBAIAkEgCASBIBAEgkAQmGMEQuznuPNS9SAQBIJAEAgCQSAIBIEgEASCQBAIAiH2kYEgEASCQBAIAkEgCASBIBAEgkAQCAJzjECI/Rx3XqoeBIJAEAgCQSAIBIEgEASCQBAIAkEgxD4yEASCQBAIAkEgCASBIBAEgkAQCAJBYI4RCLGf485L1YNAEAgCQSAIBIEgEASCQBAIAkEgCITYRwaCQBAIAkEgCASBIBAEgkAQCAJBIAjMMQIh9nPceal6EAgCQSAIBIEgEASCQBAIAkEgCASBEPvIQBAIAkEgCASBIBAEgkAQCAJBIAgEgTlGIMR+jjsvVQ8CQSAIBIEgEASCQBAIAkEgCASBIBBiHxkIAkEgCASBIBAEgkAQCAJBIAgEgSAwxwiE2M9x56XqQSAIBIEgEASCQBAIAkEgCASBIBAEQuwjA0EgCASBIBAEgkAQCAJBIAgEgSAQBOYYgRD7Oe68VD0IBIEgEASCQBAIAkEgCASBIBAEgkCIfWQgCASBIBAEgkAQCAJBIAgEgSAQBILAHCMQYj/HnZeqB4EgEASCQBAIAkEgCASBIBAEgkAQCLGPDASBIBAEgkAQCAJBIAgEgSAQBIJAEJhjBELs57jzUvUgEASCQBAIAkEgCASBIBAEgkAQCAIh9pGBIBAEgkAQCAJBIAgEgSAQBIJAEAgCc4xAiP0cd16qHgSCQBAIAkEgCASBIBAEgkAQCAJBIMQ+MhAEgkAQCAJBIAgEgSAQBIJAEAgCQWCOEQixn+POS9WDQBAIAkEgCASBIBAEgkAQCAJBIAiE2EcGgkAQCAJBIAgEgSAQBIJAEAgCQSAIzDECIfZz3HmpehAIAkEgCASBIBAEgkAQCAJBIAgEgRD7yEAQCAJBIAgEgSAQBIJAEAgCQSAIBIE5RiDEfo47L1UPAkEgCASBIBAEgkAQCAJBIAgEgSAQYh8ZCAJBIAgEgSAQBIJAEAgCQSAIBIEgMMcIhNjPceel6kEgCASBIBAEgkAQCAJBIAgEgSAQBELsIwNBIAgEgSAQBIJAEAgCQSAIBIEgEATmGIEQ+znuvFQ9CASBIBAEgkAQCAJBIAgEgSAQBIJAiH1kIAgEgSAQBIJAEAgCQSAIBIEgEASCwBwjEGI/x52XqgeBIBAEgkAQCAJBIAgEgSAQBIJAEAixjwwEgSAQBIJAEAgCQSAIBIEgEASCQBCYYwRC7Oe481L1IBAEgkAQCAJBIAgEgSAQBIJAEAgCIfaRgSAQBIJAEAgCQSAIBIEgEASCQBAIAnOMQIj9HHdeqh4EgkAQCAJBIAgEgSAQBIJAEAgCQSDEPjIQBIJAEAgCQSAIBIEgEASCQBAIAkFgjhEIsZ/jzkvVg0AQCAJBIAgEgSAQBIJAEAgCQSAIhNhHBoJAEAgCQSAIBIEgEASCQBAIAkEgCMwxAiH2c9x5qXoQCAJBIAgEgSAQBIJAEAgCQSAIBIEQ+8hAEAgCQSAIBIEgEASCQBAIAkEgCASBOUYgxH6OO2/eq/7f//533puQ+geBIBAEgkAQCAJBIAgEgSAQBNYcgRD7Ne+C+a5AkXPn+jyqRfVbnV3Tfh51T75bHIHlYOje5dy/eO1yRRDYuAhk7Gzcvk3L1i8CGXfrt29SsyAQBNYegRD7te+Dua7Bf/7zn77+0z5sXVfX1r2zAuD+f//7330+ldeseUx7fZu/+rb/T5vHal63nPpoz1L7YDXblLyDwHpHwLgbNQf9/e9/704++eTut7/9bT+2XLecMbocHIztv/zlL92vf/3r7k9/+tOa12c5bcm9QQACxpyxZYz94x//CChBYO4R+POf/9zP0Z4dSUFgJRAIsV8JFJNH969//aszMS1Gfim5f/jDH7oPfOAD3Vve8pbun//859TouVf+yjEZKnO1lWblUYyPP/747m9/+9vUdV3NC9XpN7/5TfepT32q+/SnP9397ne/m7k4ecCeopQUBILAbAiYdxy///3vuw9+8IPd0572tO4ud7lLt80223Tbb7999/KXv3xhLlztOaqt+YknntgdccQR3aMe9ahu55137m5wgxt0d7vb3bpPfOIT/WVV7/aefA4C6xUB8vr1r3+9e8lLXtI98IEP7G5xi1t0173udbvHPOYx3fe///31Wu3UKwiMRYAuefjhh3ePfOQju9vd7na9PO+2227dl770pbH35IcgMAsCIfazoLWC166lglVljzvP0kxW8x/84AfdK1/5ym7//ffvTjrppIm38yC9+tWv7s5znvN0W221VU/wkczFkrq6jiL9mte8prv73e/evfnNb14SqV2srPod6f3GN77R3elOd+ouf/nLd8985jN7T0H9vjnO2jzEB+bIxFWucpX+oeBzm2D1xz/+sfvRj350CnIhL/f/5Cc/6fsBlvovKQgEgekRqLmT9/D9739/r6Rd4QpX6E5zmtN0V77ylbs3velNfWZ13fQ5L+/KE044oTv00EN7Mn+BC1yg+7//+79uxx137L797W+vSX2W15rcfWpHwPg57rjjugMOOKC7+c1v3p3lLGfpznGOc3RPecpTeuP2qR2ftH/+EPjOd77T67B3vOMdu/Oe97zdGc94xl6frTl6/lqUGq83BELs16hHPLDWs7eUN3wajziS+O53v7u78IUv3J3znOfsHv/4x/ceee0blYosb7vttv1D+s53vnP3y1/+ctSlm3wnPx7mL3/5y93Vrna17sxnPnO36667TnXvJhlN+Y+yPvOZz3Q3u9nNujOc4Qzduc997u4BD3hA96tf/WohB3USOfDJT36yJ/1f+cpXei/euLYv3DjFBwaQd73rXd0ee+zRvexlL+sNGm6Tt4gFEQ+IxDWucY2eWNRv+ozxg8cQxs95znM26Q/EXp3f+973dpe73OW6y172st1RRx01RY1ySRAIAi0C7Tj/6le/2s9H5qVb3vKWvZfR73W09632Z2P82GOP7a51rWt15zrXubq99torJGi1QU/+q4qA5+GznvWsnghd8pKX7A455JB1rT+tKhjJfEMgcNhhh/UOozOd6Uzdc5/73MzRG6JX10cjQuzXsB8ofUjWj3/843V18PQKF/rFL37Rk/tJEFEiEfMnPvGJPVG/2MUu1r3iFa9YCLFvld/K569//Wv3hje8oTv/+c/f8Sq97nWv638adW3d4zflPOhBD+pMhLz9Q091Xbvcsz555zvf2V3zmtfsTnva03YXutCFusc+9rE9HupRBhkkWvjUdttt19eJp+5FL3pR99Of/nS5VejXxJr4YXS9612v+8IXvrBAEobEnhJfSZ2+9rWvdTe5yU26C17wgt1DH/rQfilB/a6/rLcVrgv761znOt1nP/vZ+jnnIBAEZkTAmPrYxz7W3fCGN+yNmwyA5irfmy8mzWszFjXV5UiQ8c3wd5nLXKZ76Utf2plzk4LAPCJg/Pzwhz/sHvzgB3dnP/vZ+3B8462ewyvRps09RleizsljfhEguyJAOcTozG984xvXzVLP+UU1NS8EQuwLiTU48wrzyiJX1o1t7gNhdFiHef3rX7+vh7o4/G9NmzWbiyUKrBBQoUWnP/3pu2tf+9oL64WGD996gArZv/3tb9973m91q1v1pHlcOfK3jpwx4CIXuUh3vvOdr1/Tas37MP9xeUzzvbx+/vOfd89//vN7hVhbeLRf/OIX96HtVffKy/9Ccd/+9rd3O+ywQ9+Ws571rD0OyPJwDfvw/spn1FldKDOWHGiv9Vg88fIYR+zhpL+e97zn9eGK+tUa/Da5354B++23X3e2s52t22mnnVbEENGWkc9B4NSEAEMg4+SWW27ZXeISl+jHln1EFiP25g7rhF272NxgPqi5zvg33zIIM+QNy2FUePazn90bBRkbROe4JykIzCsCoudKX7jXve7Vfe973xvbFGPJwYBtmZlnoshCY8Uz2XhpU13ve0fpAZarrZd9ddr65vP8IyDyk9PFklRRoaI+a36f/9alBWuNQIj9GvaAh4aQMusgeaE392Ftz+lOd7re0y6EtC2fZfzWt751vxZ7Gog8MD/+8Y/3676tG+JZ92AdpbDWQ9fmeSyWl770pXsvvwfvMLmWtwlBtSkVDzYDgqiCVtkd3jfr//L67ne/20+26m8tnzV9Rx55ZN+OSflRBijZQl55yWEpRF7kAuW9FIk6T8qr/U27GQ3gI0Lhox/9aJ9XEXvr/q9+9asvhOJTXj784Q/318L1oIMOWii78lUHpMBDRZju/e53v37n7FH9VPfkHASCwHgEGAOf9KQn9XMGo+Y73vGOkfNem4Oonqc+9andjW98436eKENAe82oz+aE97znPb1BzjIde4C0yTg2j93//vfvx7cN/Ww+Zm6Ydf5p883nILBWCNCTXvva13ZXvepVe+8mo7TNY8cl1yNOIt4si3nEIx7RjwnXGx/DZ137HR3EmHrYwx7WG+vpKCJgkoLASiLA8UO/5FzZZ599ev1xKJcrWV7yOnUhEGK/hv1N2bJhxqte9ar+sKnc5jpsdmcnZxMLsnyf+9yn3wAPGXXYgEk4uk3Ypk08V7zbCCPPlfCicZ4iSiZvlY3p1MEGTyzkw2Sy490XPcAbbt0466Ykj5WwclIEeLV43Rk3EPuHPOQh/QNe/csrNqzb8H9Y2TRr66237iMXhPDbnbpC89W3VSKG9w//dy1M7Gpda2XVx2HDLmvk7Tfgs2sR9vve9759ODDjh+UU8PFbJf9/85vf7Hdj1e/IhdReU9fmvHoIBO/Vw3Zz5Kz/HMY0IiCyhjHQvh/f+ta3NhlPo/rafhyiZRh1r3jFK/ZLeMxzo66t9jCefuhDH+oNnOapG93oRj3J9xypZHx/5CMf6Q0GIn3seWJenpRv3ZtzEFiPCIgwo6uI1rNvBGO7sTApGUuPe9zjescBI7fnMO/9pGe5MWLsMorxpFqqZl2/8ocp42mIyKnjf/2+3L73zLBUirOGDnbggQf2DqBTB4Jp5eZAIMR+c6A8poyVmCTGZL3o1xRAu83aYdYD0+s3fOeB6SjSXGS0zVC9eY545J0drNpCxZFGBLm8wcLgiozWubxHQka9xgaR5uny+jZ5Idry4+1GioXGqyfP9Vvf+tbeGi80X3nItHvUWf2nTdUGZfJeM0RQhK2Xt5mcMHj586Q5K8+7cx28AfYf+NnPftZbWl3LSEEpEFlgB98rXelKfTSEyAevNPG99i+Whg8NWLztbW/rFRTePd5B+Nk8r4i9Nfb6gndhiy226A0LfncvTPRhJf9/7nOf67EUOuye9ve6btTZdZMUo1H3rKfv4C+E0/pM0Q8iTMYdfreHgxBQBhPthp1+Z1giNwiUz14l5pCXvCt/Z/3uKM+q/oUjOXKvCAsHwqbPlCnfz3/+8738D+VhPeG51nUxDoxPc8WshzmDPOjXFuP28zTtc78+s+wFEfAargqt51W01GrfffftN7M0P+h7ZSifMZHXhsHSGy5seImEj0qul9dNb3rTfp2x/T+80cL1Ncblax40l1u3aY09o7HfyZu52SZ/PPj24TAWzJ+ztnlU/czV9gEp+SXDNRbqbEw5/G+8eP6oF0z0HyO3seB31xkT8nP2vTzrXGPti1/8Yj8fa4NDnzJo1u/uqTKrHiIa9FvSaATIS8kUeTLOxh3wJpvt+PPccR+M3VdYL0XO3ENOhd8bJ3SLenWjccbzaQ8Jb+QhK57VkvLNuQz0xqVIOhF1xmDVp1pfsuM3DgR6AMLlejuYk89hqnvqmeINPerwwhe+sJdfBnlRhaVHDO/P/5sfAX1GLlp5NX8udpDtukd/GxvyWmoy5z75yU/u925i1D366KMXdGRzkyhe6+/N94xKyylrqXXMffONQIj9fPffkmtvcqJYIZ4s2iyIHmAeeo56sNcDrAryP4X14IMP7sPt99xzz64OD9F73OMefcgcIn6HO9yh23vvvfuHq9/awwPUJlO3uc1t+gcvhVXUAJItP2eb5fBWU1A91JFl18jHb/JwuN7u7wjYNIniQTkQPiu8z3IEB8MBj/cznvGM/jd1F6quzN1337277W1v2y9PoIzbg4C3HDmGnzcCWJPPA1f5efWVw676vPgmamVPUhT81k7kPlMSPAhYdk30SDwFt3bFp7h68PhO2KGwReW0+RQuFB+GB8sF7KVwanrFCqPIox/96L7tNkXUV3VUn9W5vrcDsx1rKZEO0SyMVq7TrzynlrQ4/E8GHH539j3FUrmVjC8knryVjKiPo8pH3BgPjMOkUyJgnNi40t4Tlv3Mcpg/hD8aU4yGlrtQwCltw/F3ypL/942x5TDuEGx9bKM682LNL+YM84J+FZXkf6SzkvLIgTWW+t381r4Bo66TnzePMDrKxzIfEVUURLJUdVYfRsenP/3pffSA680N7jc3iCZQT3J68YtfvJ/bGJfksZykfHOb+dC4kX+NB5/bw+9kXnvN+Yg3GWd0sLTAtX5zrnHk/xqPdYap3+0Rw9hb44SxmHfXW0xqTCnPZ/eKqvBs8QyrPlxO2zfivfoTAbK8TGTfwx/+8LGHZ2/7XPcZvp6dvOReS0dWjVXGH/nCfdrkWoRdpB4dwPMY2WZUR6QtR9O3+nibbbbpI1iUQR4cjALqg9hzYFRYvjZWch1jF32kSL36ezaOGhvqpAwRAJ4NZNBeFnCCx13vetd+TIvYM6ZFGLTlVbk5b14EzIN0o+oncjGU3VH/61PPGRso0xk5o8xbjPwla7P0L2eXSFU6GP3X2OA4Mk7ss2XuNFdd6lKX6p8t5vmkIDALAiH2s6C1ga71MBsSew+seiCaqPzvaJPvPfBtZDMkJRQt35mUKGOlTNV17dk1SJHJzX0ULv+XQuc719Q98jLhybcOv9dDnYeKZ3RY37bu9VmYntfsKa/uV458qzxnv1U76n/KBaVRlAElgKLsAY7cU5aRbeGC9gMwadsYUN20C1mzASAvxjAV1og7ssF4IA+HHe4ZBig3lHUKTO3ArS7+d73fPRiU4x7fWWO422679YYbDzbkllEE7nbxVxavHsJKiWsP37f/IzC8ZyzY0yaKkQcTpY5lfJYH4LRlTHudhzCL+Ate8IIeoyIRZK1kytn/+pJiivhQIrXD2ECcfEehQ2Tae4ey5He48hQaM5X0NSOBVzdaB1rEzv1CQPWXe/JAL8ROedYfvGTkXx/oy5o7qg/9P4pgur7mDtcYx/qKV5D3hKwuNo/UeKXcUfaMJ8Y+BByZZpBk2HzCE57Qj1l9K3SesaZNjHTKNF7NR8YkDyRPtsRwYE09EmyONLcYh+Sn6tDWFUFBLBgAyBHyQW6VY4M/84O5z/IdsmxMLDcZ04iyuUEYMzxrvmzHhO/gDQdLzkQNMDSqvznF2BQtdc973rOfX91b/dTmU2NEtJFnWOvVIhcUZ32gX0Q1kQflCn1F+hkRXJc0HgHPKMZv0WbwM47IOBmt8ePs8Hsd1V/6ug7GLZvQ2rOH4YoRbVr8yZblbSJaPGsZpRF7fbvLLrv0b+Oxj4Tnsag7pIuslx5DthB05Ay5d53P8vCb/EXbIXvy56n3O2//uDoaM54B5FSE3L3vfe9+XJNh49L4JXdkVpuN+bV87o3v5VPXL+YaS6ZGyWzNVyXHw3N7j3n4ohe9aK93cSiJ9GCkbefhUcjW72SHzmZMMTCbs+kk9EVyLVIEqSc/DGOMlUlBYBYEQuxnQWsDXevBNyT2mucBVIeJqCajarrfhJhZE+8hLzzc5MQS3p7rs+/HHa6p6+rz8NzeO+o3a8mRbRPtUGmuOg/PrKPWllMQeU0p0yZaBAsRF3XAe8Q7wIpPITTJ8t7ymvNOUYwZEigNJl4kjBJOIfLgpxSUQk0xEXLlYeHMauxBMEyw5p2nKJRSNDyrR/uQoUg56rr6vz1TtGHHoIFMMgC097jX/5WvzxRhuLaKnCgM0QtFOob1r/9Lbig52o5gICb6UrjuOIWp7l/ts3oJd6PI6ROYOmu3z9pJAUDGqy3DcUBJEDrNe+++urf6gQJJWRyumx7mw9gBI7KlXF5dZMw4q7JXG495zN8YQ+yNYco1uaSQmw8o1Yxtt7jFLXqZoyi1h34xrhknSwGvMWAesXEWxX+aZDzJh7KHyPPOmTcQev2IRCL55IORzhKLYWJwe9/73tf/bryJImJQIzs24islkPGBsa1IvXxaGSEz5iWGPSTGHFdhpqIS1M9SAURmNZLytRfhMY5qLLRnUQ3mUORrVNIeii4jCyIpnzqqjyx7sP8LGTDHDsdU/a+djJj6RrlIn3HrnqTJCMDWcgah76L6kA6vtIWnDVs9GxiJRMqY13m428NYNJeRRdfqQ3Mskk93sAwFEa6+Glcb8ovcmBuRe8TeunfeVsZPz14RduSd8cD4kK8+Jo+VPKdF95kvzM0VZm+vC/Lqe8Z5bWBwGvV8lpc84aINnh/mHde3ZTE4ldFXOQzDSWuPgLFPJs2x9BEyqr/JOJkQfUkWGPR56OugO5E38zjdqdUbkHMRG7ztDIzTJDJqPqI7mAvJM+OUuZ7s2ptKpIf5z2+L6VvTlJlrTl0IhNifuvp7obUefMsh9iz5HtJeq7RWCYmmEPOulsd+XF0oEB6+zpQWXgMhftacInAmZYTfIV/kk8JtDZ+QdR4whLsm78UUkrYeCD+vHMVEXU3W4xRbCgVFQXgp71V7IA3Wzwrrhj1FyeRPeZInouN6Snx78PhRbLQNiVQHDzeKEA+g+x1CfOtQV8qO/IUw+l2UACWLR3NSgo0HlL0BPCxLyZcXhWjaJROTyljOb+qHgPCmFOkocu4MWwpAbXqorGF/kw/r75E1D/fWMCBPyjClbzGvu99FcSCnCJ0+LDlV5rDc5bR7ufeup7oYw2RZX4lMEXKrfuY0BBaeiNy45FrjHilBGirKxmdRAPpuMXKvn8w/DH8UQ+XKz6ZdjJ/mjwojpsRRGttQ/LZu5ZlnKGVUE/lDkRQFoI3GHy+3eaP6wbk9KK6WAhjfZAk+POmIhry8BpM3ezUTIkbJ5XGqsdWefc87NW7+Uze/8XoiWkXqaw5xRiyNk2r7uPboX0o6wyaDjzFf2I27J9//DwHji8ceoUcyRHv4DpFmMDKvM5DBeFwi/4zYxofxyECl/z17RG14JrpmXNJXxrMlJO5BwBjdKpLKc5rxptbfI12M7uZmY9PRJuNZRAmvPNkSDk2PMTZro1tRI6MMPyVrns0M/+6BDe9rW47nN4Mvg6EIAnK82DOgrWM+rx4C5kfzIEOfZRz+J9OItv6y1JKhtvq6zvqXTJA38zk9iL7JOOA+z38OG/MeHWtSohfR3zwvGH8YF+iV9D0GW7JCl5O/eVx0VuRnEqL5bRQCIfajUDkVfDeO2NdkVuchFCY5Sut6IPYeorz0JkEHorVSSftZSnkDkDYPaaTZgwAGfp8lmdCtc6Ugmfzl4RiX5O93/eSgrDgoHu0yAl52ZESIPtLvYTUuKfdFL3pRr+iyGAsDZ6hwD2W6vHseMDal8qCj8Fiz63dK2KQ6t+XK16ZhsGsVe8YE3pq1TggPgkFhbEm9z76jJArnnZR4VGGDOOiHysdnB48xb824vtbHjCSUPzgjH8aW5Lc6JtVhc/6mPm3dNmfZw7KMQ54Nsl/EnuLFIw5HxMMbOoydwrE9yw/WPDaw54kUTWIXeUoXxR+BMRZGyby8jCdKvLmH8UvEj/yQDfeQMZ53cwcvD8I/yigmL/U0vhjhkPsyFpEjRjaEnYJX80HblrpfhEApjUgQ455Xg5mr1VPZ7l/NpN1w3HnnnU8RxVIGL1hbwjApWcNqThsSe3noL8rvOK9q5YsUWpYgKosBOgpyIbP42fhC7BliEXPPFn1bezhY286TuRixR0zIryVhxxxzTG+cYjxm5PUc00fjkvKMB0SKYd0GuyLpaq8asoxYm2cZwxjWjH/jwb3ObfK/sGnROox3NV+bvxnkaty299Rn95rv7cshqsdzrPbD8FuVRa5FxYggUO8yNFQ+OS8NgcJ3aXf/7y56jvmA7NUrExlUza36k6wPiX1bnjqI1rBsqgynvOyM+3QGyyXtmUJPG5c4lEQDkj/y7JkhepDBjMySH4Yq8s6hZGNkYzEpCMyCQIj9LGhthmsppyYPa3it31nKQelB4ExS45KHoodqu3mea+shVefh/Safltgray2S+lHshON5iFKuedd9X0ldl5pMpvoBARZKyIO70iFR4zAeVWfXCtO3uYv6UPxN/trOm1ehhCzA+rW8FpWX+/Ub7wdlmXLs4Ya4DBPcEHsKHVLC6zJr8qASutmSep89QD2s1jqRHWHL2giPUvKc/U+e7HDswT8uGauMFMLoh3kwaLDiU4jHPejhzINrw0b9iEjWtSUbzushqUeNJ5+ND9j4zqHe0x4rQS6V3xJ7Bi/9Yc4j4zyEDCYtjvW58DSeeP9gzxPIGFVePV4dBNsbJEYlbaakIQTmUGMReTEfVTm84wwFlL5agjMqL9/VPeYYc7/xTBZ5BoU7Dz3tdX2dYc+wSTmluAqT9pm3FdlHSuDj+tVKVRdlWcuuDcaFce9cB8IOp1FJHrDVN7BF2Or+OsNa9IM+H5cYSXiEhe1TuIXur/dUba8+ctav2mKsTXMYF+6rY6ltlk+tsSe7r3/96/t+KYOteVz/iL6qsupcZapvEXuGJs9T5EokDcMbgwtS5bphkhd5ZQgnw+ZTz2JzsjrAxRzOOM3IwBjHcKY+NSfJo5I5xz3ahYwJnyZPDuSKEdcG0Jr2AAAgAElEQVQ1DvcPk+89t5A6452X1ZIR11Y5zgwLDOKuQdBcc2pNLS7wg70+K3l2XuwgA6P6cymYkr3WY88wqz6MnmSoiP2kvDmSPBcYq8wvHB4cPuSJXsbwM8loSYY4DehvDEqWbNUYUi6jqPwZdBkhGKKSgsCsCITYz4rYKl9v8uEFpJxRCE0Asx4mBcRE6Oa4ZKJdaWJfE/m4Mlfie2U4TPYmfcoCb5j2UsKHdfAwoSzbNM6ES+l0+Ow7CnN7+A4pFbrOsk+hoPib/P3mXl7YlTqm8SJpq/I8BLSVgmMdL+UKqUceeQ+QGYowa7L6qqt7JQ8wJNQ1CIPwXsrJkDDUtR5AyD/iO+3eBW3/8v4jXjyZyqNAkWlKzyQvT5vHan6GCxLHYKOP1bE9kAceJbIwlKmql+8t5eAxRlqG+ZSXtvqg7quzMYjgwNg+DzZe00+SvOuo69fyrC5k1ZxByeeZtnkVJQRxQiQdvAyTDtdad9ouc1hKu4zrIbGHnR2GEXvE4aCDDuqzLhzrXOUNiT0Puzx4FpEZ48zmh6P6D0mwxwZ5JjfKEwEiMkdSFiUN2TcmXSeMd1JCcJRNSSRLDs8AsqEtrRGu2lJn9bZUBwky/5Nf5IKyKXSYUc+1q5ng5CDXQkstJ2iJfRFz4djWlurDccn8AXuGxTIIFBHzP4wQNGWNapfoBOG27tf+xZZVjKvH5vxe/4u6MA+IdkIMLReyHMOYqjE26QwXIeY83ctJ+qaIPZkqjz1STT8xNhYj9saC8GQkyN41vOuSZ6s1xfQa695HLc3Sp55fNhMzj7qWt96Sm0rmI0TKs0x9zEvkoeRwKBe+txzDc53RyTgxxowV9ajlPJV/ezb2GF6F8ZMpz1f9Jc8qh8zaA4DBgqFBH660M6Ct03r/DBt6FqOJuZHOInqIYY9MexZMc5hDzW01ty613XRr3nJzorkBsadDMi5NS+zJcBF7EVEME+Ya6/H1OQMWp0ibyIdDWcL+PVs8M+gNxpixRm6d/U6vE4kmykiETFIQmBWBEPtZEVvl61kAPUA8dDxErEUzkThMiJMOlkDhPRQ6pEwY6KhkkqGY2jjGQ03YqdfdSTUJ1Xl4v8maksi6afLxvs1KJl7kkaeM4jbrIXS2jrpX5IG1oSZivyGF9fA2ESJGLJ8ethRn7aqkDQiESdfDQchee/jOQenwwPFbfYa79ukHigNs/c66b0J2+CwMy+GzSd26K9ey7LfHsP/co2yEHKbjkt8QEOF9lBH9Sj70FwXC2uDaqZ4HuogGTHghkQuJgmF9PE+kA2FQv1FrfikxHjDaTVFU/qwJ9hQzD3SYCL+0vlF/TWrvrOUs53pEjnyVd7Ql9j5by0spGVdf38OXog3PIbGnQNhYbYhxjS2Khv6nuBpPw03zXLceEuWFJ8qaWgTWmECuCq9qdxGwSWf3kntEazntM/YnEXuKPmylwrs9+76IvTGlbRWqTvnn2TGGzB2jFEpKvTXstcZSP9tJu5J5CEFDys0jImnKiDeq3Yg5MmbuYABzH2LXbpyHJCEPkjzIn8NnsmSsmfsZIhmleHyUbY6gGI8qt+q7Emf5Vxk8lTbNLDJPVkou1JGS7zlSbRmWT+nWHmPDfS2plxcDJe8tPDwP2nlfXkgaw6WwaW/+IC/rLRVe6m6O0F7h26I0jJPCzmfEloGoPXxfY6/GIqyQFCR3OamM5p4nDI/2ASFrLbEXim8MVTvqXOWOI/bmE89z4864MbcMk7I8zxkAzK2MC7z/7Vg0h9gLgw7juc0ATRZKP2jz9J1xXRvomfMtF3Gf55yxrj3m4JLh9n5kTai/Z6dnP4eC6+Rb1zMq7rTTTn3fIWee0UO5bPOc9bNyary71/+jjlH5Vh1H/bZS31Vd1NGzlZHSHGAMljyTUzI8rbPKfcLWyYs8l5OK2OtD+fmfnDMgGjN0QH04KQ2JvfvJAEMmhwo5FY4/Cm/1Zwyj15M3ugfiTkbk4RkguopsigJkOFiP89YkfPLb+kAgxH599MNCLSgqiJuHGWu9cENeQxPAYgfrqLWJlFoK0WLEXtiqh6IHbBH7hYqM+WDCUh+WckS2wrR97yHvQU3ZMCE7WkVksc/DyZ6C66jvPYCRQ8qFidCkV6FvHqgeym3ygPHwRyS0E9EadfjNZOow6fq/ytUGiqiyKck+twclzFGKl2sck8orYg13Hgn1bBMstY0S40HDyiw/D0iyAWcedSSLx74eJO7RXju4qpM2kCFeVmG6jD7aR0FhNeYFEuWg/LYO5IiS44HK++MBuNSkTvJjYKGst+UsNc+Vus8DlYJGcR2lIDN4sZqPekirgwc1Dw25obCMysODflwYMHmlmOpX3h3ET1njylupdk+Tj37Sd6JUGOpqJ2zEQVvrbJ4yNmocLHbm1bAGvjViTFOf4TXqNiT2lKzy2JsDeWKkwrQ9+56nEHE3DkURFLEnq95ZrF+NJURkmIwJipm5QLSQvTha0uF35YtYoTRW9BRczV2V1Ml91uIy2pobeDgZJUTTCPdkGFMOxbH13LtXfs7wFLJvHnK9TZ5smsdrDnMRFubtzZW0H1GlwLbjgtx4DjBselaNS55N5MS97mmJve/IGeOA5RAwcFSCrzHHoCEU3waH6zWRLQYgpMJ8q51F0p31p2eW+X941HOonjn1fGJEtbngchKSwQhbm+fRD2C8EsTe2DUePL/IgTl4mJQFFx5dY4KRhuGMrFci4+6HD8Oc56K89b/7Xeswz4us4qk3Fhi+ECzGJ89G48b3DvOAiIIhIa/wff1h6ZT1+JWUAZfa9Iy8Iv8VoVDXrcRZ2xgVOYA8LxjhRx1+cw08tMX/xiR585250u/uNf8M2ztrXQtruDOC6A9GTzpIjX/Y6cuS55LfSWfXm18Z5yZFz01TX+2nS6nTkNibJxmxht72Yb6jiL2287wzwqorWfHdMJEr+phnJvkwvvRDXcvQyRCizaLhyGYrx8P88n8QGIdAiP04ZNbo+5bYI6v+n3bSNel7gJlQKau8rqOSiUSeSyH2bX4mHUclRAdRRRwpZc5LPbSd19zDlrJjMkRMS2GpCU+btccEOUyuoaybaGEx7qBk8IbZxMQ6PUTL5M8jLuzQfbwFrmsPhhOKNi+Ah5M68riIMBCq1x6swvJxv3KcKUuiJmpir/r7X72t3RIJQMHTn0imh7CHM+8e8oLYI/nuqf7QD0gFUmktKgXGenp1RNCsS+TNK68mWah+lA/jgOgECpC1shSBjZpEgAjxLOWjlGrKGbx4bkeFw5E7HiAPYrKi7+XR5iMPxgEYUqAqwZjiTEmgDOhDxK5k2e9rlaps8oAsWv6BnGqLg3LGG2VcGyu8pmTZ+JjmsGZWFERLgpfSVjI5itib0xijFiP22jmK2Gu38WNvE0RrHLFHKBECJNU8pf9aJY1cMY4hYwg7w5qoGWPRucYb5drbI8ozT8FsX8tm/pc3AiOvWmbDSFZJW0rhpBQyFimDfBr/6ojgIkrKdT38W5msvFbqrH/UW8RPjak6kyOGRfOn9g2T+Y0sjQrDL4LvLJwXaS+ZrXzMnfrP2BP1UJEB9ft6OSNonmciftp5g9GCTIm4Mm+LXvOcaQ+GH88UzxLPrvYgT+RzOcn8ZJwiIp4jSyH22qcfh6H4njciABhUyTWCM0xkgEHRsg3eS5/Jir52GGvabi5CpuBh3HqeIt0lE+SQTsQIBFeGbaTeNeZbdWEw8AxgGGHMg7ux47dK2i+Kxvwneq59JqgLHUMEnPHnUIblcyudOHrIhOUlnuEiGkYdlpiZf8w72mFe5IzxvfvqXmeRkKOWQ0xT98LZGZ42CCYzyLtxbsx7jpIB8xIdhhyP08WG35eeZN4kT1XeNHUbXtMSe/uY+F/fGUdLIfYiEsiXOlmWZcx6VjLGDusJG/MhYyM5ZDiGec3H6mouM0+br+nRDLv6m2NEOfXMGLYr/weBIQIh9gNEakB6sBn4FCgPmc2VPLzKY0959r9BbXJ2mCDGHSYpEzgPEVLmwTcqaWNN9pRFpNGDa9pUGLm+/WzigVcdFKzFDg9jIdss3j6zLJvQKCc8Tzw+HrawqFA75dYk5+xo61HtGPVd/TY8y4MyxKrv4Y3cIy3qA295VX6upRjD2288BSz9JmxGFYSe/Lje721q8xl+71r3sexSLig0JnkKhcgIsqBM8kiRQF54Zyx/kG9hIV/1o9BQUGwqKMSXZxUZQdh4GNWXZd19lcgFnJUpf8YF9WqvqWtnPRd+w/Os+azk9ciNBztlrCUelBLY8xi1nsXCWV+QUUTLw1roMzkV4UFJdz/yQZaEew4VbXMLYsN4JAxfn8NY/oXPSrZzmryqbGfeEeSIYU17tIVSzHMmQsS4XstkThwSe9/x2Neu+JM89to4JPZFlpFy409/Uo5r/ndPjQOKHMKufynWvPzGSV1TkUSUWl4ikTGUVoZCippr5YtsUwgZhii/5g4yWbLgjPzzQJsPzddek0R2fO93Ci8skCAkhzcKFmRMfuYR8yiyYa6lLLpfP65mEl5uPjUmSsk3xnxmNDFniggpzKouxop5SXt4thhL3deSep/N0aICzIltqhBu95Ph6tf2mrX+rO9r062KbDM/m6fNR+Zoczg5qfm3Pte5ZAR+dVS76v861/fTnltij4CTL+VN67FXLrlkRDZHmgMZn3yvXYxX5FKkQi0Xa+vGMGXsMZoyelVUmvvVg9wwLJJrBh5YGiMin3hPJdch7bWmXhRjeeQLU9d45pEZ5J9cmvPIn43L/CZ5/nq2mwsZi+o3ODGsI62eFXQpY5Axhu6w0qmMrZ4bNS/XuKgxhlSbSxglEXv9oH2WTRpLDBjGE2xdZwyN2mtnUt1LrpwleJrjLG/wLFUncu3ZaD6il9a8Ninf1fxN+SvpsSdv5lmJDiYCkqyLJClcqj3wEXXgFXbmLYatMlSQQXMYmdGvZMi8zeDFAED/KDms/HIOApMQCLFv0DH4DFQPBhM7ryWlm3JAGTIAVzuNIvYGtaN9GKnL8FB3FmvWRw8xVvxRyaQjP5PtShL7UWXN8p06IaMevsL0PIB4M1mokf5xaTiJjrtu3Pfup/BSFDwUTaw8lZQYmA/z979+YkX28PY/cs9T6GFGYaG4mKz1kd8dPsuv7cf6Td18pvTbqZui78HLo8GSCxu/u5dSyDJOKbJRmAdAKwtVhuvhhsR72FqXyoCDlFG4eLTIeLshEbJAifEb4kJGJPlvxGTMUDh5FikjFB4Kk7PDg5iBp8gDbClz+okHhHGEsYTiychS9xWxlyfF2INfqj4kL8KjeSXlo09bWVlLrCkcjBY8ddoBDwoHBW254ZAr1S79NorYk9dpiL16FLEn6+YcBFAfmP/tiYEY8mYZe23yv/WPMOGhMb6q/8iHMWTNJaWWcYBXTJguObEfhrojNzw4SD0DEg824u97MtKOZ5/NN6J0zAeuJ1OUP2WRRQYDZYlqYvSr+xk6GB7MJfqTci+iCAEig6uZKNI8qebDdkzVGEHaGUjUtRJsjCWRSvBjnBHxYl4uAlNnzy6Eqg2Ldr/2U7IRLYYTeK63xPCDBOlL7dF3QrzJb8lbzRXVl7Oe3V/HrO1fKWLvWdISe21gBKNfeb5bWjcqooLcwsfzlDGxvPCFAUMokgY/Bi9yzRhH52HQkpB6+SPqjJLm23a/E9hUfsatPL2KkbHA9eaE0vvIlMgKsmus8jx7Ljsbk8g+54N+RJ7JHVlcjWQuMC7oeebn9iBL6smbTDepOminOUqouZBzuIkwYJTQ17CYJZVc1X3mUth5HqqP+QYeSKnnyXpIq0HsSy+zLMs8J1phVDi/ZwtZNGcxVFl+om/Inb6hpyHx9HbyRZ5dT/dlaC6c1wOOqcP6RyDEvukjE5wHEU9lKQ8mKZMgRQ/pXO0BNorYG/w1AdSDaNTZRGFdzrwRe6SJBRzBgb2HI8IjjBTpkrR3JVI9kCovE7MHOlJvYjbxKhfRr9T2uYcjD4MHOcXT66x4mHzPO85zy0un/hR+Src+9bt2Kq/ty2F9XIeo26vA5F6e3qqDPjbRU4gZcZByD6w2z5IN8oxI8L5TbihISL08kBeeDm1geS58ETevqeO5ELY3yaBS+MzzGa6UEpubUSIRkDqMfcpnyUP1lT6kgFOMjDXhtBRG17UEphQu0TOIlyQP+Os/CiDvq9C9+q3K6L9Yoz+UWaGevNEw4dWhSDJ0kSmyttYJhi2xNw6qX5ZD7Mk7zwnCbmyM2l3cGLK3AiXM0hbeQmXrO6kMI4ySDGo8NAzEyL7x7TpzCAUbxvIQXWWekPxeY7jOvqOoK4tXl+GP/FDgPZeQHGUhQwyOlQeSIxxayDLZNA9QuCmW+tF1q5Xkj/yYZ2pc1BlBMnYYJ+BV8w8FmDGFYdcyF0oyI5NxUs/kOhc5UUa1Rd8wQDHIMWggd+stGUdCgXl2tQGR9BpTS6DIdY2x6sOSgaWc5bGUPlaHCsVnRGpD8RmFyBOPurmzyqgzvH0m65be6DuERySY740p5Mb4QVwYp4bJM4nceA6JYCTHbft5oMmxOZa+wKjKYOX5JTnXW2QY6tW1jANVlrpUnvXZM7yMAf+PvfsAu62o7gZOEREVsfeGCSBYUBN7PhUFG6FpxJKImhCJoIBEjYAlUaPGgmKNQlRAwYYtGjWBWIgIKhqjRozGSrOhEUXKvXe+57e56zp3s08v7znvXXOfffd5z9l79sx/1sys/1prZjP4RYQN4wMPuGcZExFY+TKW2/CMoc+4o18y5M1KV1ROB53F/IxAR3+Ahf5lvtdnok8Ym7SnwzylX6gHh5X+AgN5jpKiHM7uNxYzKsYcam8GOoZnj5P/KGUZ9tpJiH3gQx/l8DAnavPAlN5Hd+SUYbhqJ/JgDmCgFEGirwc28BGh4l4GJfmIDhFh5bp4djvP/DsR6IVAEvv1yOhclACDkwHSYBlnn03AlF2TlWtnlXoRe8901ANq+7OBYhmIvXJTYEwqBkqTLkWOskfxNPFQgmcRyubZ0X4mPhM5QobAmaiF41GMI7nedQ5KDOWBRdUESrnhzTUoS+pEETWxkxeTv89C1HjiTALaKPKr2zOe5+x318svUrS/tX12t6dQkEeGA2WMfOM6Z4YEypTNA01G9VpGxgHrxxlSGBDInTzg4fpYXx/PX81nSqPQZIpmKEc1AUHwtCF8JHKJLCEPiJSJnNIghNakLI/68J2JP8KO3e95lFYhqsIrQy6dHSuV6ogN4x5MGK9i3CNT5HOlk74xLWKPxPPm6Us8WIgzBQvZCqJQ15e8ICfWQSKm2j/6suu0nzblzUM+GA31w9pzJfSV4U+/DE993Fv34foz3LUPTz/Dn7GKgi8v8qidGJmUL/JyD7kTQUTWeIXVMcj0rGUNmRKpgPAY30Px1z8oubx8xjTlUFb14YVnGDXWamdGG/uYGFPreVke5g3eMn1KHoxS7jeWIy7G3EVK2hPhsfFs4MHAw9ASfcw40zWe17Iw7GeYjNPGcOtF7MltEA/ziLLEc+pnycPu/AxXiJ4+oH0iNJ48ijyr57loKx57ocsiXQIb8uFZzgxwnDDGVevj6Qvm4SgHLL2iz1zGExoG8sjfOa6Ns+/kz8nAW29sZ0jT57QH2VR3kSYME+Z2IdX6Vx2hw0ERY339vGl8jrIqj+gEyy71iTjIFIOEsUlETshJ3CcahkHQuOMz7OM351GTe2DLaWCeU47YsDLyDvkYNe9pXz8NYk+GYSf6ifHEPgocITCnF9qwtB7now4Iuugl13p7Uei2gb15lYHSmM6gydBrXiHrmRKBURFIYr8eMQOlThnrg2oFIj5TIpA7aZxBcJjG6SL2MTjHABmDQfusDstC7CnMJlwE0mTEq8ULzlIfIfDD4DXqNYFZkF5WVCQOgREeWIenwtsAjOzyIgmbJR888gZfg7zf4R7JZEZ5oYhSXFnUKQIGc96oIPfuCUUlyhR59Dq7JzzFZJGyTl7cH3kpc3yWj3pSrnn363IqC6NEePCQGmWzPgzRET5JsdsUEsx4UCkkQTziTDYjHD/wQ9rIKuMK8kYGtDsFVPgvwuG+OHhlhfrHXgiUYfJBGTDRRxvW/XulcDe+8UwZ8/QLSgwlWxpWTudRdniPS+zh7NDXedvIu/ZkmIm9KHgYRbsMUqyi7wU2zoNS3IPQIq2MeHXbR/l6nZEWMsSLOOh5fpcPZZOcGg/iO+dB9w+qS7/fPdczGbFgHPOofqGPIOrCmOHsWmVDkCjNomFiiRESZ8OtOpJOXvKxLp2HFR7aitFDGD5vL+OLfBcpaQcbghk71AFBJnchAzEvqEuM4+ow7jFuG3cRe+UxNzMEI5Q8imRQ2eI5UU7XqitizzCqPzGCIS4M3u5HdMxDg1Kdp8+BTWDVdb/yMHAhVHX0XX1tlDnO9W+IuXEeqffMeJZr1cuYbQxSFoTRchGRF4z96hz9rM5zGp/rsjJA0EPML3XfonNYnqBfxfXqoC+KkEBAGS5475XfNeMm+dJt9DdzJgwYY4xtfosjyjHJs8YtY9w3iNgzPnWF0btfuWFljjdH8NjTv3jZ6a70R0YfcjNKClzinpCpeOZK4hVlyvPyIZDEfn2bmcgoDzFAUjziiO94AXjupFl1uH7EftAzDTxCfmYZiq8MButI/h71cL9JhdeClZfHAqGkNEQaVNe4rt85ylVf49ksoUJpTXCUS0onC3fsYusa1n+eFd5xiiIyz6uvzBRV19aDcDzDvSZQVmwTXGxy42zgZyRok/t2OYOM2/jGIWybEcF6NXmaRChGPFqUX78ra33whCCS6ooItCdwZTdJUSwp0kh8KG2UZZ7G1R6GH23mzOtpt2PGGIS2PrQ9zxB84KYdRPYw9MCQ0ucg0zyQFBykI/LwWdittiMbolSsg9RPhfOFrIccxN91+ebx2XONb7xRxjxeU2HNFGRy3VWuKPM8ylc/Qzv0IvZkl7KlPdVH/4C5Qz+KvsTjx/PNm6xPMbQIUUVCrKlFtvSbSFFXZ3g4/B7Y1L+37+n6u84n7o18hzm7p1/ye5Qv8qv/jmf2y2PS37STsR1Rrw1eQeyNwQie/qN/CX3WV7yGkPE36iAPy+GCxJDPOORt/DJe8fIazy1NaIdeT1qXadxP8Vc35Etd7MvC6Fq3S1dbxXfDnKNdncdNXcQ+2sg4xsgiso7XUn/St8w/0c+QSo4S3nntyYDsrH8J7Rdl0RUN01Xeuj7xueu6lfqOcQ4W2tPeEOaEWZWzzpeuyOEQRiJ9KnRVYxn9IHQq8hX7FiClxj73T5LIIrLMWEC/Me9FXyQrtUzX5R7lmePe1/WMfsSePiWSwd5DNht20L3is/HFnEAfdC1d0BxDf8ULEHwOndC1up4/ynfqnSkRGBeBJPbrkTMQUbJ12Bgca0WEcq5DIwAGtGkOOHXjLTqxV/dpJBZdFlIkUujatAayunwmlmgniooDKeOlp1ghXhRL6wAp8QgMJUtoLEs4ZZ8MIHbCBoW+IezaSF7yj0R+1Ik1X15+l58IBBbeyIdySpHlGY3yKXMtU2RMmHworuOcPY+Ca8dbZDLyj/LChUeCYknpomxat6isJqp6w7i4ZzWftdm73/3uJgQ7CHmcET+eeAobRYnCRHESAhprFOHrM9nxm/GiHj+MK0I3hXPy2FGMkUrKQKSQ1Wn1hch32LPnCs+kgCu7viHEm5Fr0AGXYQ7kixds0joOIvb9+oy6xe8+U0gp5aJghOSL3tDHo88MU1bX1Ec/zOM61/gcz4lz/N51dk19Xb/nRP698onvB+Uxye+eweBlYzNKsD4VfUMbGP95D8mXDeW85pTRjNHGmBp10E945ruIvU0Oec+MX0KC7ZUiDN+4t2jJMi/jABws92B8Mg6bKxCPSQ91NgfF3AT/cZL5C5lh5Io19tpDH+exR2piaUT0pV7nGAfNKwyk5kT1jTIOKl/Iafs86L55/W6PFFEJxhF7tYgeqfvouG0wqPzyRT5jrw79Kg79hHFLhJ+2JBP6FM+6JXz6yjQSeYuNEM2TlsF4pkiMaRzmVDIXRtZJsOxH7Dk46nEpZDnw9HfMG3EWeSIyQiSK6C9zUj0+d+E7Sfm78svvEoEuBJLYr0dFh0Pa7BJu0tV549CphWCzyoWy4bZZdFJKL6uggZnnKRTMmCi6GjG+M1HO2mPPm8zrXFszw6o57Nm9QXiRZgSJ5xmpVn6HJQX+NkkMc7iH0mQCqJM28h1vggmIZRm2nsuwgOibOHgX4v3XQfoRY7vOI3yxjlY7wNlBFlhoyQ1PE2s9Is0rAyfXmFCFzAm5pnDyCJMlIc5CMIUy1hOC/HkyKHw2wXGwsFOuGBooUxRkG3NRJurDBkLWMyJm6uhexiplCfmpZdZE5/3A6utepIbyJWwcuXHPppK0FfmhJOn3QerjHOH4ZBH5oAgg8YErnHwWyseTH0qCvEI5gDFZYkQhW5aiULok7dI+4vs4x+/NDTP4jxzywDH0GPPIGpkTXkr+Qh67zmR0mIN8WnNN+a1lcdTqDCL2lGzLfESjRASTtvS9OjFaKC9vF4U0NrsML6Kyac+6ffuVMdomzv2urX+L68c913n1+jwo7173Tet7yr8oJ2Nv9IeYW/UNb/cwd1hXql0YVY2ZdTIvMogilKF0x9mYyjPMYCa6iudNSD4ZWbQkgiTGGBgg9+pMTic95KNvMhiqv3YfN7WJvbXkQextZsfzzlip3zCIaRf9SJv4zZihLMokPNt8ay8bXmPz0Sipl/yOksesriWXlmOZc2FARukbw44bk5QLLsgzfTEMLaG76lfGN+3GiEJHsfzLEjt9cRpGL8+3zIExjQ7hmeYORmtj7jQOzjTGCPsl0FfgOm7qRezhQU7teWM+MLc7+9scSHbJuWvgF1jbv8FyH1iGPug8j7YfF4O8b9NAIIl91c4mLh0VWUUoWmwAACAASURBVAqlwRlJ2m+//Rrv2iQDS/Wonh+D2BtQbN6CGA6bDCossQYgyivi0ZUMyOqKpEQo0TDvsXefEHSkssZn1M8UGpi6Lyai8Jr5Xt0dvovP/c5xL9LAyxAJHogzRQSp9iz52KVXiLFJSZ0o8/6GmQkKMbOhXwzasHJdJDJA8TFRIM4UUwoaCy5POyODdnNdDPT+tmkVazlFxyQIex4M5YhrXe/wTIopJYjxQLuyDps4RTjEJOe++hA1YNdiz1Aua+cl16hDXQ/PYGQRFm7y4j2TP68DS/mmlsgBAw0ZDBLo7ICPXY9FMjB+2DfB+s12YtRB2LUv+a6JjPuQFuGK+qj1xFK0S9c58g/5qNsvfpvWmUJKgdIPgnhFHfQxR+Ax7ln/oxDVkQrjlL8fsWegQza0FcMob7AQS8YJ0RTW1TMsGGsZsLQJuRfJUy+1ir47DObtthu2Tu37Rvl7Ws8YNp9xryO7xmXr6cmNvhH9wmftYo2yjf0o0EK9tU2Nu/YWMWMpVHu+kSdCzwiLHBuDGYU9d9ESHPR/9W7jEJgM27fqPKK/OsPAfF7jNyoO5h3Gdh57+RkXzBeM4OZThk7r5eFsLopNY80hDAvuNW8ZU81H+p18RL3pk6sh0QHM6aL5GOsDpzDWzqOO2tir9ewPE3ITcsHgFWOdclpiZezVj4xt00jGUREo5gayF32zlsdJPsvP3GssJ2eTJPeLYqDjxRIzcs7Bgsxz6lnCKKqMIcReM+ZCBvn3ve99jYEEiadXMzgwYNEXzPnaIXS30LUmKWvemwhMgkAS+xZ6FAjeYmuXeJJ5l0xqEYI/605r4EDcDNIsrgY0XlXr/x0swg6vn4ojvhOO6BUvvIG8VQasrmQQMkmPSuzlhSgiNZ7BclkfvjOBD3MoX0wGLP3+dhhI6yO+R4p6Ha5HrFl2rfGLZKA18VBATLys6rzS2rc9+VIkRRE4eOf9rq3JA6x8driOLCD0iB5FVD14J4Ro15vvRTnirDwMI7y2FCYGEhMGQuU3z4kjJgl/h+GB0oSE8251KW2hjJnkKV7kRvlDZt3Tvo8hgMzE2nIW6XjnepR7UzjDhfHF68N4GihHNZFFSMmPSZ58U1a7vB7agAy5plZoKCjy4wUgx4wuISvRLl3nwJ4c8M5Yz2m9sTWqyJD149p3GokiLlwTyVV2Bg4yx0ikfzlPeqg7Y5bw40kSue61xl6/5DUyPkpw1e/gpW4MgJYY8GQhGXYjZjTTZsLCKXXR7/VD9w9KddsNunZT/N04zFjKmBmENkiAsTmiPYzhNuOqE2zJuOVLsT497o2zPCjaxr14Pdow7VY/Zx6fw8BhLDCmIC3T7F/k27IhRsNJ6m8cU1bzFCNkm9gzlFteoa/oI8YO8xqniPnYmyBCZ7L8iFdXXRk1zC/Gs2VNyk7PoEuQVzKnznShcAqIEGzrGLOqL32FrqoPRN+KM2MaUm8dvCgKUafRZtMoj2cjy+YKMi2KQz80z3F0THrIC4lmEKJ7TZL6EXtzvkgaBipjDZk2tzLamAPJL4eNeYFxy/xPH3CfvhFee/eFvjVJWfPeRGASBJLYV+jVE6HPBnATXHzvPOtOa/CxkVsoLAi+AdPflG0DtiOss84xiPvdtQZ4hFiIUVeKuo1D7A1cyKAD4awPnudhDsYBln4WUpO9DcdYPeu84nM8q9caX797ZtyvfJHU09+UeoYa3mkKiDZsKxa+k+pzrdz7bEJkLBGKbbCnmLH0ei0WLF0j1WVovlj/X+BOpkxSJsUg9e5xKFd8dlZeSgJCSXnw/uPa4xEy6RGwoFBRFBFH9Y7kujjiO2f5I6KUEnLD6zXpBFrnv0yf4UMJ1b6heEf/in7I2s9wQunVPl2JJ1+ET90voz87I8naibxEm/Q6y59MIsKIKc8kZYkxjGGIh8G900hkTwgvgksWRLbwnopcoYwjwJMcCJuDl5zcT5JgNwqxd70xh3eJ8ql/2PSL8k0p49HXlx0MdLw27oFJjAn9ylu3X7/rNsXfYGPMQ/wYXGIOM1/V/QLpZ0hHCNsy7W+GN5t+ISj1ffFZH2X4tJxkURPZFxkCA3M0o7Py2ttiGgcSxyNr7G9jOAom2is89oi9nd71hfDYt4m9sdC8bv09ostQw3hmrtJ/zGGIk76HCIpAm6R8o9Rl2tcqNyOrvSMs3zKuIH3qxGlg00Zjyrzqp19Y540Ax3wVcw9niwg8c5oldgw+2nZayThpGYx5kXNAtJSxVBTBpEfMO+Y48txrvh22LsMQ+1iCSGbNDRHpxWBGtuma+oH52NIGupZICPNi6JbunVfbD1v3vG7TQiCJfdXegzqj3+OobpvqxyD2lB6KDkVTiFd9mGjbR/wurNHBkkzx7UrqYHAah9jX+QUW9bn+vd9nA6Q17oi9cLFhlOd++Q37m+d0PUsdKPImPYfJklLCoEBZ4m3iCUGuTWLWixrYEZ5+YetwNsk7S13PjjI5m7wc8ZmSa2KmENl4rw5hVmbXKjdFQxQBMkbxtWeA3+sU7VR/p+zC0ljYWd0ZW3jGorz1tZvCZ4qKfRLCsxiKUhjVeBC0O0NSr8QoxaKPHLsvjiAg+idjijaONul19gy/kUmGIBEe1hBToijKlMhpJc/hieLRZthQToYszyYPjpDP+lzLb696+H6aicyPQuyVUT0oi4xk2pFCypMsaU9hlb5nMNGXoi7uHZTi2mnXc9Bzl+H3wMYyBwYV/aDuEz6TN2MXRZrRpwtz+TDOmjf0y+hPcfadZRWLuBt+tJOlYYwX6mvMte+L76YtN4H5uPnqK6MQ+xgDYC+EGeGxjwxDnt+QJOu99S1GZFEVdIDVkALjOM+7Tp6LkFq6ac6JOUu/YACGN+8yrzNDxDQTPUmEqfbWjxkQ9FHjc8jEJOfQhaLMk2A8KrH3LPqRPQwYu+niZDicMQxoljbQFZ7whCc0Bp6od5Q3z4nASiCQxL5CfdCg4fdB11TZjfUxiD1vsIHa5GdwiSN2z0UWHa73HWLn8Nn3vK4Gma6kDpT0aRP7rmf1+g75CWIvPMwAPo/Ur/38BjvhzgjAkUce2ZB5Chgyz2rL6i0cVJgWrClAJq42EfY37y+jBQKGhPTyhHtue/LzHWXI5n4mFJMmo4L3bbO6IyKu8Rz58j4y5phgGQLgWyfXxhHfszCrJ4WahZ8iYAJD9D17U0zwDMxhEkoS/H1mNBEW2C9RdnjhtBtM3evwmRzx2AUhjzbpdyYbftefRQqQQe0sbNy4MM3EcMSjpqwUFkSJZ8qzYeNcH75zhAIWZe1Xn/q3ccuuDKMQe8+U9FlrJBnmrMMn6/q8pL/a1Vk/12cZOYbtB9OoU1OIVfgfmSAfDFP2n2CU0h9izHHWL5ACc1LIUhcU5kOKtogpMlofxi674RvXFjGREfInIsSSFPU2Zlv+o8who9Mq+yT56V+jEnvl1nbuE8Isskh/+vrXv95UiX6i7jz6xkYRhXX02bTqvSnmQw9kTEbiyVXMN9E/9A1LNV03zaS9OREYSz3TpnOeQ/8gQzE/THKO8SDmlnHLr+691thHKH7tsdd/lNu8YPkY54oNkkUQqJtyiULyFg+6Way3H7d8eV8iMC0EkthPC8kp5WPwEYqP2NuEJsJ7DCIxwBlw6sOAF0dcozi9JvYYsDZFYt/VTJR3WNirwFo1yhbPHa+Kw+uUbMjEWhskJ/KBdzsZ9L26STg2LziiwOPPG9wrRXtGO0YbWYetXMggA4NJG6ljFLGLNGXZWwqEwCmzNXVCAyNFvvXZb/7mrVQvVn4RIJ6BzAkts47fpDZp8hwYxUTo70VPwuzilVShJFFatKXXAZIV9emV1NGu3tqEMaBWsoThMxjVoeiuH+ZwDyXKvg5IqT0UyMu0kjKIULF+XySNcgvvRIT1EfKg3vURCluMO8ozTF3imnHLrgzDEnvPiOc5k3sEU7+0rIKhTH7KzkDGC6OPUQK7NkjsKnOdf9fv+V1pZF6b2Y8kCIezPoaQWGqC+AaWXZiRM+1FEa/zIKvaUvjvNPtEVxkm+Y6cCdvlzVZm/cxSLjIZfWeS/Kd1r3LySFpjD+tBofhRdm2HrHtDgbEDobScRwi/ZDkbwzPSb57xbvBFNcRMC8th8oHbpEl0BEzpLPWco3/RCxhc6naa9HnuV27LEDihzI+eZTmf6JyYM/TZ+og5Y9hze24Zt9zjEHt4KaeoTRGT5FaUDTmWGNYZExk0LDMScdTLgTNuufO+RGBUBJLYj4rYjK+nvFNwwmPfZdEOxac+j1Is9xmsNnViDwfeOt5VSxmErcGdN0g4sgnK2jXEWTu4vl8yCVgL9trXvrZRhkx0QuAYavqR+jpPz5BPfVCyTCC8td7lbBKhECL6lFmeLh4g669N7iZC7SsP+dVHfMcgIJrARIUkIm88lLzB8kZq+oWb12Xu9ZmSfuqppzYkmSLLuIHwKsMiJ+XW7gwlNTFnlUfKh/GSa+9XvepVjdEkCAhliwGFlb9Odfv0+0w5tgkSGbWWWGTBtBNlTL42uVJe3lU7kVMK/SZChTzGEcpZW/nqV4/6t3HL7/njEHvPU1aeGWHhjFq8817DJVHKGPCQT159pER7D5LZadRpXCymdZ+2NM7NwnusjDCMkGHkI/oFMmDcQfIiwbMr+Z7h0gaJcb8zj79w2GENMV15z+s7Y6/XmYahVhSQOYOc9ar3vMoWzyEL1sUj9gj6iSee2MwpvdbYa9s41EFkhRBtY6a51AZjdBv91vjCo29sYUCddnh41GFRz8ZQJJPuAWcJZnGMWu6QGbqH5UVwbfcNG+Rqk3hG3DPqs+L6Oh9jBmOw8dJz6SIMp6K/gtyHbMR8Mcq5PbdEGUY9j0rso8zOxkQOFuTdvgX6q74AB44AuDPa03PslaGNJ8V41Prl9YlAIJDEPpBYkLMBj9eIAo8UmQinnQw4nrOpE3u4GrQjRJSyaEJ6z3ve03jmhVQPGpzd7xqDvPt46XmfkHpEO3bfdp00KD+/R54+19f7nvJHMbJO0wTKw84gwcNoDZ0N9OoUeUS+2j02OYo3DiD48jXxWVMtLwcsfDdMuetn+gw765Trja4oHMiUqIdFTvocpRbZQOwdiEhsVhdt2VUHOIfSImQPkUeQHWSCohzrut1ft8+gz5aIUISRmEc96lEzW6MaXnvypd4UFhEip59++oboiyD4Ude28jWoLvF7F4bDfDcJsfds8qm/Ii3qaXkNxVdi0EJKGPgsU2FAUM9+KerjvExJeWHJeMnz9LjHPa557ZzlJsJpo17TqJO8jD0M10itPhGkXKQUYhKpF476nrFWSDfSGASGAdWcGcsqIp9FPfMA8q4yahhfvI0EcdD3+o0v86qP/szQa7wSNo/Y+64fsW/Lis3kGFv0I/mYt/QjZE/kkR30zTM2EjUHr/YEH0uwkEKvvT3ggAOaNrfHwiRtHn0FrrHZW/QLZ2HynBd+95x2O00Dd+OHcHVzk2fSLRiv1Nf44tkO7U+OYt4Y5tyeW8Yt77jEPp5vfPImBGMNTMkwQ7A6iHCk23CUaFubKLovUyKwEggksV8J1Ac800BosIgBe8DlI/8sX/knsb+KWLHGUqgo9tYB+jvaoNeEC0PXmbh4I3j9DPi83ay6dvrniZDPKJNpTLr1ORrYd/JCPIRhC8nmvTWZWP+FoCD3FLIwSrhHinvV0eZwQiQpVdZA2ixPIhPqw/rMk2nnY+vlxlGWKYB2kVU+yqvJ3hnRF4q6qAlOJmSePxEblG6EHF6iGBCTYZNwPe/mDmKPIB999NEblDjPGvZQJu3K+xXKsPbyPeVCG8Xhb8R73ETGKGpkiaIGA2eKuMgOy0N43zw/DuWo5bxfveK6ccvnPv1K5APS4PWbvEO+43m3BEIfjNfduT7KE8/0NzIR61KFG1vzC0PlE16K5OoH8heW7J5eKfLvd02ve1f6e3LKuEcZJ6vaW99/8YtffDVD4aRlhe2HPvShZtd0z/E8EUNe5UrxHyaRbSH3QYyNKyKX7BcyjUSmGTqNi7Bh4FA24z35cJ60nY2PxmHLvAJzHk8kl+wNEyE2jbr2ykN/5mBAyI3Z3kYAl1GIvf4oCsMr4BhyzCv6KRmAL4Kr7RkOtL9IqdWcyJFNAxn+tTm5jaVZjL2TypT7RbMY/xjR5W/cRjTJlPbQhtMYf9vtJF+GfMsYIxqHPkIPEu2lvV0T84QyDHuoV2AT5/bzh/m7TeyVSb827jPA0+HqNfZRvvqZXofHAWTesXTRXkvqJR/zkUi6mOe7Xmc7TDnzmkRgUgSS2E+K4BLeb6AyGCWx7914MDKwx0QUV/qOcuNd4jb949FDWk1mlBSedK8Mo5i5Fs71xBD5DHuu7zV5sAyzGiN3PPWUWwTaZM6oYDKnlL/0pS/d4HHzLGWhqPJEmnBdy/uLwEUZQy4oAcL7KQWUTWHplNlhk2chTchCKK0w8pkSJ1RtUVO0OwMPYghnZaeMUcTJw7CJokphZXSRB+XBbvjxDDj5PMyBrDMgIV8UbZ9DHuCMhFPgHP4O71jkPWyZ47ogyYwZDEehiFqXbr0mjykPvr0kkGkyw5A16LCRFjmU/yTJ/RQpZeM90VbWXtsMT58gZ/2IfTwb0bAhJeONt14cc8wxjYLKw2XpiI2+PIMBrI60iPvjHDg7L1uyizXjhbFDO0efFbFCXqedyABPLmLvmfY0sCZ3FOx4g+0PYgw0TvH4h4FykvIy3Olb5N5yFG8J4Vl93ete17xq1BsxTj755Kmso2WgtdSDgTbGR4Ykc4poKZvqwUWfIqcidoY5yCkDxCTJOBcee5ER3lmvPKJXtJ3xsH6PfT2W1c+1JMkrWvUjhm9zFwLIuGMM0ecYf5F/b5jRr6Mv1fmshs/mWvM0XUEf0+YObx8xdpmHJ03anUGOITp0AZEgSCxsQ58Zpa8NWybGXn1HZJu+rW7O9CJLCEUTmJd4sy3JsyndoEN0n34yiv7Rq7zm44h4M57bNwLuNqGlM/Ui9mQ7cIOhN9MwciP35lvzkHFSlJN9sRix6E2iH+kRq1Wee+Gc3688AknsV74N5l4CA00S++FgN6gj6YgqL9Ezn/nMsttuuzVKiomTUumdvTZUYZk2eYSS4xyfh3va1a/SVp6PPPH2CtlENBAXBI6yYEKl1NpMzw6tiLvNbLwqz/N57xlxKGRC9x2szr4zUUUZYwLiEeOhZH03MSOSFFuTlGsHJfkgoiZOyhzSBCtnBMKatEVNgYGJnHWeJ5DiScmP3Z2HLTts4SgPdbdWXUSEZ8CxjXs8u+usLXnzGGTkRx6UkZGJMsWTr90pLjyXsZ5y2LJ2XUeueO142uRN1mFBKSVDvI0UGAd5ZLgYdFi7TsnrR5K7ytL+DrZB7GHLS6KMlC1kb1hiLx94wY8iSum2t4J1lBS0UFDJMYVZ/9Y+7VS3Wfu3Rf+bLFFI1TWIvbN2RQqmnXjOeGsZzRiK6mUQg56lz5B7RMW6XgRTPtpGW46bjHmMphR+yzMYexgg9XlRS8ZC467yWkpgTJ0kkRf1QFrUwxzCy0p2tYN+RpbVjyy3X2eLDHYd8uFJZFyeJCkbg09siqa/62Pqz/jAWDkMsddeop/0effIRx76lrO/yZq6m5/MSV39a5K6LMq9yKwosPBoB7Env8cee2wzj0+jrJZ5WOtNliLaiL6nTes5ZxrPaudhzjAuMwrGXKF91Zk8G1eNKyKqEP5BB93DhrUMSsaNSWTD2M1gZ74gewxWxnoy6Lt+xB5ugZ2xxxigHu4jywzu+gcZV1d92GtpjSGTjEttfPPvRGAYBJLYD4PSKrzGIE+hQxQoxAbOUVOtzI464PKMWLdrsKfYKc8iJIO3gZuXBJFHaCl5lCgTpcnYYM7CSxnmdaD8mdCmmUzE1t7xHFKKkCjP1V5wY2lGnk0ayiz5zMLNw26jPcqqNffW+cdEbxJC1GLtm+dEHtGe8qK4Cpmn0Ko3GdFOlLRBbR35aGMbyPHwClHj+aJ0KNeipii7c6ypM2mr+zheA+F4vFQ2PLSBURDDWlGon9n+DCffkTHypr9QgOWr7RB+ERvIPoLQ3qTRveMk98mfHDDE6Ad2BY7og1BKGWwoMY5QaOLvrjMZZuDgeZwkKRuliWzx+tUHpdIeBPpOpMA1/q7PluHYxZsSzDAmAoC8+sz7xDsj/1jm0jVWRf7j4l2XZ96fjRGiG+wJQtl1aGfGDP23q76TlFHb8c7ClKGHB3zYZ+g37jdmGZ+1k/bhBR4Xe/3aWCdyAJEWicVQ6lnKhWxaP4yo8KYjLsOWtx9OMQYgLDx+Xi3J04oItfuO76LPDTobayyZgdG4mCibOZAhG8b6lLO+wbiMbJENYyQsXB99oK6z70QWMXozmpAxh74V/Uue2tC4YONK81rkV+e17J9502Mu1s76GYMGg5H9IcwN00iMuoccckgjS5wBjEcha4HruHIxTPn0J/rHgQce2OgtbUPGIPmtfyf3xiJ6Fr1sksRBYiNjOo350mEMItsOzhmOkhqr+nPIN3k3H0ffYEzTJ8iwPsJITMY9RwSY9siUCMwTgST280R7Ts9CnIQ8UcaFAjsobgifgxfGQCksjAJBmaEkTTMZ3K1PNPGbWOoDKRHWZ12rQdu6MwPoPJNBGmkx6Ap3pKwJi0TihQWyxoY3wcTEW0nRFaLOgyMEmUJMyZzmJGnyp6QiEUgFIk6hZGFGPHjlYz2e59YTdV0OypT1X5TFyIMxQih+KGMmKPe0D+3gO3mQI5ZnEyyCbzK0qWO/9qrLQblEPpHDUFzq3+fZ5qM+iwzbRM86bJ7rcdqajAlpFcZPziK1Me/1t+uVg+KPBAlp9b5c6zX1L2Ujk0is8s0qKYNwYIq3fQMoL7wdDA36MIOTQ5/pd1BibTDJsDRughXZpaiRLeNJHAiZw3jj9zauvZ6pfvJiTOt1iNpBwvrJfq/8F/17ZIpHkZwLk2Y8oqwKn51FgrWIHgYV49E4ydgtWsWYOK7yTI5scslARJaNu5T2GFf1KetuzZXmALJrGcC0Ezk1nzAwiMxhRBOir78M06+iz+mLCAZjySRyqjz0CEYv/cmc44j+pS8wIromsOqHSVdekadz9Dl5apPVkmL8ifqYU43boiEYtxi7eaUZYqY1fptzGVLoeWQ32kg7DdNWUdZJz8ZKUTA25WQ0o3/QY8g0eWXUGHS4jn5KbzVGTZLUXYRbzBVxDvmOvTSizXqdlUFeDA3GrsinfZavPg3/TInAPBFIYj9PtOf0LAMJjy7F28ApdK4+eM3C+4y0IrIUrWklE4sQZMS9rfgHAaAkIYss10j1PJMB26BrjSZPNGUIHowcrMW8kCYgIZBey8Pjal2VCRkBcH+k+nN8N8lZuDtPCNwQct4MG9BQ+Civ7Um6nqyjLM489zY+0tawpijaBRzR9PuwB0VESLq1ZLG+G7nz3HFTlHPc++d5n3pSNOvzqM93r3arPWjD4u9ZFAihmhQikSMMK0i2KAIyzDsyS0zrssJCHyCnlBoGG2UZtFYyfkce9b1Jlfdh61uXvd897et6/a0tHf3yGlU+Fu16XisGTuPHqGvfR6kLGRjHWBbP0Ab6lGOcpB2t90Wu9C3kgyFTuRx+V74IbTYe8+Yju7Nqf8815iJFSIG+IkpKmwxzMEqIhtE/J02D6uj3TaE/TIIjjGoc68/GTvOqudlramE5rRR9yznKUJ+n9ZxB+agTeWbUR5yRX0Zd84G5YNDBiEamyXON3aDnjvO7/JW3xqn9edx8Z132ccqV96xeBJLYr8K2NTixgAuXY/FEpsMyGuvjhOsJFaKosB6Pqxz1go/yYyM5z0YueZ0jVFcZeB4f8pCHNITFtdI8Bz8TBS8qhQ6JR6Ctf/OecpZuRNrkM+0Q+154xfcmYm3Hgm+dpImwPeHDyXdxxOQTeTjz/CPgQs2En1H26nzinmHPlEzGIp6gcTHxrGVOgdW4dajvj8/9ztG+jG68eAxQjHA2oyKrDkaXul3HLduw9ynvIqRhyhHYwic+T1J2eURek+SzqPeqH4+pN24IKbWOFMH0/azSJJi6N45xyqeuvInWxorQYlBlRJNnECJGLFEFvI3WA4t88908+9w4dZv0nkG4Dvp90uevlvsDJ+c6kSGbqwnZFi4/TcdK/ZyV/hz1DhxWujz9nq+MMb5Hedvnfve3f4t7fe9zpkRgXggksZ8X0nN8jkGEYiLEjVWYpxlZjFA6YXTWP1Nsag/uNItogETYWVx5Reya7TOyzJscoXzTNigMWwflY0FGjHhFhGgJ3YVbnVZiQPbMfoqj39tHXWaf/Y6Aa3NtLL842vcO+jvy473KsLI20sP/PQjnrt/Jo35jfT0DGa8hoxiDnXDpZVQI1XMeKZ5T49rvuXF9v2tW42/qTc6MgdYAe6uAXeZFYsw6RdvM+jnt/I2FlsiIyNKvbJxl6VKUJ8ZKGMCCMdoO+d4E4Rq/zzp5TqblRiDkKc5qY14WpcixYemHPRzmIU8rieQiy3KULdpo0HklccxnJwLDIJDEfhiUlvQak0UMUqGo+Du+r6vl+3knz5zWurJZlD2wm0Xek+YZZYtzV361shDXjXruyje/Gx+BUfFnSLFruwibrbfeulkOYe2zSBibT806DH/8mva+EwbzTDXm83zusjzLOMHQ6lWB1mfbOdrGqnCLeWNWdYm2mVX+vfLlMbVu11IsfcmrDRm6a9lk7LB8yZIy19hbQuTTSpW5V13y+8VFIGQlzpwd5M5mbfZtEC0ZzoRa9ha3Rqu7ZNFO/c6rG4Gs3WpAIIn9amjFAXUYNEi1fx+Q3VA/t/OMv9s3h5HB75m6EZgmNtPMq7u0+W0/BKIfDHtGNrwazHIRhN5GmDY0s7GWXZUtHRGRUadFb+N5l6/GusYpP1+FgDGY99ou1jZmFOVVj8vzbq95tIsINq9rs/+I45FJfAAAIABJREFUV8nZhC/qjGg5rP+1/p5HX/+zyasNvEKe5lHOfMZyIxCyEn3IprsHH3xw84YUbx1YZMfGciM/Xunr9ur1ebyc865EYH4IJLGfH9Yr9qReA1T7+2kWsJ13/N1+RnzvnGn2CCTOs8e43xNqeR/ms42GkAt7VHhloSUtlrbYCZ8H3z4adj6u06K38bzLV+Nc45Sff4eAZUj20YhlO4ht4Pa7q1bPJ6RKZII+5E0f9lSJ+jpbluDtJ963bUNVe7DYY8RvUly7ehDJmswCgZCTkBsbydnHoW2MncWzM8/REajbq9fn0XPNOxKB+SKQxH6+eK/o03oNVPH9NAsXeY5ynubzM69EYBERGKU/IFc8PA960IOaTR5tRmnTR4dXWVr3K5SYl1XIvo3OkHxr8hc5wWCeqcZ8ns9d1mfVeM27reaFmX617777Nt54xN6u5JGsgfbK0b322qvZME8YvtfcMaptCtgEDnmeHIGUl8kxnGcO7fbq+nue5clnJQLjIJDEfhzUlvSerkGq/m5Jq5XFTgSWBoG6vw36zItqje/tbne7Zlduu5XH6728pxgh4cnntUdMvGLSWuEzzjhjofFQ73mmGud5PnfZnzXvdponXjz2XhWp/9jt3hIX6+4ZzU488cSy//77N4e3inhtrH5lfXTK0jxbafmfVctL1+flr+HqqkFXG7W/W101ztqsRgSS2K/GVu1Rp/YA1f67x235dSKQCEwJgXaf6/e3cOBXvvKVzQ74NjX78Ic/vKEUwqb9dtOb3rT53fp7r7/znVcdLnJS53mmGuN5PnfZnzXvdponXvrWS17ykoa0W0Nvnb3lLQ9+8IObV4QeddRR5aUvfWnZcccdm83zvJqsXl+/mrGZZzus9mfVY8+gz6sdi2Wo36A2yn6/DK2YZUxivwnJwKBBaxOCIquaCKwIAoP6YP078n7ssceWXXfdtXktkrX1kWz09Y1vfKN55d12223XbKZ3+OGHN6+2jE3A4tpN/VxjuqljkfW/an28PuJVp0984hObTShtomeDPB56fc6Slmc/+9nNUpfdd9+9WYNvo7OUpZSgURCo5WXQ51HyzWtng0C20WxwzVzni0AS+/ninU9LBBKBRGAgAhQMGy2dd9555dxzz23OwvB9j5Q4rMH3+8c//vHyqU99qtnwa2DGeUEikAg0COhDF1xwQTnttNPKKaec0vQju+XrV2eddVZ5xCMe0exjgfzbId/1ofgnhIlAIpAIJAKJwCIikMR+EVsly5QIJAKbPAJIhBRkIonFJi8SCcCUEYi+5Rz9i0HthBNOaMLwb3WrW5WXvexlG4XhT7kImV0ikAgkAolAIjA1BJLYTw3KzCgRSAQSgekhEMQ+cgwSEn87d31X/56fE4FEYDACNbH/8Y9/XI4++uiy7bbbNstg4jV37f44ONe8IhFIBBKBRCARmC8CSezni3c+LRFIBBKBkRAIQhHnkW7OixOBRGBoBPSxM888s+y5557NjvnO1uJL2f+GhjEvTAQSgUQgEVghBJLYrxDw+dhEIBFIBBKBRCARWHkEkHaHne+PP/74ssMOO5Stt966HHLIIbl3xco3T5YgEUgEEoFEYEgEktgPCVRelggkAolAIpAIJAKrD4Ff//rX5ctf/nLzusj73//+5drXvnZD7B/2sIeVD37wg+X8889vNtVbfTXPGiUCiUAikAisJgSS2K+m1sy6JAKJQCKQCCQCicBICNgd/6STTirPfe5zm9fcHXrooeWwww4rRxxxRPPde9/73vLLX/5ypDzz4kQgEUgEEoFEYN4IJLGfN+L5vEQgEUgEEoFEIBFIBBKBRCARSAQSgURgiggksZ8imJlVIpAIJAKJQCKQCCwfArHOfvlKniVOBBKBRCARSASuQiCJfUpCIpAIJAKJQCKQCCQCiUAikAgkAolAIrDECCSxX+LGy6InAolAIpAIJAKJQCKQCCQCiUAikAgkAknsUwYSgUQgEUgEEoFEIBFIBBKBRCARSAQSgSVGIIn9EjdeFj0RSAQSgUQgEUgEEoFEIBFIBBKBRCARSGKfMpAIJAKJQCKQCCQCiUAikAgkAolAIpAILDECSeyXuPGy6IlAIpAIJAKJQCKQCCQCiUAikAgkAolAEvuUgUQgEUgEEoFEIBFIBBKBRCARSAQSgURgiRFIYr/EjZdFTwQSgUQgEUgEEoFEIBFIBBKBRCARSASS2KcMJAKJQCKQCCQCiUAikAgkAolAIpAIJAJLjEAS+yVuvCx6IpAIJAKJQCKQCCQCiUAikAgkAolAIpDEPmUgEUgEEoFEIBFIBBKBRCARSAQSgUQgEVhiBJLYL3HjZdETgUQgEUgEEoFEIBFIBBKBRCARSAQSgST2KQOJQCKQCCQCiUAikAgkAolAIpAIJAKJwBIjkMR+iRsvi54IJAKJQCKQCCQCiUAikAgkAolAIpAIJLFPGUgEEoFEIBFIBBKBRCARSAQSgUQgEUgElhiBJPZL3HhZ9EQgEUgEEoFEIBFIBBKBRCARSAQSgUQgiX3KQCKQCCQCiUAikAgkAolAIpAIJAKJQCKwxAgksV/ixsuiJwKJQCKQCCQCiUAikAgkAolAIpAIJAJJ7FMGEoFEIBFIBBKBRCARSAQSgUQgEUgEEoElRiCJ/RI3XhY9EUgEEoFEIBFIBBKBRCARSAQSgUQgEUhinzKQCCQCiUAikAgkAolAIpAIJAKJQCKQCCwxAknsl7jxsuiJQCKQCCQCiUAikAgkAolAIpAIJAKJQBL7lIFEIBFIBBKBRCARSAQSgUQgEUgEEoFEYIkRSGK/xI2XRU8EEoFEIBFIBBKBRCARSAQSgUQgEUgEktinDCQCiUAikAgkAolAIpAIJAKJQCKQCCQCS4xAEvslbrwseiKQCCQCiUAikAgkAolAIpAIJAKJQCKQxD5lIBFIBBKBRCARSAQSgUQgEUgEEoFEIBFYYgSS2C9x42XRE4FEIBFIBBKBRCARSAQSgUQgEUgEEoEk9ikDiUAikAgkAolAIpAIJAKJQCKQCCQCicASI5DEfokbL4ueCCQCiUAikAgkAolAIpAIJAKJQCKQCCSxTxlIBBKBRCARSAQSgUQgEUgEEoFEIBFIBJYYgST2S9x4WfREIBFIBBKBRCARSAQSgUQgEUgEEoFEIIl9ykAikAgkAolAIpAIJAKJQCKQCCQCiUAisMQIJLFf4sbLoicCiUAikAgkAolAIpAIJAKJQCKQCCQCSexTBhKBRCARSAQSgUQgEUgEEoFEIBFIBBKBJUYgif0SN14WPRFIBBKBRCARSAQSgUQgEUgEEoFEIBFIYp8ykAgkAolAIpAIJAKJQCKQCCQCiUAikAgsMQJJ7Je48bLoiUAikAgkAolAIpAIJAKJQCKQCCQCiUAS+5SBRCARSAQSgUQgEUgEEoFEIBFIBBKBRGCJEUhiv8SNl0VPBBKBRCARSAQSgUQgEUgEEoFEIBFIBJLYpwwkAolAIpAIJAKJQCKQCCQCiUAikAgkAkuMQBL7JW68LHoikAgkAolAIpAIJAKJQCKQCCQCiUAikMQ+ZSARSAQSgUQgEUgEEoFEIBFIBBKBRCARWGIEktgvceNl0ROBRCARSAQSgUQgEUgEEoFEIBFIBBKBJPYpA4lAIpAIJAKJQCKQCCQCiUAikAgkAonAEiOQxH6JGy+LnggkAolAIpAIJAKJQCKQCCQCiUAikAgksU8ZSAQSgUQgEUgEEoFEIBFIBBKBRCARSASWGIEk9kvceFn0RCARSAQSgURg7dq1xXHFFVeUb3zjG+Vd73pXOfHEEzc6TjrppOZv537H+9///vLVr361XH755QlsIpAIJAKJQCKQCCwRAknsl6ixsqiJQCKQCCQCiUAXAuvWrSsXXHBBecELXlBucIMblG233bbc9KY3Ldtvv33ZYYcdmvONbnSjcu1rX7tc97rXbX77/d///eK47W1vW/zm+5122qm85jWvKb/+9a+7HpPfJQKJQCKQCCQCicCCIpDEfkEbJouVCCQCiUAikAgMiwBi/6Uvfansvffe5SY3uUnZa6+9ypve9KZy9tlnl29/+9vlAx/4QHngAx9Yttxyy4bEH3jggeUrX/lK+eY3v1k+9rGPlYMOOqjc+MY3Lne9613L+973vmEfm9clAolAIpAIJAKJwIIgkMR+QRoii5EIJAKJQCKQCIyLwJo1a8o///M/lz322KP8zd/8Tfn+97+/ISu/feQjHym77LJLucY1rlF23HHH8vrXv75cdtllG6752te+Vp70pCeV/fbbr3z5y1/e8H1+SAQSgUQgEUgEEoHlQCCJ/XK0U5YyEUgEEoFEIBHoicDPf/7z8sY3vrE87WlPK1//+teb63jxrb3/v//7v8Z7f/Ob37wh9jz3p512WvG7Qzr//PPLP/zDP5SjjjqqXHzxxT2fkz8kAolAIpAIJAKJwGIikMR+MdslS5UIJAKJQCKQCAyNwIUXXlhOOeWUJuQemZeCtH/3u98thx56aNlmm23K1ltvXZ785CeXH//4xxtd4/4TTjihnHzyyY0xYOgH54WJQCKQCCQCiUAisBAIJLFfiGbIQiQCiUAikAgkAuMjgMTbFb+9m70w/DPPPLM88pGPLFtttVW51a1uVZ7//OdfzSvv3l/96lfl0ksvHb8QeedMEAgDzUwyz0wTgTkikLI8R7DzUZskAknsN8lmz0onAonApAhceeWVjdfzW9/6VuPhvOiii8qHP/zhxuv5jne8Y6NXjXn12Hvf+95y7rnnbgh/Xu0KDpL4P//zP+VnP/tZg0+8km2113tSuZrG/TAOnK2j/9CHPlTucY97NGH4d7vb3ZrN8RD5dop72t9vyn/DzysEjz/++CYi4qc//elc4GBg+d73vld+9KMfNW8o+OIXv9hEU3S9qtD4ItrCuOPw+Z3vfGf5whe+0OyjwLhjA8UPfvCDG8Yl1zi6XosYr0b02sSzzjqreX7I1A9+8IPy0Y9+tHllYuThHPcYA+v9HcYB65e//GU544wzmjrEM5TTM9Tr3e9+d7NR5G9+85txsl9V95hTTj311A3YaLM4YOWAXT0nfepTnyqW7kg/+clPyr/+679ukINBMhGy9slPfrK5N8DUFtpMG0WbOXt+tJslQgyPiz7O/OIXvyjf+c53inPIfdQzz4nAoiOQxH7RWyjLlwgkAguHgFeBfeITnyh/9md/Vo488siGvP7Hf/xHechDHtLsLG538Vve8pbN7uM3vOENm9eP3fnOdy5ve9vbNigKi67cTAI6owdSYTO2Jz7xieXzn/98402eJM+8dzwEKKfWznuVnR3xH/SgBxWyqo3aaTXLZLuuvf5GPBjpvGHgzW9+c9lnn32aVwJ6deABBxxQ/vd//7fXrVP5Xhucd9555dWvfnV5/OMf35BYZPrFL35x88rC7bbbrjiMK15R6BxjjHFHOW9961uXP/zDPyzHHntsE4VxySWXNOTK3grGJa9DdLi+fdzi5jcvt7zFLcptb32bcte73KW85MUvLj++6KKmbsqGFP7Jn/xJUxbPvd71rrfhUJ7dd9+9GRsnAYMhxV4RXsMYZXWOut7mNrcpz3ve85p9ISZ5zrLfqz2Q5vvc5z7NmzBCLuo29YYM2On/8PN6y7/+679ujK7uP+ecc5p5jMxc//rXb667znWuUxzucWhXeWhr8nPHO96xPOUpT9mwyWbI7LOf/ezmN3t53OxmN2ue5x753uEOdyhvfetbC1lc9HT66ac3Mm75ko1El8EYseiYZvnmh0AS+/lhnU9KBBKBVYAAD8cxxxzTeEAf/ehHN4oRj5gNyv793/+9POYxjynXvOY1y2abbbbRQXF67Wtf2xBcipBjNSfGD947ZOL//b//16z9zjDv+be49fV/9Vd/1cgiJdtnXuBM3Qj813/9V0MqERiGEMfmm2/eRDsw5PHkzarviqL43Oc+V/70T/+07LrrruWlL31pY2RALDwXMdKXvNmgPb7E39tvv31BsIxFF1xwQTE2iZYxbjGwGbvue9/7NnstqFfcF+ett7pmue+97l1e/YpXlv/47Bnl/B+dV64U3WHMKqUxFHz9G98op7z73c0bFMiUJR4IJCPexz/+8cbQ2Y3ucN/+9re/LV/96lfLEUcc0RDJKFucr33ta5fDDjusMHhs6sleGV5X+YQnPKEx0oS8BlZx3nbbbctjH/vYJlrHmECmJOO0V156xSVDEhJPLuJwv8/ytYxHmzBqi8aKiAn9QX4iTJTlkEMOKYwvcR/Dg409/d5lUFy0NmR8+Kd/+qdmjt9zzz2biIacuxatlbI8vRBIYt8Lmfw+EUgEEoH1CFBcKN2Ua68S432gSPF2RIi5s7Bdig3lmlITSpXPlKLXvOY1jWIjv1mRg0VqNMqQME/ru4WA84BSJDPNBwEy9ulPf7r80R/9USOLlO1XvvKVuY6+D/wiHL7yla80ocl77bVXs+Gg/ou8Iq7T9thrI2OHvoIw7b333uXud797edWrXtWQ+rqolrcIhdaXkHsHwrXFFltsIGK86fFWBPfGOBNnY5Sw7J122mnD+LRhnNpss3KjG9ygPOuII8oPvve9sm7N2tKw+VKK7RjrY83atU00gUgkXl3RDP/5n//ZGBLqMo/7GSaf/exny8Me9rCmjlFGZ97kJPa/Q1bbmovIDjmtsYrPZEbIvvbvSvA+++yzC5m/1rWu1cgUuQrZYkx51KMe1VwTshT51H/Lx7IRZbFR573vfe9mKdAyEWP1YVyy5OP+979/ud/97td81v/8po6OTInAIiKQxH4RWyXLlAgkAguFgEncGlWeCKGuwnMpsVI90fNaIFJ3vetdN1KuEAMe+02N2MOHQuf96rw2SIC1ysuk5C2UII5YGDjz8vLCUdAp2QxPs0q8cQw3y9y+0Z8Z8iyd4blHjpDoWRB7bQEv69Z32223xijIU9+1ll/Z/vu//7t5q0GbfAUBQ6iED7s26uJcJ8R///3338j4GARw2+tetzz94IPL97773atuWX8rGrOmdZz6gQ80kQXCu3k4e5HG+tnDfjbm8iQzGCCIUT7n9NhfHUX9jtEuPOUhD4HbLrvs0pBThLVXQlxtrCmU35zVzkOkh0iQdgpZC3ljGBPNZtxhCF/GCCGRLmFIM5/f6173agwjcI4omDYO+XcisAgIJLFfhFbIMiQCicDCIkDBjNeFWaP4gAc8oFlnqsB+M8nHRI8M2IH8D/7gDzZSRDdVYh8KXyhIIh3udKc7NQrmMoRkLqxQDlkwa7XtAcGjigwJtbV+uU30hsyu87JoY31BGDuCx/O3zCnw4bEjs8jRrIg9Mvwv//Ivzf4ct7jFLcrhhx++0eZzygLbwFn48+te97rG4IB41QfvPRKi3DEmuTfu1ybyEZb/ohe9qAmfD+IX52tssUXZa889yxfOOnuDt959iL1dGRpyL/R6zZXlDW98Y1Hm/fbbrzF0Bm7TaHt5Cff+8z//88aDHOVzXmRir9zGNu3qmMc455na2DIOEQ5kNUi5My8+kv3yl7/8am/DaLeVDRbtzxCRICFfMYeRLc/qlZTlM5/5TCPPZPE973lP4/3udf2if2+JneUrv/d7v9dEPjGM9jOOLHp9snyrH4Ek9qu/jbOGiUAiMAECdnW3kRUvhsmdxxmBp9zUpN7flDjrWClGtSIaStGm6LEPpZPXhjeIcWSPPfZocPJb/D5BE+WtPRAQVWLPB0q6tdA2zZrmUohoP48///zzywte8IJm2YUds5c5Rb2sO46Q9WkS+5B5Y4YQat5z4eX77rtvs2mf3yPV17re36KCbNQZBC5ImHHGJmd/93d/13gbY4yK+yJP4xeCIsx4o3HKeurNNis77rBDefs/va1c/tvLGnKvOGsQ1orY/893vl2eetBBzRKjo48+eqMd0uM545zVL+osOoHHXnRCXc5FJvYXX3xxs16dp5pRjYd71kQQXpI9Bw466KDGkEcWHDVu1th/7Wtf69sslppYZlZHhIR8GUPU64c//GHPPNSV4UkUB4OP6JFlTrC1N8Bf/MVfNHOXvioiQZ/KlAgsIgJJ7BexVbJMiUAisOIImNB5x6xL3HHHHZudqClNXhPkt7ZHzESfxP7qzRZKJ7x4lIQb2yXZrtc294rfr35nftNGYBSskDdrtoXP8roJxfXqKe0wSj7tMnT9LSKDp37nnXduNnfz3GVIvXDwvWNWxD6wQZCe9axnNWNLhLNrt3i+s3GlPnwnEuPpT396s0lnELjw0CJkCFyQjzVX/i6iyL2REC7h0u012VtuvkW53nW3LUccdni58Lzzm03z3BOh+M5r7Y7/6U+XPXbfvfzB3e9e3nPKKeXyHmu343mjnKPey0jskcCnPvWpzRhn2ZY3UsRr00bBYJRr4eUw/9jHhAG6TeoRfLvZe/VlLQft5zD8MdDZDDG89XFmSHrEIx7RvAKRTHblc+GFFzZRFgy43uTAML7MSR3V1aaQljIxnKmXN2dkSgQWEYEk9ovYKlmmRCARmCoCXQpI/YCu3xEgocWUZMqyEPJ6fbJ7YtIPxXtTI/aBQWDZhWP85kzJsykY5QjRtIY5iEx9XX6+CoHAN3CNcz984h4hpG9605uaUGkKOQ+vZSKxG3a/PIb9zbOEG4f311pou7bbMLGd2mWPv6O8rve5F2Fo5zfo78i/33X9rvHb+9///oEe+3559Hu2dmA4sFEe3OyE/61vfau5RZ6OGFfiHN/btfv1r3994y0Pj2wQfGcbpZ188snN2v3aABlldfbaOka2uN95C7v/b7FF2WbrrcufPOrR5ZwvnXO1KjAN/OqSS8pbjzuu3OPudy+P23//cs4Xv3gV8/dj13G1XPp/EXXvR+yf8YxnbLRkoX+OG/8aOGz87XT+Yqzx5gm70At/f9nLXrbhnfHTecLVc1GfqJNXWSLfXW9mMe7av6Ef2UZYGV2VP4xFZMpnnnsRLG9/+9ubiJD6uVEqxltjDWP4e9/73oV8VVxXubu+izo52/PCMhltaonBBz7wgZlHYtTPz8+JwLAIJLEfFqm8LhFIBJYSgVCK+xXepO66SP7mmfeKHt5lSo739nq1UJ3ivnjGKMTePUgtBR85cnbII5Rx+c87KZdwUu/xtvYX+eCtsDa7HcatfAikV1P5XX36JXVDKHg+ttlmm8ZjaIOsGvt+9y/7b/CCAZzi7HPX4fe2fIVchLz529GVhMYLvaeUC/MWSvr973+/eW7X9eN8R16FhXslFM+vwx4UQvGVSx2ibduy7O/6u8Aj7ot7o66Dylfn1XWt3yNvefo7ytbr+kHEPp4pH3lH/vF9V76+8zvSakxB6nlYjTV1/3JNrwM21jE/9KEP3YiYB7nnLT3qqKMar6IyBYZRLhEWwqW9Jz6IfUPeNtusbLnZVeT+TjvvUt554ollzZUC8K9KRsgr7Dnywx+UZxx2aLMh6Aue97zys5/8tD+xH2MYU+ZexN7YgdjXr7tTt7odoj3qs9/jusAi6jatcxD7eP+7De3gPctU1yUIqLD5aNs4M1ALsxetAZeupO96i4a+XBP7kC15WGLAM18/V17+fsMb3tDIs7czWGbS6zldz570O8+yf4Rd+c1dou3MXfZqMMe20y9/+cvyhS98oRkXYz+Edp3iHrJjg8t73OMezRIY4+m55557NQzi+jwnAiuFQBL7lUI+n5sIJAIzR8AkbcKm7FBEhEQGYUCmkFKKABLv75jUnXnrd99990a5oQDzkJncJb87/F0f8h52jb21jF7ZxMPZ63jQgx7UhOpSQOLZswINTgj63/7t3zY72N/sZjdr1hTyUPjsFX7WF1KUKKqUKG8KcD0yxxM0aDd0mKn3wQcf3CidCM0//uM/bjKeDyHUFH14Wd/c7+B1s59D4EyZ9tqlONxLPniRtFud3MNz5jWDlPPb3/72zRsZBrVPncegz7zGFF2bdVH2kQcePZEYQlXJCeX6tNNOazzR7f4lf4YBG1N++MMfbuTIe+KFh4uSeeYzn9l4nXmxB5Vbv9PHzzrrrPLa1762wY1XUp/Rd3gxlelxj3tcQThgKarANWSyK/m+F7GHL8+mSAVhy3bLt5eBd3y7h1GlV75Rb6+cE36vfXg4GbzqPu7+XofrGGmMHwhkELc4I2EIHEITeShz5O97a9cZfJBk97lny/Uee577617nOuXwww4r5593XuOER+/tp/6rtWvKJz77qbLbwx5a7rjzzuXkd77zd6/F6/LW1991Ad3jO2UNYs/4EXVztsaeV9lYon7GdYYRe3dE/2ifLUkRIm98hsWsUpvYi1CaJ7HXF3jUhd3XmPlM1mzsqr/pj+2kn9lgz1jPmK1f69NB6iM/hjx9LeQpZIzcW65mQ0X7POgjfpt1Um5kXr++5z3v2WwsybjlsKRAlAF5OeOMM5rldcYdb4bQfxiZTzjhhMao1qusUT/9xvhBHvXdZd8YcNbtkvmvDAJJ7FcG93xqIpAIzAABioZJmOJGyTjllFOaV9TxbAk7pexag0hh5Im24zKF/BWveMWGtfOKRRGzZphiwHNBSfRO5Ugx0XtefYxC7Ck9SC2yjHjFBkXOwih9h+C85S1vGUhsolzjnNWFh17orlfSRQgn5WXXXXctz3nOcxplzzuMeYFud7vbNd7Ad73rXc3mSIiFtaQ2xhtmk6hQwm1GiFSoY+15G6cO7Xuiffqd2/fM429GpOOOO655dRK5CkW5PsPfawEZPz7ykY805JdBwLIFpNdrEyno2kfINUX8O9/5zobik0eKK+VdyKgwfOHe5J18+n3SpJ2FoiIJ8q/LX39GCBiFyEZ7nTEs1ImBQj8ja8imPkkOyRX5YASxNwAZ1Z6R9HFknueaUQnZ8Go65dHPYWLzQK+ovNWtbtVgFmWDH/JiZ3jY1vlG/r7rIva8dJ7pDQOMXvKKfNXgyZriAAAgAElEQVQXkRCK3e/tA0i5cmlDBArpsDa7nfrJrzZG4BjH4vn1Wdtoo2hzZ5g582SSCZt82rAPbjbN22KzzZuzz1tteY2y5yMeWc783JkbdsRH7C9Zt6a88W3Hl9tsf/uy9z77lC+fcw5LZ3cIfk3qf9d07Wp2/k1Oe73uLjz2cHSdSAdrx0VA3OUud9lgrICH9jE+mQOQbIaiafSBzkKX0mwsp/3JL7meN7HXxowXjBxtQu5v467lAfpOO8GbXAujJxfGl65xyhxgbiVLUvQfc6TnaoNYCtJ+xjT+juc5m0cZ3WNJi/7PIMGQg+i/8IUvbAxnIu8YHY2XXgFKHsxnjBDmYUb+fsmz6AUiYWL/AWN0V7/tl0/+lgjMGoEk9rNGOPNPBBKBuSFAYeOFs7bvgQ98YKOwIgw8abyfvGu+t1uvcEOKDqWWgl+TUl4XyjaS5aAE1BO4Sd7hefVB0RnGY+8e91PCEAuKVhBdxM3GWF4Zhgy5dpYplhxQ1uBBGUY4RBEgABEtwDuPjFCcKNaUmzACUJyf97znDWWAsCGh9uHx8Czk03vu4bEMKdp93PKSM4SdZ0n9a+XbZ69X43WGE/mIRA6QVR56HktyzeuL8IY8KVNEXlA6t9tuu0Yx9ywkT37TkCdyzlvKY012EQAEilEKKXjuc5/bvHLNq7EYGHjHlEvyfIRMpAfCzWuMTPAAknf1dj2PPWWcLCL/DBO1l9HzKe0UegQqcFSOP/7jP24iFJAM/Yp86ueuI7Oudabo24dA9EE7wbIm9ggOwwojoPIomzwZ4Bgv9An5er5nGnN6vb9buDNjIbzc+5KXvKQhFp5Zy1X83etszwSRHfIhS/WhrvJFet0Pd+0vcgnhUXb9GQELEshTLxQfwbfW3sZ4fv/NpZc2r7lD43500YXlsGcdUW58s5uWZz/72eUnF/24lLXrBofij9i9lbcfsVf2ekxWN33hxBNPbGRCWzCaGOvJoI069b1pyH9bVuq/a499EPsu+arvmfRzW2bU1ThhTX0tE/GZ15nRq74PLvGqO/Kgvx144IEbGUnifuOP8R6pltzLa84YblxiBLaUa9bJXM+ox7gVfUA/ZZT4t3/7tw1LW0TfGWMYW/Rb44FxhYzof4zn/aIqov+p57HHHtsYt2HBMCbSpsZx1nXO/BOBQQgksR+EUP6eCCQCS4EAxY6y79VLlFZKjdBLr/dBREy+SOpJJ53UTMys+kgqIoIghcLnWiRDmLPJm8IuhBfhiBQTvbP74kA8ut5jLx+E3evuXOP6uJfy+uQnP7lROmzQJ6SUkuEa1yrPrFKQ7LbX7za3uU3z7l5eQc+HLWJGQYZXKHgUI58pSsN67NVbmDivrHuRIEriJAlWDA8UNB6yYQ6vMBznID/kbNyk/hRvoaqIBwwCR2ceJGHjtaEpZAVRRKYoo4ceemiz50P8pq0QYornXnvt1ZD6aCcEg7LNUyVkdVBo+yh1kx8ijdDqTwxm9eZ5yheHfMkc8rXDDjs0dRcyjBCQL9dJ2jM2AaOwU9ZFdsTmcpEPA4HwWuutGTGivjAUfstrbemDMQB2ysWbz5gQuCPrvPDtpCw1sVcOfZhByjrbv//7v2+WQPD0hSFCP4gyCPG1VEFd6oRoMyboY66NZT5R/8DAPYFbr7M9P5B0hCXqE883bqkrUhNJWfQ98sGgZtxjLLIXA+8lYo/Ub2FZheiDG92oHHXkkeWiCy+MLJpohd0f8pBy5112Ke9429vKpcZF7aaamq/XsSGH4T4oa69QfHVj/NT+dUL0GDMYjBwMTMKnY/wPHOt7pv15pYh9yI2z8VrbekuFPqlvkgtnY4x5Bol3XSRGEdFZZJxXWj2Mp2GADbmKfPbee+9mDb3naSuyKLSdPJsLjHGzTMYw0Xfmo3r89DeDonEmMFFP86p5rr7W52GIfV0P4fciqtx785vfvMkXdpkSgUVBIIn9orREliMRSATGRsDEjSDb0AahN+FSUtphtoiycMF73etejaJD6eGZrt/tS1GnFPFgU2KQIq+k6iLYFIf6cE0vYk/RPOaYYzYi9sqH4CEiyhRe1QAi8o6/p3mmjHklFgWtVnZ4MoU/87jAK4wL6iYaAXGDS9zj8yjEXh2QDc+FPyXdcggEY1zCiRRR5uCIgMnXuddBwQ0lVz1GOXhpJnmdmzZVXiST57fGEZYMTkg4slgn7SWKQ8g5xVJ9fRcHQwCSTYElZwg+zz9jkrO/hZx6r3Y/71T9zGE+23zKWn5lhzvZqYl9Ow8KP8Kl3bUB8iGkHCb6ccg8YuGd2QgnjHgCEe12Ip/6jd9dJ08Gk/DakSkYydu1yqbPhwxrTwardlKOmtjLm5fPngK8gfB2jeRsDLGsRr4OY5BXnbVl2hIh9WKIgJdoh2jLdhkG/a1Pin4hD/HcOMNBNIPf1VtCdpA15Ac+5EUeljrccaedGmLvdXfI/VZbbFmutdU1m93x//MrX2nu/+1vLi3Hvfkfy8477Fges+9+5YtnnV3W2JsEQeS1l7qI/VW/DPV/tL/2CmKvT0S9nIPY89i7XvuKPLIhIHkS9SKyQnSC3+aZVoLYd9XP+K2NYRdjjLOD7MGHoTuSfmxPGYY2ck8ujDei1chS4B95kTnGgZAtz3M/7GPZT+Q97bM2N8+aQxjpol7Oxs6IRnBdJFFh5lh9rr4esTcuDjsm0h9i3DZXisyZ9lKyKHOeE4FxEEhiPw5qeU8ikAgsDAIUQJ486xqFCCIC1lpGGGw9ufNq8vBR5k3urn3Sk560kYLD+m7NnrwoMyZ+HtReCqL846AM8YjxFIYi5OxZQeyVgRJh0zChxELalYcnoE0CZgkyAwYPrtDEuqyUPpEOlOKaaKkj5c1Shvp6n2FkmUPtZe5XduuPkSCKEW8somWTNfiNkyiXlFFkihKKgMm76/C8IP6uHfYIg4FIA6HUkyZGHZ6tdrgsWeFNFQJd44GUMThRnHmvyY/2IZe1/MEivvdbfbhu2qmL2PfCx/ORMWHUcNcWSCZjBGIvRV0QYPiQT5ggHDz97QQjG/VZUytP7cRbjqzra7BwTRwiO8i3PB28ePY9aCflqIk9mUFcvAUgylif9WlEPvoT8im6og7Ddj3ZNz4hXOqPJNSv0WyXY9DfjHPIjLqov3OMOQxuDIf2M4AD7C0xEi1g+ZF11uRDhNK+++xTrrPNtcs1GMTW4+izV9p98NQPlHVr15Yf/uAH5dBDnl62v+1ty989/wXlxxdcWNZeceV6Yr/2KlI/qMADfg9MlbcfsReloT7KbwmHsUy/sXeC8Gzj10qkRSH25JEBjWG6lgmyQZZFoUU0hzGDUYQx22sXyagk1J4M20uiPeaTc1ErZMv9yLG+xJhg1/1ox1m0AYOEZ2trdQm5F7mi7cl1+/mMcfqa6+ERx6jEntEgNtWFibEYjp6XKRFYBASS2C9CK2QZEoFEYCQEYhKl1CHwFBiTOiKHJPJEtZN7kAfEXigtZUDYIUVA8jtlkkcRoQhFJgi5Zw1K7h9E7F0jhNQaYoq39c88Zoj2sMR4UDkG/a6uwo8pJXCIujpbxlCv+a3zorDZwbu+3udRiD0ceaMpkMiN5wsNtRlftGv9zGE+yxM5sfEahVXedirvOuy87nCNUOVhD9czAjFgIFOTpiCk7Q3oKJzIPk8QwhIJiUFmhMZaahChpuruGBe7yH/c8yjEXjmDhCH0+iwPuD7pt0jqgthbohEh9q5n2Ggn/YlRKAxO8ONlJA/yDEIfZ/3b+n4Yu5bsWpLRxs/fNbE3tmh/yzD81j4Y5WwGGOG+SDsDQqxDVm5lsMRA1AUDhGse/OAHN4Yiv42alEEINMMjo5Y8g7DoV/In3wiya0UriLhh+PDGgsAHEWIAuOlNbtIQe/c65IUY+u0XP/95OetzZ5ZHPvwR5U4771zec/IpZd2VPPVr1x/rvfWjVqJ1feCqXQcRe+MoQ6woBGOIMHB7PsA88olz6zEz+5P3lvFE1Ajs5rF5Xq/K8JyLCNGO9Zjtbxvc2XCQ8Uu0G2MTo6G+EKHl5MO4HKHn7TyMiYwA5MfYJGJK32q/FrZX+cb93jMt/wl5J6s+M1ipszope8g3GRCpRDeYlNgzDFrKEs9m6NWvGDcyJQKLgEAS+0VohSxDIpAIjISAiVpiueepQUZN7jay4m2P8Nt2prxnSDRlnpJi8ywTfiSKAEMBUhVKDGXBmliK5qDkmi5iLy9GBEoTQh1eEF494YReV+bZ81BCPQOJsOmP+ocCH/VFHK15phy1E0LLWxHXxnkUYu/5yBGvbYRReiav6TjkJsroXuuXZ32QrWFkIcrV7xw4II2BpbM2QVSRwJAJ7cXjhLRaEqG+8VvITr9nzeq3UYi9Migzb6LoD+QSeavD2l0DY2HANu9CkOBBRmyA2U7a4vTTT2/eehGklrHA/X6DU30gIbx9vJCUc2d/w7BOytkm9gcccECzZCTwDvyd1cH+C9b2a0Ok+i//8i8bA0XkS/m3jAPBUFbX2PyubdiI64c5q1us+/XcIHEwk38s8UHW1JMBwJIlER+SssOp2SkfCVyfR2DJ+PbY/fcvZ5/5+XL8W95a7rD99mWvPf+4nMN4ahg2FjfHdIh9XaZ+xN7mkN6TbpmJ/RrUF4nVZnBWL+0UbTUMlr2uYYwSFcYz2++wHMPGmMZ0uJFdhJcsWusvD+f4bC5AquPQJnWER6/yDPO9+nsO4y0yW48vPosUE2HC4y6knrGHkUlESo0ZEm0Dwq48LH8R4m7O0+cYABgCGB1nlZQt9g/Q5iGn+jLjTrxJJNpe//DZ+GmZ0KTEnmHQvhz6lufHfgURcTSreme+icCwCCSxHxapvC4RSAQWAgEKi8NEiuDE7tLC6ikglBmKqmvq5G+eHN5oEzLFiwIW6+P87j5kS1h/KEK8QDbp8dug5JouYk/5YHyw4RmjAaWKYkAZoWhbc0vxbpd50PPG/Z3iZe2tugURiPoiJvWrjOpnTIPYyy+8z0HshVQynoTXY1441HVbic8IrvXlPGWBf5zJi1czMbBQvinhvNYhK8oLJ0etiM+7HqMS+67yqYN68vQhFrx+DBtIdyjuyFs/Ym+zy7h2GGLPm2ocmDext2wg3sjBoMN7b8zQhuMmZNOu37WByNhijBEVxIttbTBCwlMrsoDxJBL8kUuRLO7ZjIe38vLebdddy+tf97ryjEMOKTe+4Q3L8448qvzi5xeXZl39Gh776nV3kekQZ8/tSr43lvYi9pZJiUSwjwrjZIxhluDwIossMpZMq18gi9oJiRt0kFOyBX/lEnEiisO46hwHQ5XD9fq130UY6U/TSDBk+BbNwZMe40qclQ9WjEo2nDUGmZvaGxIylIpgs8lp4Bx5GL9Fc4hKIFfmX+WfFu5dOJALUVNRnujzzgwNluDQDdRfOaZN7C3x0I+ifeGW77Pvaqn8bqUQSGK/UsjncxOBRGAiBJAdYfQIPQUdObRW10TelUz0SL9Qbdcj1EL45ROKJGWQV0VIdygvkxJ7CgcvgXJaw0jR83zfUUQp45QiHrMgtl3ln+Z3PFCwohxFPeNMUbYZWZdyhth7FVJcG+dRPPbqwTNlV+sg9nDheaOQdT13mnVfhLxC3tS3Wd+8775Xw5ThyaaCSBuPn88UV2vvYSTJJ46VqtekxF5deMEYmhAby2SE2eqbiEf0bwSoay08RZ/HfhRiz7gnFF8/RMLm5bE3NvHYdxF77ThusozH7v8RiWTMQTyMMcYXrzezrMFmesgXeQq5ibPN5xiPLD3a3PKcLTYvm/GIbrlFudVtbt2EH9/rnvcq97jb3cu7TjqpXHrJr8taUSOIfZ+yt+ulvRgVgny1fw+57kfs1c3YFQbSGIecfYeIImBdeY+DMS+0MVqfHHTAnFw5tENdtn6fXcujzLM8raT+vcLxlcUyMG0uasT8aQ8L7VIneSDLrq3r4zMjkKVZDGmi5fTZ2NumzmMan6MtzZHxFgdliEN9LGtihIkIIGPLrIm9iD5RgLWhbBr1zTwSgXERSGI/LnJ5XyKQCKwYAiZ3Yco2nTOhI8gPf/jDm1f0hALQLpx7rIWLDXcixN7E755QAuzOftBBB21QyILYB5lq51v/TRnt8ti3FTrKCMWPguoQki/EnadpHqk2irTLFqGF6tvGclbEHsaWKVDIup47D0xW6hm81AxUCGa7LRB5SqPQU949RilGkWgX5zhWqvzjEnvlJofC1/Vdxh0EwzIQfVAkDc+cTbr0ldVM7O3wHW06Tjsad5Cv2LQzxhe4IZrIOmJqx3jREHDXz9wX/a3J4yMfKfe6z33KFtfYcj2xR+43L1tfa+uy3fW3a0LLeSuNA8j8urVXyV9XmaM+IjGQPXVkvBGF4nVqNjMzJnfJr++Up5fHvt1P4u8g0zzg5CqMB13lG+U7Hlmh6qI7Bh0MRsZzc5KD8ZIxl4Gq30HOyb/IisBulDL2upahWiSGMgVOcVY2xh59z2amloR1Jf3R2FNHhIRsydch4sAyCO02ixSYaFORBbAMUu+sTjbQtHEnmXM92Z41sde3yFoS+1m0euY5DgJJ7MdBLe9JBBKBFUPAhC1s3Vp6yoUJnZeGRwox7JV4Bb22jseFgsIo8JnPfKa5XJ6hCNjV+PDDD9+gBAWxH0ZhcU0vYk8R4d3gPbNpGGUkiD3lm0LoffaxNKBXPabxfRB7a0BDyYtzm9jDJdKsiD0jyyTEXhlhT4mj1Flq0G+tvXWswuAHHa6TF6XNQb4cYQwKXCY5KzeDE4+YNggl1WdkH5HiuWaQ8uq6ICshs3GepAyT3DsOsVdnkQjWH1tyEN4+ETWBrf4au+Lr5wwb9tNoJ3kti8ceka1D8Xk8vSoQ6Z00wc7mfsYSMgSzOGKcsQY9XkVGbhCfIPaef+63zi1PesqTyzWvtXXZbPPNfkfu1xOneK3lBedf0OyS389TLz/PsNmYaAJjnygp5TPGKEdc03yo/nOfdu1F7NVPHvqGs3pGv3GGq9B5JJk8jZuUQzLfWKpg/Bt0WHMuKgLZNS/xLltegjTHWvqus98Z7aZNEMmcV9vBPsb4OMNKeyincPp6s84aM2OpPOwTE/c6B+bw32effZo9D+r7pvk52sL4Z+PZmLuiDMqD2BtLZ03svYVCn/Js47Kla/10j2nikHklAoMQSGI/CKH8PRFIBBYOAQqQNaUmVkoF5U4IHiW1nSgEJt3YfAypRqIpIpRhyTXupUzajZtHKRQYyox3gAfhCAWj/Rx/u78XsUde5YMIeSVQlF35Q/H2LKGRytvvOV3PHuU7xJ7nLJSjqKuz14p5r7a6KENdjmkR+/Yaex4jr1uihNZEY9g6UfZEOwjn9xov7Wcteq/D2lyHTQwHHYxBlHNn+WlDu/rXuAxbzl7XBR4ISa2okg3kHvlFjGLTPPlE28S5V96z/n5UYq99bZzHA8jIFuSHQc1v+hk58HcQe/3D2mS7n7cTOV0mYm8cineDa2+fGRgnlSekzNgRBI4cBfnQr2Ft0zzeVynkBubR535z6aXlFa9+VbnxTW+yMbHfYvMmPD/eTHDZby8ra+2I/zubX7tZNjwj8jYu8kgzqlpqwZgRY0z7ZmXzWy9ijzTbfNPbT6wh1z/qMUzdeckPO+ywZj+Pdv7D/l1jFHJJNhHHrsNvohMYrBhyefcZ42a5mdwwdUF2kd7AqB5jfGczR9cof6/klYzxurjIJ84iE4488siZvmIw+gfcjcXwjefHmeFKOdXD9TGeOE9j8zx5ek2p+Vvf8lxL12w+aA7KlAgsAgJJ7BehFbIMiUAiMDQCJlcKHTLP20A5pph4v2xXoiDyGlG2hB4GWWL1pyS0lUsKMpLpWhO3davIYigLXc+I7+TVj9jH+7p57bxzmYJVE3t1EUlgt/BZJpsqee9w1xp7EQqUUZ4jWDsiTYvYM6jYxwDZUH9hwsJdPYsSNmqiVPEAMhDIr624huI36Zky5/VG2m+aiUfshBNOaDzXXWXUTowKZDPaI9omztMszyh5jUrsGeUQLkalIHkMFtEXESgHglQTe5tUkdl20ueWhdgrq0iFAw44oAnT1t9tEohUTZqMT4yb5DP6AHl1+Dv6db3reshOnNeuW1f+7d9PLw988G5li/XEpfHcb75Z2Qoh33PPZgmU9hm1n/KeM2LY+M5YrH09tyv5Hlb9iL2oKtFNYSRisFXXuu8j/P080V3Prr/bgMt6o68yhXy2z/D3HSOdzVfJN6OcaIUa8zr/eX3W58ic8db4AqPAiZFEe7imV4KDTWWN2XBuj1GWyVguNMt6RlvA2YZ9DILtcjCe2w/BfOD6WRB7uoRoEH3K8/VfRgNtnykRWAQEktgvQitkGRKBRGBoBHizvX+X0kaRszbRDsk2S+pKCKrN4Ez6JmITMgJop/uuhPRa5xs7lVPOeGyHmbgpfoOIvWfGa/rsVqw8oYA7U5yE61MgKCezSOpiLSKFLBS8UJLgyRtmMy2pLkMQ+/Y9o2yeJz/edV47xM7BG21Dr/bzmi+G+I8iZ/2uNo5Q5KjPNM/aZxbEngKKoAjxbGNLPqydJsN1gmN91L/N8/MoxF55rQW31ls99S0ETZRMKOEUd0dN7GEg5LXus/KS9LlRib3N8jxbvs7Dbp4X77FX1hp7n41L1tqKeFE3pL39ujvlFYkgSkQ/I6uWYBjPJklRFjua25QSeSb3yhEHUm1saqe4N77/4Xnnlb865OCy1dZbX7WJ3mabNXldf7vtmt3wf3zRReWKNVeWtetGM8AJV+bdNOaJehnk4VQuxN6GijzCdT9GRsMbj0zq+3DUnuob1/pbf/3oRz/ayEnUcdhzYFOftX3XQQ59z9iA2EdkGGJvyc9KJhiJZtKH4BM4+WyNOFLOsNYrqZt5VF3a4fiwFv1m/ILTrFK0gbIw8IngiXaOswiJN7zhDcVmkq7XHuY6n6fhsVc3rzS0WWBgaK42L3pWpkRgERBIYr8IrZBlSAQSgaERoKRQoFnsKSYUc5vdIcvthCDwBrKwIxPWiFKmeYjj/fUUcso2r6lEwfEKIJZ4CgPPPW9HP8Unnkvp8Dzvjg5lI85IJ499pFDCKak1sacw8NBS/q3t7EoUFeWhHDur5zCGhzov4eTIda0IKytCYt0vD00oR3EfQu5dx8ob9XIeldjbCd4u5tqCAswTFK/788xRE9y9b9k6fd4cG4S98IUv7HnYlG3Ug/dYntZ5izgYp5z96hWb6FFOYapdHOTD5lfz2HuhX/l6/YbY61/KGoYP64zrBCuHPioapO67CJrwVr8HYdKe+oddtnk+5d322Af+rh2F2FuGgsjDWXmNH3bJbyvm8rcZmE3Bol8g9jyykt/rwzjijQUiiZRXPzrwwAObutVYGL+QD+OBvm7vAK+fm0YyDpDPMGJGH2VEsOEYY8mg9Ktf/6q84U1vKLe/w+2vCsdfT+x33mmncvIJ7yhrrri8rGv+ITL6qnOv46q+fMklvyovf/nLmvHX2Ihot/HuKhfjZkT2RF2c9QmvDtUWxkBtag24qARtCv+4nuHQGyVmuTEpOVAfZ/3UfGTesORrpYm9Mukjp5122oYxN0gpnBh8zFmDkjxEXcS8GPgyIgmNV2/PmmaK8UCe8o66mLu95jbKEGcRCSLx4pV9cb2zfQ6UPQy/6u4wd1niM6zxhYHAkgQYNs874ojy3e9/r6wt6zbqBdNFYpqoZl6rHYEk9qu9hbN+icAqQ8B6RWHbJmQTM8WcAh0e5qguwitk/ylPeUqztpMXGomkcHvdFKXQZM6ThDghm6FsIvquN3FTDK0N9d2gRPmhJMXu1KFwOLeJPSJunWkoKOpCWXAo453vfOdGSW8bFCjvNlqiwKjH3nvv3UQY8HqOkn72s581Yapd6+x58r36SH0oRZIzEueZdb18HoXYqzcl02vN1NmaYEsdQjEepQ71te6HjQNmszjkrfwhJ/XzJ/kMW/kiqO11rLxsiKC2WMSEMNksjNySBcRWnwq5gZW2gJ0N8RhdEB5tr38hXeS5rp/r9Q35UsSRNf2H1xFOkTc83NeL2Hu2393j7Ljooos2lGEQsbe8gwde3ZTDJoYMXpIy1AdiLww4ohGMG9a0d5Fp8m/5kOfrO96KgPBPIyFfjG/RR+GsTeybUePW+1nrymfO+HR56MP2KFtthSRvVrbYfLOy7z57la98+UsNfVlT1hXH2qvRmW6C/+1vf6sceOBfNOOv6Cqe+EFJm/GE2kuly2MfxJ6suNbeAcbskK2ovzNDEsPcqGPkoDLWvwe25olFIvZRxiiX8Z48kwvzoT0KzAXDJMbHgw8+uLkv8GX4msXmcYFnlCv6mj6tD4uiY6hXjyiLz+ZeS6VinHC9e0Wo2WdgUmJ/8rtPKXe6852b10De4pa3LMcdf3z51SWXbETqw+QVZc9zIjBPBJLYzxPtfFYikAhMjACC4FVJvDMmdEof7y+CEcqAa4QGUiL9xsMfr7CjzFDQKTqUXaSdF5FiHcoDwi88kUKIZAvzRB56pXgu4uA1fBTpUDbi3Cb28hIyKOy/veGVZ/L48KYgOJSTSLxYyh9EijIjnJKnWn7DJmVlzKhJgLKGwodwCTuMusEHcbGMIa6Luo1C7IV0Cp1FWN3vdUve7R0K2LDlb18XbSefIHHTPst70nJ2lVs5lZ+nicIa+zsgfsI+w9sYbdHOYyX/FvnBMEZmyaRQXR7xkEVKuM2l7BuB2PsN+XKtgxEJYWeYUz99134ZwthdBwMyycNunwFLblyLZITBILyRriNTMLO0o5aF+Izc2ejLOCBvz0Bu/F4nZWFAVD5kQP28Eszrw/wWcuCzA7F/+9vf3oQIy5fRwlsuwntY5+27pz3tac3YZZM3ZAkxJQeTJOVQP8sbggwrN3KsnSTX9E/rygUXnFee85xnlRvc4Hplq2tsXm5y4xuUo476mxtuuqwAAB8PSURBVHLhRReUK8vacllZW65oyH3bT/k7Yr9u3VX0/4orLyuf+vTpZffdH9IsP4A9mYiyBI5xjrLBgiHRzveMJDHWOPMSP/WpT212mUfg3Ot65K3L8OgeBFRkxKw2sgtcg0ArI9kKj338HvWb9xk+lkAYv6OfmNdET+hH/VKUXd80X0UUi/7LsGyuHSfJNw73++wZjO6MfeSkbt9oZ9+ZMxjH9E3tq04O0Rz2DDBPhkwZi0R0mHOUOa51NneN4rG3Z4P5Vj5k7TOf/WxZY15oxa0M6mXj4JX3JALDIJDEfhiU8ppEIBFYGARM/pRUhD2UPcoxciHc7pxzzmk83cLudtttt2b9KmK01157Ndeb+K3pFn67xx57NOcIw5M3ZYDigFy4zgQeO3L7vZ3iHmebmwm3V54oW5xFFgg7Rko8Q6Js8UrxTAYx8jzEIEhHrOuN5yLjvPmUksibcsMbIURR2bvKGffXZ6HRNm2z23UoO/F8Sqk136eeemqzPhH5sYRBueK5cR6F2EcoNGUdgbWGFlkbtsx1+evP7neEMhd/z+pcP3vSz8ooMXowngg71x4MS8gsj1pdj0mfN837tSfZIPPKTD4YtnzHk2fNtzW4yD3jEGMaskx2XE8OGOnImnBxBiXybXNJ66MtSwnZ1A8Z6xDmY445pulLltAg1MiGZ7tWNIg9CfSvOKLO+pt1seG5I4PWRLc968qKCFkTrm/KWzQF8oh81HImb4YGr9yEg2vVi2GOB73ddsLHjz/++A3GrVj/HuNClHWcM+Iq78CY0dBu+eozOOk/V5bLLru0nHjiO8pOd9yxbGmPh3vcrbzv/e8pV6y5olxR1pTLyppyRVlb1vTx2CP2a9ddWX5z6SXlHe94W9l5l52b+lofbbwV2WSphXHZOGz5jyVP2k2bIpsMKzYTDfzh6vA3mZKH9oUv7LSBJTY8ucax+nAPIyZCOIjIDsap9xWLSuyVmNE55k14MJ6de+65DX69a7TxLwzND3/4w5s2YDwi83AfNWkzbacvaW9GZKSZHCDs2src8LKXvayJxGBAYBAmx9ra3MVoYkzQlx1kQ5uba0OWGP28AUV/0Cf9HuOJ8yjE/mc//Vk5/BmHlhte//rlutfaphz9N88t5593XlN1I3hN7q+uKYyKUF6fCIyHQBL78XDLuxKBRGAFETCpW0sa65GDYJrYEXfhhpQPr5GiOFAaeObjOpM7zyKlpL2OPRQOhIUnkaJujaqQfh7HdnK9Z1CQjj766A2huPGsOHsmkiAfm2VRwC0VEFKKlLQVDkqH75C7etdihgvh+xSZyNsZGeRNQexHSUijTcmQe/nEc0P5iWfwcConEqZcjvhtWGJPIbMrOPLmXmHL1iVTtOE4SXL/PI9JytrrXuWHDw8rfJEahHgUY02vvGf1vbLxxvP+6X/kJuQi2hjRpLxrf/0kQpXVMeQtlHPK973vfe9mKQjDgFdY1Uo7QmKdNjLPq3fcccc1a2dDafdMsmrd/zvf+c7Gc0e+eO2QbN5x8hoyrMzWufMk8xDzeDuLLFAnnlfPd71XbJFda+952BF0/YexzesjGSMiX2fjk9f66e+xuac2RmgYDv0mb32P1xBGkyb5I18IkjIwbloXDPth0po1V5Tf/vY35eyzP1/223fvcq1rXqPs/chHlLPO/Fwpa9c0RwTib7yquKY1PPmiD9aViy/+eTn66CPLdttdr/FwirZSRuSet5gB1rjIgBk4aQN4MFYaz2tM4zPyxiBCtuzRILyfV7bfPfKCyzReL9gLy17Evtf18/yeUZlxWf8QQfamN72pc2+afmWSB2Mj2dZvkG3z3ziJHJh/GY8RefOBOZm3Xb/ydhoRXfqdPuI6fUciz+TEMi6e+Bg/4hzjkP5NH4iNG2OMivmtk9ibimI6ciba60r50tlfLHs+9BFlm62uWe77h/csp3/ik2XN+rrHZdEL4vZxcMl7EoFJEEhiPwl6eW8ikAisCAImdQoUZdoaWIoKzxtlj7fQekqbqQUhEtqHQPNCO3gEeeMoKZSLOEJp8DcywCNEeeSZ4K0Wju+3dqLg+42H3/Pj8BwHpUI5fY+shUEBqbUmkELTdbjPPTz6SIlE4REV4HveON4p5OP2t799Q9CVZZQES5EGdivnFZEfLNXZQSmiwDEuWJ7Q3jwJkRqW2AtXRoqEg2oznlfK2ajGiK76RRvO69xVhml8R9Gl0FJkedQWddM8dYW1PvPTn/60IVhkWx9kCPPWCiSKYaIOfyafiLBQdHKlPzKekTsknncNsSYrvOgia/QDsu7Qx/QbRI43D8nXt1yjDzE+8c75jqwie17lhVAymCAK+k5c7zr3yccabR5lss64oM/rv66PfqyMPMw2aiS7omREC+nH8oxDnvKWB680UhLkGm48jwxqSImwfW3dFbY/jkwpF28446W6tKMR+udpPLSO+YJy9FHPLdvf7jbluc/+63LBeT/aQOzLOuQqKEy/85ryzW9+ozz2cfuXbba5Vnn84x+3/rWk68r5F5xXXvziFzUGV2NxbKCobCKylBvmcAxM6zbTPxzGdddbVy1sv74G/vXhN8TfOEa+ZpHaxJ6cDBctMYvSbJynOc3eKSJaGL4YgMjiqElUkbYxLzE0j5OHZzK2MeDsuuuuTb9laAhDuzz12Qc84AFNdIB5uF6Wpi+ZN8xdDIC77757Mz4YS0IfMA7pf7HpaexfEqTeuS+xB816eC6/9PJy/JuPK7vscMdy4+1uUF70vBeUC3/4I4NgA5//656w/rZRoc3rE4GJEUhiPzGEmUEikAisFAI8BZR2m1wJKeeJsS7P9yb+UDjiOp5FygJv2zBkUmSAdZkUZB4KynIv4uxZSI58Bx21gj/oWr/LN+oCa/VRT7uzq/NjH/vYxlsojLW+blC7uLa+ngLKmMFwgFAhRZQ4XmTkjJfR+mUKEc9ZeGaHJfZw561liKBc2j3d8wOPQeXdFH7XtiJMeKRn6VmcNpbRxxCsj33sY00dYolL+1nanHfaenWh7UgvwxUCinCFTJJ7ijvywJtrqY2oGX3CNX733H59KPoOGfO537XR14a9LmR3mOtrGY/6iV6w6zsDGm8/HKTIt43bsH8rj7BryxVg1mvM6s7PmLCmXH75b8uXvvSF8ta3vLmc8dlPlcsvu7T53m+l8cbXNKb7s2s/+cmPl/vd777lute9Tnn+848uF1/80/L97/9vef4Lji6Pecyjm3btItmBgXN9wLE+/Bapvq7f57h+FmdGZJu5ig5g5NIG04jEmFZZzZeiXIy9+hYsawyHeQ5jo0gJeZgjx0naXB6I9/9v795i5arKAI6rWNHDJVG8FQS0gFipoJFEKhpIjBdulhQL5WLqg2l4kgZbSwyUJhCJgrENvBgkPBRJW+UiITxAIgmEay8v1jRRWk0DFgkRggHPrWeZ/x4+us50Tudy9szsmfOfZrKnM/uy9m/vObO/vdb6Fr+vJJCMVi2sj3Lxt4HWabTSoUsPtlHW/PgyLzcJOOe5OcBvFzf9uQFI7T9/Iw433F3DPvacVvE8kNLfdr+Uln7/snTUkSPpu9/6dnr2qafTgax1HLPm34KDZ2UnOi6jQOcCBvad27mkAgpUUCD/wY/X7RYzv3jgQoiaZZr6UlsXid7aXWc35ueChvwB9E+m3zCBQruP2Nd8uZne6zSwZ31ceHHzhdp6moFy02CmwC8vy1x8jRfBmY9akBvnI9MIRGIanw2iFTcSaI5O6wBayZBFn+8wx579i33sdN+wyZ+trYeQpJb4blpkQ3/6KW6otB7Y01f/zrs2phM+c3xasOBz6e67f5t27NyW1qz5aVq58sfpySf/3NX+7q3tb7lzResVulyRu4Hfi0Y3Lsrdantr6/Q7w3Jxbra3xYNzc04TaBO0U4POTS1uhHCTL3+Qb4TWM7S+oTUPrTqozWf5KEOc24f7nsQ8rQb2EaBzltOpjU4Gb779v/TL2zekE09ekE77/Onp/vt+n96u6zYTy0Vwb2CfH01f91LAwL6X2m5LAQW6IsAPezz4IY8f+vhRj8/amcZ6uAihCSBNAWk2TGZsagF4xPqZ9uNB0iISY1H7TSIhLiAJFjp9sB9x0cR64v+8x2v6NJO7IJoytlpjz7pofk3TbJpTk/k9MmN3Wta5sBzm8RyG/Y19Ycp3lCfnFk2E8/M2ny9/jUH8f9A9Yj+oNaXrBU3yuelFAjG6CMX3MObrdH/DufXl8xCl9pqEevFsFtjXPq/9PX7llZfTqlU/SUcdNZLOOedrae0Na9Ill1yUrrpqeXr+BUb76PxvVev709s58eY3gyd/j5lW7cE5FY/8dbw305R52Z/4bZhpvmbv0+2CXBcE7AT3jzzyyHs3P6I8tARYvZqRGWpd52ixQ8sTvhdsP74fcX4zZdl4nynPWF97gf1UmkhTRVD/3/HR9MCjf0pf/+Y30gknnph+cdtt6V+vvJKmsmsO9jf/1nD2HxRupuHnCpQrYGBfrqdrU0CBPgjEjzeb5nX8yM+2KLFeLtCoeSGZFk3yyd7NxTfbyS8eZru9dpan9oIaDYJ6+gbHcFlR5nbWdbh5Y31MqbHnBke7TfHpMkCrBxIB0hSfVhA+5p4A51D9My7MZ3o/vssxXz7NlxlkTZogkwSMYbT4G0MeCm52xL6yn7171IcoBEe1Wnqm8Xp6w+Oop4ykebXAfseO7WnpZZemefM+mI477mPpuI9/NL3v/e9Ly5b9IO3a9Zfe7ZJbKlVgtucjeTf43SJ/C79dcaM8LyR5NmJUGm6mx9CrEbAzje8H0/h//E3IP+O91gP7qVRLCjmVxiZG0zPPPZ2+d+F30ic/9Ym0es3qovvb+OhompqsneNR5vpvTS+/sVEGpwogYGDveaCAAgq0IEA/SRLMMQQXGehJ3EWtQlxItLCKUmbhAmbPnj1p/fr1RSIwaj5oxsj7s73galZAhgojSRGZhck+3KzGnjKRxJAmqdRIchEXQX23y9psX/y8/wLx3Slj2v+96bwE7D+J8xhVg1p7AhrygVBDSYDS2+9KfYgSQXstqD9YIx/vH5zyGUPcMXY9mfUfeuiBdPbZX01HHvmhtGjRF9NZZ30pjYx8JC1c+IV0//33pcnJ4aux7/wsmBtL0v1qzZo1Rf4BhqqjH3x9DghasfD7RkJYhrtkhApGqWn170Qe1Mf3JwL7Zlnxa9+1AylNjqddO3ekH115ZTrt5JPSuht/nv6xd0+RBX9yfMIa+7lxug7kXhrYD+Rhs9AKKNAPARLIccFNpl4yMtNPnL7jvXxQk0cm7quvvrpIzJRnk+5GObgwIkCn+SMXR2QPr2+KH+Ot59mfWWb37t1FDT2ZqRlOjIzRPhTIBeJiPd6L/7czjWUHecr+ks2eG4b8bSHzPq2E8i4K/d0/ajJr/+r73kft/cEafXJqvJk2bPhNcaPilFMWpI0bN6R77vldkQH9mGOOLpro79v3z/7uklvvuQCJWBm9gJEgGOKObm48OP/zIPz8888v8toQ3JP1nt895onHTH8fYl0xb0y5Kc+oHSR9jd8vpiQ4JFksNxxinZRj584d6aorl6evfPnM9Os7fpVe3revlizvwFRKPA8WJYrkVIFKCBjYV+IwWAgFFBgUAS4wyNLN8FQk06OPe32NQzf3hYsPEguRpIlpLx4EF9QoUnPChVDU1MeU4YVoLsmwU1wU0Q+TCziGoqLpPiML0HUgLrJ6UWa3ocCgCfDdoYsPgQyjT1x88cXp8ccfL75T1duXQ2v2a7X5tYiHEQ5ooUNSQFr5cFNw1193pRUrfphGRj6czj13cXr00UfS+PhYceOQv6H83eCGIA4+hlOAURoI6Ml0zzCQ27dvL25eRb95Mt/T1Y3+98xDXhay3fN5p78fjKTBMJrkd8mDeoJ8kuIytCKt3uImGr9dK1asSBdddGH6wx+3pjffeKNWQ28wP5wn5ZDtlYH9kB1Qd0cBBbovwIUnyd/oC0tTwl5nPWb7vbj4ZRsMbcQQQoxZzLB2BPNcHEVQz2suwLgQu/TSS4txkmlFwDjjmzZtStu2bSsOSNSGdP/ouAUFBlMgviN87+jCwpjjzzzzTBHsVnOPpgf3U1ME5LU8CnzvGSudwH7lypVF4ETXpY0bqcU/KR119Eha87PV6dVX9xc3KAneqL3t1c3KanoOf6kYCpNRIAiquXEVgT03zAnA77zzziLwJwg/9thjiwR6/Aa1++C7RIsx1nfBBRcUSfjy3yx+t6L2nub+y5YtK5L4cY7S5WzLli3F8lVMftiuhfPPLQED+7l1vN1bBRQoUYCLh7jLX+JqW1oV2+72g4saxlKnxo2xhufPn5+OP/74Yhqv+T9Jv3jSZ5JxuQnqCU5Yvhc3ILrt4PoV6JVABPdsj9prnlV+5KE95aT8fOe56XnmmWcWyUYZU5xuTDTk37b9xbRkySXpiCM+UCRQ27xlc1Gbv27duvTggw8WgX0v/rZV2XSYy0bLDWrsydGyaNGitHnz5qKVCq29brzxxqKZ/hVXXJEWLlxY5LKhmTytvdp98L0hSR8txsiJQ5P+Rk9yv8T7a9euLXLAROsBz8N21Z2/CgIG9lU4CpZBAQUUqKgAFzn0P3z99deL5v9M40mz4fxJ0iNq3CI44QI/nl4kVfQAW6xKCcR3J59WqoDNCjM1lci1ceuttxbdds4444y0devWYilq9N966810110M7/fZohk0wR35BG6/44706mv/TgcYOaHZNvx8YAXookELDjLij4yMFDlbCORJSrt48eJivHqaxnMj+bzzzivyTFCb384jvjsE99xQ4veLXDjUxtc/eT8+Z16W8beqHW3nrZqAgX3VjojlUUABBSokwEUOFzsE6DHNg/W4iIppXvR4L5/mn/taAQWmC+TflXg9fY4K/Y8IPI/C331N8HbDDTekU089NV1zzTVFc+vavnCjbyLt2fP3dP31q9L8+Z8u+j1fd911xZBnkZqvQntoUUoW4Dyg1p6+8wwdS1cNgvylS5emJ554Iu3cubPo9kXeluXLlxdDrPJ7w3KtPhrNWzv/Dh1uM38/fuMaLd/qtp1PgX4LGNj3+wi4fQUUUGAABDq52MkvmgZgFy2iAgrMVoCm+JOTRd4Rau7JP0LAVHsQWNG1YCq98cZ/0vPPP5uee+7ZotVP8feluFHQegA326K6fO8FOM6cD7T0Ig/DU089VeSToLk97z/88MPFMK4E9nTP2L9/f1tBff0e5b9BrL/+WZx32UL1/88+8qUCAyFgYD8Qh8lCKqCAAv0V6OSCJ7+o6m/p3boCCpQtQAhOyE6ozpPX8Wy8rViCuQzgGxvN3XdpCk8/e5LZnX766UXOhbKS1+W/RfWvc/H8dy7myz/3tQJVFzCwr/oRsnwKKKCAAgoooEDFBAjNCegn3n3mwX3jokZgn0+nz5kHVtM/8X/DIjDTMSaB3pIlS4qm+UxfeOGFrLXHsOy9+6FAdwUM7Lvr69oVUEABBRRQQIGhE4jAPmrsWwvsWYre9IfW2s8U8A0dnDvUUICh8EiixzB01157bXrppZcM7BtK+aYCMwsY2M9s4ycKKKCAAgoooIACDQSi3j2a3+fTBrP7lgIzCrz22mvppptuKoZNZfx6hkjkPbPUz0jmBwo0FDCwb8jimwoooIACCiiggAIKKNAtAYL3xx57LK1ataroVz9v3rxiGLzLL7883XvvvWn37t1pdHS0W5t3vQoMnYCB/dAdUndIAQUUUEABBRRQQIHqCpChfu/evWnTpk3plltuSevXr08333xzUXPP6w0bNqQXX3wxvfPOO7PKjF9dAUumQPkCBvblm7pGBRRQQAEFFFBAAQUUOIwAeRUmJiam9aXnPZrgE/ibd+EweH6kQAMBA/sGKL6lgAIKKKCAAgoooIAC3RU4XPB+uM+6WyrXrsBgChjYD+Zxs9QKKKCAAgoooIACCgy0gMH7QB8+C18BAb5D8TSwr8ABsQgKKKCAAgoooIACCiiggAJzV2B8fDyNjY0VXVToptLsGfOzDE8D+7l77rjnCiiggAIKKKCAAgoooIACfRYgrwTBeeSXiFr4dqYG9n0+iG5eAQUUUEABBRRQQAEFFFBg7gqQNJIaeAL5Th8G9p3KuZwCCiiggAIKKKCAAgoooIACHQhEEM80r63vYFXFIgb2ncq5nAIKKKCAAgoooIACCiiggAIdCNDsngdT+tNHoN/BqopFDOw7lXM5BRRQQAEFFFBAAQUUUEABBToUIJinCT5N8Q3sO0R0MQUUUEABBRRQQAEFFFBAAQX6JUBAX0YzfMpvjX2/jqLbVUABBRRQQAEFFFBAAQUUmLMC1NbzjGb5s4EwsJ+NnssqoIACCiiggAIKKKCAAgoo0KYAwfzo6Oh7Q9y1ufghsxvYH0LiGwoooIACCiiggAIKKKCAAgp0T4CEeWXV1lNKA/vuHSvXrIACCiiggAIKKKCAAgoooMA0gRjijj72ZT0M7MuSdD0KKKCAAgoooIACCiiggAIKzCAQme/z2voy+tezOQP7GdB9WwEFFFBAAQUUUEABBRRQQIEyBaK2nuCeoN7Avkxd16WAAgoooIACCiiggAIKKKBAFwUI6mOIO6YE9VGLP9vNWmM/W0GXV0ABBRRQQAEFFFBAAQUUUKCJAEF8NMOPwL7JIi1/bGDfMpUzKqCAAgoooIACCiiggAIKKNCZADX0DHFXZtK8KImBfUg4VUABBRRQQAEFFFBAAQUUUKBLAtEMv6x+9XkxDexzDV8roIACCiiggAIKKKCAAgooULIAzfAZt56m+GX1q8+LaGCfa/haAQUUUEABBRRQQAEFFFBAgRIFCOSprSew70ZtPUU1sC/xgLkqBRRQQAEFFFBAAQUUUEABBeoFCOp5dqO2nm0Z2NeL+38FFFBAAQUUUEABBRRQQAEFShIgmO9W0rwoooF9SDhVQAEFFFBAAQUUUEABBRRQoGSBbtfWU1wD+5IPmqtTQAEFFFBAAQUUUEABBRRQAIEY4q5bfetD2cA+JJwqoIACCiiggAIKKKCAAgooUKIAWfC7lQk/L6aBfa7hawUUUEABBRRQQAEFFFBAAQVKEhgbG+taJvy8iAb2uYavFVBAAQUUUEABBRRQQAEFFChBgOb33cyEnxfRwD7X8LUCCiiggAIKKKCAAgoooIACJQj0ogl+FNPAPiScKqCAAgoooIACCiiggAIKKFCCAEPcTU5Odm3c+voiGtjXi/h/BRRQQAEFFFBAAQUUUEABBWYhQDN8ngT4vXgY2PdC2W0ooIACCiiggAIKKKCAAgoMvUAE8jTD7/YQdzmmgX2u4WsFFFBAAQUUUEABBRRQQAEFZiFAE/xeJc2LYhrYh4RTBRRQQAEFFFBAAQUUUEABBWYpkNfWRw3+LFfZdHED+6ZEzqCAAgoooIACCiiggAIKKKBAcwGa3xvYN3dyDgUUUEABBRRQQAEFFFBAAQUqJ0Dt/NjYWE/71geCNfYh4VQBBRRQQAEFFFBAAQUUUECBDgXoWz86Ompg36GfiymggAIKKKCAAgoooIACCijQVwGa4Pc6aV7ssDX2IeFUAQUUUEABBRRQQAEFFFBAgQ4FCOp7OcRdXkwD+1zD1woooIACCiiggAIKKKCAAgq0KBBZ76mt5xn/b3Hx0mYzsC+N0hUpoIACCiiggAIKKKCAAgrMJQECeZ55Jvx+7L+BfT/U3aYCCiiggAIKKKCAAgoooMBQCND8vp/N8EE0sB+KU8mdUEABBRRQQAEFFFBAAQUU6IcAQT0Z8fvVDJ99NrDvx5F3mwoooIACCiiggAIKKKCAAgMvQDDfr7HrczwD+1zD1woooIACCiiggAIKKKCAAgq0KNDvvvVRTAP7kHCqgAIKKKCAAgoooIACCiigQIsCUVtPM/x+Pwzs+30E3L4CCiiggAIKKKCAAgoooMDACRDQ97tvfaAZ2IeEUwUUUEABBRRQQAEFFFBAAQVaFOh3Jvy8mAb2uYavFVBAAQUUUEABBRRQQAEFFGgiQE09gX0/M+HnRTSwzzV8rYACCiiggAIKKKCAAgoooEATgRjirslsPfvYwL5n1G5IAQUUUEABBRRQQAEFFFBg0AWopa9SM3w8DewH/ayy/AoooIACCiiggAIKKKCAAj0RiKC+Ss3w2XED+54cfjeigAIKKKCAAgoooIACCigw6AIR2B84cKBSu2JgX6nDYWEUUEABBRRQQAEFFFBAAQWqKkBAX5Uh7nIjA/tcw9cKKKCAAgoooIACCiiggAIKzCAwMTGRqlZbT1EN7Gc4YL6tgAIKKKCAAgoooIACCiigQAhQU09gX5Uh7qJcTA3scw1fK6CAAgoooIACCiiggAIKKFAnEH3rDezrYPyvAgoooIACCiiggAIKKKCAAoMgEIF9FfvX42eN/SCcRZZRAQUUUEABBRRQQAEFFFCgpwIE89Hsnpr6qvavB8XAvqenhhtTQAEFFFBAAQUUUEABBRQYFAECe5LljY2NFdnwq1puA/uqHhnLpYACCiiggAIKKKCAAgoo0HeB8fHxxDNq7/teoAYFMLBvgOJbCiiggAIKKKCAAgoooIACChDME9RXtW99HKH/A/CQBDYFZ1quAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "4e6e1662",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![image-4.png](attachment:image-4.png)\n",
    "    \n",
    "    等价于将key和value合并起来后放入到一个隐藏大小为H，输出大小为1的单隐藏层MLP\n",
    "    好处是q,k,v可以为任意形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe423da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:17:14.826716Z",
     "start_time": "2021-08-29T16:17:14.804713Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 加性注意力\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"加性注意力\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # valid_lens就是可以考虑用q乘以多少k-v对\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1) # 维度不同，广播强行加\n",
    "        features = torch.tanh(features) # 激活\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values) # batch matmul 批的矩阵乘法\n",
    "        # 对weight做dropout，就是不看哪一些k-v pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58f5bc8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:18:08.757226Z",
     "start_time": "2021-08-29T16:18:08.732225Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 演示\n",
    "# batch_size = 2,1个query，query长度为20；batch_size = 2,2个key，key长度为2\n",
    "queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))\n",
    "values = torch.arange(40, dtype=torch.float32).reshape(1, 10,\n",
    "                                                       4).repeat(2, 1, 1)\n",
    "valid_lens = torch.tensor([2, 6]) # 第一个看前两个k-v对，第二个看前6个\n",
    "\n",
    "attention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8,\n",
    "                              dropout=0.1)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a64f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:20:51.772932Z",
     "start_time": "2021-08-29T16:20:51.499911Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"101.818906pt\" version=\"1.1\" viewBox=\"0 0 186.99575 101.818906\" width=\"186.99575pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-08-30T00:20:51.712927</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M -0 101.818906 \r\n",
       "L 186.99575 101.818906 \r\n",
       "L 186.99575 0 \r\n",
       "L -0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 34.240625 59.13 \r\n",
       "L 145.840625 59.13 \r\n",
       "L 145.840625 36.81 \r\n",
       "L 34.240625 36.81 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#pf525aada70)\">\r\n",
       "    <image height=\"23\" id=\"image5b77c41b99\" transform=\"scale(1 -1)translate(0 -23)\" width=\"112\" x=\"34.240625\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHAAAAAXCAYAAADTEcupAAAAeElEQVR4nO3YsQmAQBAF0X+aWp8tGFqDXZjZnC2YCV5uJnIcA/MKWBaGTbbcx/ZESZJxXnuv8NnQewH9Y0A4A8IZEM6AcAaEMyCcAeEMCGdAOAPClSVTk1/ofp0txurFC4QzIJwB4QwIZ0A4A8IZEM6AcAaEMyBcBc2IB/NA+hblAAAAAElFTkSuQmCC\" y=\"-36.13\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"mf5a6b3afcb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.820625\" xlink:href=\"#mf5a6b3afcb\" y=\"59.13\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(36.639375 73.728437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.620625\" xlink:href=\"#mf5a6b3afcb\" y=\"59.13\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(92.439375 73.728437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_3\">\r\n",
       "     <!-- Keys -->\r\n",
       "     <g transform=\"translate(78.371094 87.406562)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 628 4666 \r\n",
       "L 1259 4666 \r\n",
       "L 1259 2694 \r\n",
       "L 3353 4666 \r\n",
       "L 4166 4666 \r\n",
       "L 1850 2491 \r\n",
       "L 4331 0 \r\n",
       "L 3500 0 \r\n",
       "L 1259 2247 \r\n",
       "L 1259 0 \r\n",
       "L 628 0 \r\n",
       "L 628 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-4b\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3597 1894 \r\n",
       "L 3597 1613 \r\n",
       "L 953 1613 \r\n",
       "Q 991 1019 1311 708 \r\n",
       "Q 1631 397 2203 397 \r\n",
       "Q 2534 397 2845 478 \r\n",
       "Q 3156 559 3463 722 \r\n",
       "L 3463 178 \r\n",
       "Q 3153 47 2828 -22 \r\n",
       "Q 2503 -91 2169 -91 \r\n",
       "Q 1331 -91 842 396 \r\n",
       "Q 353 884 353 1716 \r\n",
       "Q 353 2575 817 3079 \r\n",
       "Q 1281 3584 2069 3584 \r\n",
       "Q 2775 3584 3186 3129 \r\n",
       "Q 3597 2675 3597 1894 \r\n",
       "z\r\n",
       "M 3022 2063 \r\n",
       "Q 3016 2534 2758 2815 \r\n",
       "Q 2500 3097 2075 3097 \r\n",
       "Q 1594 3097 1305 2825 \r\n",
       "Q 1016 2553 972 2059 \r\n",
       "L 3022 2063 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2059 -325 \r\n",
       "Q 1816 -950 1584 -1140 \r\n",
       "Q 1353 -1331 966 -1331 \r\n",
       "L 506 -1331 \r\n",
       "L 506 -850 \r\n",
       "L 844 -850 \r\n",
       "Q 1081 -850 1212 -737 \r\n",
       "Q 1344 -625 1503 -206 \r\n",
       "L 1606 56 \r\n",
       "L 191 3500 \r\n",
       "L 800 3500 \r\n",
       "L 1894 763 \r\n",
       "L 2988 3500 \r\n",
       "L 3597 3500 \r\n",
       "L 2059 -325 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2834 3397 \r\n",
       "L 2834 2853 \r\n",
       "Q 2591 2978 2328 3040 \r\n",
       "Q 2066 3103 1784 3103 \r\n",
       "Q 1356 3103 1142 2972 \r\n",
       "Q 928 2841 928 2578 \r\n",
       "Q 928 2378 1081 2264 \r\n",
       "Q 1234 2150 1697 2047 \r\n",
       "L 1894 2003 \r\n",
       "Q 2506 1872 2764 1633 \r\n",
       "Q 3022 1394 3022 966 \r\n",
       "Q 3022 478 2636 193 \r\n",
       "Q 2250 -91 1575 -91 \r\n",
       "Q 1294 -91 989 -36 \r\n",
       "Q 684 19 347 128 \r\n",
       "L 347 722 \r\n",
       "Q 666 556 975 473 \r\n",
       "Q 1284 391 1588 391 \r\n",
       "Q 1994 391 2212 530 \r\n",
       "Q 2431 669 2431 922 \r\n",
       "Q 2431 1156 2273 1281 \r\n",
       "Q 2116 1406 1581 1522 \r\n",
       "L 1381 1569 \r\n",
       "Q 847 1681 609 1914 \r\n",
       "Q 372 2147 372 2553 \r\n",
       "Q 372 3047 722 3315 \r\n",
       "Q 1072 3584 1716 3584 \r\n",
       "Q 2034 3584 2315 3537 \r\n",
       "Q 2597 3491 2834 3397 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-4b\"/>\r\n",
       "      <use x=\"60.576172\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"122.099609\" xlink:href=\"#DejaVuSans-79\"/>\r\n",
       "      <use x=\"181.279297\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"mda879e0752\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mda879e0752\" y=\"42.39\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(20.878125 46.189219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#mda879e0752\" y=\"53.55\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 1 -->\r\n",
       "      <g transform=\"translate(20.878125 57.349219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_6\">\r\n",
       "     <!-- Queries -->\r\n",
       "     <g transform=\"translate(14.798437 67.277031)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 2522 4238 \r\n",
       "Q 1834 4238 1429 3725 \r\n",
       "Q 1025 3213 1025 2328 \r\n",
       "Q 1025 1447 1429 934 \r\n",
       "Q 1834 422 2522 422 \r\n",
       "Q 3209 422 3611 934 \r\n",
       "Q 4013 1447 4013 2328 \r\n",
       "Q 4013 3213 3611 3725 \r\n",
       "Q 3209 4238 2522 4238 \r\n",
       "z\r\n",
       "M 3406 84 \r\n",
       "L 4238 -825 \r\n",
       "L 3475 -825 \r\n",
       "L 2784 -78 \r\n",
       "Q 2681 -84 2626 -87 \r\n",
       "Q 2572 -91 2522 -91 \r\n",
       "Q 1538 -91 948 567 \r\n",
       "Q 359 1225 359 2328 \r\n",
       "Q 359 3434 948 4092 \r\n",
       "Q 1538 4750 2522 4750 \r\n",
       "Q 3503 4750 4090 4092 \r\n",
       "Q 4678 3434 4678 2328 \r\n",
       "Q 4678 1516 4351 937 \r\n",
       "Q 4025 359 3406 84 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 544 1381 \r\n",
       "L 544 3500 \r\n",
       "L 1119 3500 \r\n",
       "L 1119 1403 \r\n",
       "Q 1119 906 1312 657 \r\n",
       "Q 1506 409 1894 409 \r\n",
       "Q 2359 409 2629 706 \r\n",
       "Q 2900 1003 2900 1516 \r\n",
       "L 2900 3500 \r\n",
       "L 3475 3500 \r\n",
       "L 3475 0 \r\n",
       "L 2900 0 \r\n",
       "L 2900 538 \r\n",
       "Q 2691 219 2414 64 \r\n",
       "Q 2138 -91 1772 -91 \r\n",
       "Q 1169 -91 856 284 \r\n",
       "Q 544 659 544 1381 \r\n",
       "z\r\n",
       "M 1991 3584 \r\n",
       "L 1991 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2631 2963 \r\n",
       "Q 2534 3019 2420 3045 \r\n",
       "Q 2306 3072 2169 3072 \r\n",
       "Q 1681 3072 1420 2755 \r\n",
       "Q 1159 2438 1159 1844 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1341 3275 1631 3429 \r\n",
       "Q 1922 3584 2338 3584 \r\n",
       "Q 2397 3584 2469 3576 \r\n",
       "Q 2541 3569 2628 3553 \r\n",
       "L 2631 2963 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 3500 \r\n",
       "L 1178 3500 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 3500 \r\n",
       "z\r\n",
       "M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 4134 \r\n",
       "L 603 4134 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-75\"/>\r\n",
       "      <use x=\"142.089844\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"203.613281\" xlink:href=\"#DejaVuSans-72\"/>\r\n",
       "      <use x=\"244.726562\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"272.509766\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"334.033203\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 34.240625 59.13 \r\n",
       "L 34.240625 36.81 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 145.840625 59.13 \r\n",
       "L 145.840625 36.81 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 34.240625 59.13 \r\n",
       "L 145.840625 59.13 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 34.240625 36.81 \r\n",
       "L 145.840625 36.81 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_2\">\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path d=\"M 152.815625 88.74 \r\n",
       "L 156.892625 88.74 \r\n",
       "L 156.892625 7.2 \r\n",
       "L 152.815625 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path clip-path=\"url(#pea1f345c87)\" d=\"M 152.815625 88.74 \r\n",
       "L 152.815625 88.421484 \r\n",
       "L 152.815625 7.518516 \r\n",
       "L 152.815625 7.2 \r\n",
       "L 156.892625 7.2 \r\n",
       "L 156.892625 7.518516 \r\n",
       "L 156.892625 88.421484 \r\n",
       "L 156.892625 88.74 \r\n",
       "L 156.892625 88.74 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n",
       "   </g>\r\n",
       "   <image height=\"82\" id=\"image696bf44249\" transform=\"scale(1 -1)translate(0 -82)\" width=\"4\" x=\"153\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAAQAAABSCAYAAABzJnWUAAAAm0lEQVR4nJ2SOw7CUBADHxL3vyoNBeyXFsZIFqQcje1NlMveb3venuuZPg6MMXbKdvxcqqASoDG7+TSG7xBjm5GSSLgVjXiDQO4Izvq39SsepHxC/g5/lLJDjA2C4mzKHQ5MjjF01q50obR7P0E1jYIhkZRSgmKk7UoNI8tZgiLA6hdDI0cM1yF3BE//YqA0xCB4SClB8FK5g6UvE4PMuTPJ8jwAAAAASUVORK5CYII=\" y=\"-6\"/>\r\n",
       "   <g id=\"matplotlib.axis_3\"/>\r\n",
       "   <g id=\"matplotlib.axis_4\">\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 3.5 0 \r\n",
       "\" id=\"mb6d331c347\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mb6d331c347\" y=\"88.74\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0.0 -->\r\n",
       "      <g transform=\"translate(163.892625 92.539219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 684 794 \r\n",
       "L 1344 794 \r\n",
       "L 1344 0 \r\n",
       "L 684 0 \r\n",
       "L 684 794 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mb6d331c347\" y=\"56.124\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 0.2 -->\r\n",
       "      <g transform=\"translate(163.892625 59.923219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#mb6d331c347\" y=\"23.508\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 0.4 -->\r\n",
       "      <g transform=\"translate(163.892625 27.307219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2419 4116 \r\n",
       "L 825 1625 \r\n",
       "L 2419 1625 \r\n",
       "L 2419 4116 \r\n",
       "z\r\n",
       "M 2253 4666 \r\n",
       "L 3047 4666 \r\n",
       "L 3047 1625 \r\n",
       "L 3713 1625 \r\n",
       "L 3713 1100 \r\n",
       "L 3047 1100 \r\n",
       "L 3047 0 \r\n",
       "L 2419 0 \r\n",
       "L 2419 1100 \r\n",
       "L 313 1100 \r\n",
       "L 313 1709 \r\n",
       "L 2253 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"LineCollection_1\"/>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path d=\"M 152.815625 88.74 \r\n",
       "L 152.815625 88.421484 \r\n",
       "L 152.815625 7.518516 \r\n",
       "L 152.815625 7.2 \r\n",
       "L 156.892625 7.2 \r\n",
       "L 156.892625 7.518516 \r\n",
       "L 156.892625 88.421484 \r\n",
       "L 156.892625 88.74 \r\n",
       "z\r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"pf525aada70\">\r\n",
       "   <rect height=\"22.32\" width=\"111.6\" x=\"34.240625\" y=\"36.81\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"pea1f345c87\">\r\n",
       "   <rect height=\"81.54\" width=\"4.077\" x=\"152.815625\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 180x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 注意力权重\n",
    "%matplotlib inline\n",
    "d2l.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),\n",
    "                  xlabel='Keys', ylabel='Queries')\n",
    "# 结果为前两个和前6个，由于数值一样，权重也一样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89bbf5d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dot Product Attention"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "534db512",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "    q,k同样长度时候，直接将query和key做内积\n",
    "    不用学参数，速度较快，实现简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c81669a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:23:25.332249Z",
     "start_time": "2021-08-29T16:23:25.324248Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 缩放点积注意力\n",
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"缩放点积注意力\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        # 这个注意力不需要学参数，实现简单\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        # 不需要权重，直接乘起来即可\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1b08de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:25:41.351427Z",
     "start_time": "2021-08-29T16:25:41.333426Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n",
       "\n",
       "        [[10.0000, 11.0000, 12.0000, 13.0000]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 演示上述的DotProductAttention类\n",
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "attention.eval()\n",
    "attention(queries, keys, values, valid_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b42beb0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:27:59.247334Z",
     "start_time": "2021-08-29T16:27:59.020189Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"101.818906pt\" version=\"1.1\" viewBox=\"0 0 186.99575 101.818906\" width=\"186.99575pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-08-30T00:27:59.199203</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M -0 101.818906 \r\n",
       "L 186.99575 101.818906 \r\n",
       "L 186.99575 0 \r\n",
       "L -0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 34.240625 59.13 \r\n",
       "L 145.840625 59.13 \r\n",
       "L 145.840625 36.81 \r\n",
       "L 34.240625 36.81 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#pe104ddc7e9)\">\r\n",
       "    <image height=\"23\" id=\"image7f74eece2d\" transform=\"scale(1 -1)translate(0 -23)\" width=\"112\" x=\"34.240625\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAHAAAAAXCAYAAADTEcupAAAAeElEQVR4nO3YsQmAQBAF0X+aWp8tGFqDXZjZnC2YCV5uJnIcA/MKWBaGTbbcx/ZESZJxXnuv8NnQewH9Y0A4A8IZEM6AcAaEMyCcAeEMCGdAOAPClSVTk1/ofp0txurFC4QzIJwB4QwIZ0A4A8IZEM6AcAaEMyBcBc2IB/NA+hblAAAAAElFTkSuQmCC\" y=\"-36.13\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m116e81ce95\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.820625\" xlink:href=\"#m116e81ce95\" y=\"59.13\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(36.639375 73.728437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"95.620625\" xlink:href=\"#m116e81ce95\" y=\"59.13\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 5 -->\r\n",
       "      <g transform=\"translate(92.439375 73.728437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_3\">\r\n",
       "     <!-- Keys -->\r\n",
       "     <g transform=\"translate(78.371094 87.406562)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 628 4666 \r\n",
       "L 1259 4666 \r\n",
       "L 1259 2694 \r\n",
       "L 3353 4666 \r\n",
       "L 4166 4666 \r\n",
       "L 1850 2491 \r\n",
       "L 4331 0 \r\n",
       "L 3500 0 \r\n",
       "L 1259 2247 \r\n",
       "L 1259 0 \r\n",
       "L 628 0 \r\n",
       "L 628 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-4b\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3597 1894 \r\n",
       "L 3597 1613 \r\n",
       "L 953 1613 \r\n",
       "Q 991 1019 1311 708 \r\n",
       "Q 1631 397 2203 397 \r\n",
       "Q 2534 397 2845 478 \r\n",
       "Q 3156 559 3463 722 \r\n",
       "L 3463 178 \r\n",
       "Q 3153 47 2828 -22 \r\n",
       "Q 2503 -91 2169 -91 \r\n",
       "Q 1331 -91 842 396 \r\n",
       "Q 353 884 353 1716 \r\n",
       "Q 353 2575 817 3079 \r\n",
       "Q 1281 3584 2069 3584 \r\n",
       "Q 2775 3584 3186 3129 \r\n",
       "Q 3597 2675 3597 1894 \r\n",
       "z\r\n",
       "M 3022 2063 \r\n",
       "Q 3016 2534 2758 2815 \r\n",
       "Q 2500 3097 2075 3097 \r\n",
       "Q 1594 3097 1305 2825 \r\n",
       "Q 1016 2553 972 2059 \r\n",
       "L 3022 2063 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2059 -325 \r\n",
       "Q 1816 -950 1584 -1140 \r\n",
       "Q 1353 -1331 966 -1331 \r\n",
       "L 506 -1331 \r\n",
       "L 506 -850 \r\n",
       "L 844 -850 \r\n",
       "Q 1081 -850 1212 -737 \r\n",
       "Q 1344 -625 1503 -206 \r\n",
       "L 1606 56 \r\n",
       "L 191 3500 \r\n",
       "L 800 3500 \r\n",
       "L 1894 763 \r\n",
       "L 2988 3500 \r\n",
       "L 3597 3500 \r\n",
       "L 2059 -325 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2834 3397 \r\n",
       "L 2834 2853 \r\n",
       "Q 2591 2978 2328 3040 \r\n",
       "Q 2066 3103 1784 3103 \r\n",
       "Q 1356 3103 1142 2972 \r\n",
       "Q 928 2841 928 2578 \r\n",
       "Q 928 2378 1081 2264 \r\n",
       "Q 1234 2150 1697 2047 \r\n",
       "L 1894 2003 \r\n",
       "Q 2506 1872 2764 1633 \r\n",
       "Q 3022 1394 3022 966 \r\n",
       "Q 3022 478 2636 193 \r\n",
       "Q 2250 -91 1575 -91 \r\n",
       "Q 1294 -91 989 -36 \r\n",
       "Q 684 19 347 128 \r\n",
       "L 347 722 \r\n",
       "Q 666 556 975 473 \r\n",
       "Q 1284 391 1588 391 \r\n",
       "Q 1994 391 2212 530 \r\n",
       "Q 2431 669 2431 922 \r\n",
       "Q 2431 1156 2273 1281 \r\n",
       "Q 2116 1406 1581 1522 \r\n",
       "L 1381 1569 \r\n",
       "Q 847 1681 609 1914 \r\n",
       "Q 372 2147 372 2553 \r\n",
       "Q 372 3047 722 3315 \r\n",
       "Q 1072 3584 1716 3584 \r\n",
       "Q 2034 3584 2315 3537 \r\n",
       "Q 2597 3491 2834 3397 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-4b\"/>\r\n",
       "      <use x=\"60.576172\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"122.099609\" xlink:href=\"#DejaVuSans-79\"/>\r\n",
       "      <use x=\"181.279297\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m3dc1eaeed1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m3dc1eaeed1\" y=\"42.39\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(20.878125 46.189219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m3dc1eaeed1\" y=\"53.55\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 1 -->\r\n",
       "      <g transform=\"translate(20.878125 57.349219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_6\">\r\n",
       "     <!-- Queries -->\r\n",
       "     <g transform=\"translate(14.798437 67.277031)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 2522 4238 \r\n",
       "Q 1834 4238 1429 3725 \r\n",
       "Q 1025 3213 1025 2328 \r\n",
       "Q 1025 1447 1429 934 \r\n",
       "Q 1834 422 2522 422 \r\n",
       "Q 3209 422 3611 934 \r\n",
       "Q 4013 1447 4013 2328 \r\n",
       "Q 4013 3213 3611 3725 \r\n",
       "Q 3209 4238 2522 4238 \r\n",
       "z\r\n",
       "M 3406 84 \r\n",
       "L 4238 -825 \r\n",
       "L 3475 -825 \r\n",
       "L 2784 -78 \r\n",
       "Q 2681 -84 2626 -87 \r\n",
       "Q 2572 -91 2522 -91 \r\n",
       "Q 1538 -91 948 567 \r\n",
       "Q 359 1225 359 2328 \r\n",
       "Q 359 3434 948 4092 \r\n",
       "Q 1538 4750 2522 4750 \r\n",
       "Q 3503 4750 4090 4092 \r\n",
       "Q 4678 3434 4678 2328 \r\n",
       "Q 4678 1516 4351 937 \r\n",
       "Q 4025 359 3406 84 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 544 1381 \r\n",
       "L 544 3500 \r\n",
       "L 1119 3500 \r\n",
       "L 1119 1403 \r\n",
       "Q 1119 906 1312 657 \r\n",
       "Q 1506 409 1894 409 \r\n",
       "Q 2359 409 2629 706 \r\n",
       "Q 2900 1003 2900 1516 \r\n",
       "L 2900 3500 \r\n",
       "L 3475 3500 \r\n",
       "L 3475 0 \r\n",
       "L 2900 0 \r\n",
       "L 2900 538 \r\n",
       "Q 2691 219 2414 64 \r\n",
       "Q 2138 -91 1772 -91 \r\n",
       "Q 1169 -91 856 284 \r\n",
       "Q 544 659 544 1381 \r\n",
       "z\r\n",
       "M 1991 3584 \r\n",
       "L 1991 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2631 2963 \r\n",
       "Q 2534 3019 2420 3045 \r\n",
       "Q 2306 3072 2169 3072 \r\n",
       "Q 1681 3072 1420 2755 \r\n",
       "Q 1159 2438 1159 1844 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1341 3275 1631 3429 \r\n",
       "Q 1922 3584 2338 3584 \r\n",
       "Q 2397 3584 2469 3576 \r\n",
       "Q 2541 3569 2628 3553 \r\n",
       "L 2631 2963 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 3500 \r\n",
       "L 1178 3500 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 3500 \r\n",
       "z\r\n",
       "M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 4134 \r\n",
       "L 603 4134 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-75\"/>\r\n",
       "      <use x=\"142.089844\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"203.613281\" xlink:href=\"#DejaVuSans-72\"/>\r\n",
       "      <use x=\"244.726562\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"272.509766\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"334.033203\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 34.240625 59.13 \r\n",
       "L 34.240625 36.81 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 145.840625 59.13 \r\n",
       "L 145.840625 36.81 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 34.240625 59.13 \r\n",
       "L 145.840625 59.13 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 34.240625 36.81 \r\n",
       "L 145.840625 36.81 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_2\">\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path d=\"M 152.815625 88.74 \r\n",
       "L 156.892625 88.74 \r\n",
       "L 156.892625 7.2 \r\n",
       "L 152.815625 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path clip-path=\"url(#p7e99c6f3da)\" d=\"M 152.815625 88.74 \r\n",
       "L 152.815625 88.421484 \r\n",
       "L 152.815625 7.518516 \r\n",
       "L 152.815625 7.2 \r\n",
       "L 156.892625 7.2 \r\n",
       "L 156.892625 7.518516 \r\n",
       "L 156.892625 88.421484 \r\n",
       "L 156.892625 88.74 \r\n",
       "L 156.892625 88.74 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n",
       "   </g>\r\n",
       "   <image height=\"82\" id=\"image58a166cd7e\" transform=\"scale(1 -1)translate(0 -82)\" width=\"4\" x=\"153\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAAQAAABSCAYAAABzJnWUAAAAm0lEQVR4nJ2SOw7CUBADHxL3vyoNBeyXFsZIFqQcje1NlMveb3venuuZPg6MMXbKdvxcqqASoDG7+TSG7xBjm5GSSLgVjXiDQO4Izvq39SsepHxC/g5/lLJDjA2C4mzKHQ5MjjF01q50obR7P0E1jYIhkZRSgmKk7UoNI8tZgiLA6hdDI0cM1yF3BE//YqA0xCB4SClB8FK5g6UvE4PMuTPJ8jwAAAAASUVORK5CYII=\" y=\"-6\"/>\r\n",
       "   <g id=\"matplotlib.axis_3\"/>\r\n",
       "   <g id=\"matplotlib.axis_4\">\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 3.5 0 \r\n",
       "\" id=\"m5786f96808\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#m5786f96808\" y=\"88.74\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0.0 -->\r\n",
       "      <g transform=\"translate(163.892625 92.539219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 684 794 \r\n",
       "L 1344 794 \r\n",
       "L 1344 0 \r\n",
       "L 684 0 \r\n",
       "L 684 794 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#m5786f96808\" y=\"56.124\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 0.2 -->\r\n",
       "      <g transform=\"translate(163.892625 59.923219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.892625\" xlink:href=\"#m5786f96808\" y=\"23.508\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 0.4 -->\r\n",
       "      <g transform=\"translate(163.892625 27.307219)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2419 4116 \r\n",
       "L 825 1625 \r\n",
       "L 2419 1625 \r\n",
       "L 2419 4116 \r\n",
       "z\r\n",
       "M 2253 4666 \r\n",
       "L 3047 4666 \r\n",
       "L 3047 1625 \r\n",
       "L 3713 1625 \r\n",
       "L 3713 1100 \r\n",
       "L 3047 1100 \r\n",
       "L 3047 0 \r\n",
       "L 2419 0 \r\n",
       "L 2419 1100 \r\n",
       "L 313 1100 \r\n",
       "L 313 1709 \r\n",
       "L 2253 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"LineCollection_1\"/>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path d=\"M 152.815625 88.74 \r\n",
       "L 152.815625 88.421484 \r\n",
       "L 152.815625 7.518516 \r\n",
       "L 152.815625 7.2 \r\n",
       "L 156.892625 7.2 \r\n",
       "L 156.892625 7.518516 \r\n",
       "L 156.892625 88.421484 \r\n",
       "L 156.892625 88.74 \r\n",
       "z\r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"pe104ddc7e9\">\r\n",
       "   <rect height=\"22.32\" width=\"111.6\" x=\"34.240625\" y=\"36.81\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p7e99c6f3da\">\r\n",
       "   <rect height=\"81.54\" width=\"4.077\" x=\"152.815625\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 180x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 均匀的注意力权重\n",
    "d2l.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),\n",
    "                  xlabel='Keys', ylabel='Queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9682986",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## self-Attention & position encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01bcb65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "对于给定序列X1,X2...XN.自注意力池化层将Xi同时当做key，value，query来对序列抽取特征得到y1,...yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26ddf605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:34:35.272956Z",
     "start_time": "2021-08-30T03:34:35.263955Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10166459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:36:07.363889Z",
     "start_time": "2021-08-30T03:36:07.354409Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (attention): DotProductAttention(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自注意力\n",
    "num_hiddens, num_heads = 100, 5\n",
    "attention = d2l.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n",
    "                                   num_hiddens, num_heads, 0.5)\n",
    "attention.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f902068",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:36:12.921765Z",
     "start_time": "2021-08-30T03:36:12.899765Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_queries, valid_lens = 2, 4, torch.tensor([3, 2])\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "attention(X, X, X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076e420a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "transformer中的position encoding被证明为无用功，在BERT中就发现直接输入位置信息让BERT学也有同样的效果，不需要这么哲学的变换sin与cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d905c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:36:27.634364Z",
     "start_time": "2021-08-30T03:36:27.609365Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(\n",
    "                10000,\n",
    "                torch.arange(0, num_hiddens, 2, dtype=torch.float32) /\n",
    "                num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faf2d91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:44:36.978816Z",
     "start_time": "2021-08-30T03:44:36.545769Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"184.15625pt\" version=\"1.1\" viewBox=\"0 0 383.982812 184.15625\" width=\"383.982812pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-08-30T11:44:36.881809</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M -0 184.15625 \r\n",
       "L 383.982812 184.15625 \r\n",
       "L 383.982812 -0 \r\n",
       "L -0 -0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 38.482813 146.6 \r\n",
       "L 373.282813 146.6 \r\n",
       "L 373.282813 10.7 \r\n",
       "L 38.482813 10.7 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 53.700994 146.6 \r\n",
       "L 53.700994 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"me96ca94d56\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"53.700994\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 -3.5 \r\n",
       "\" id=\"m2e529a9f88\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"53.700994\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(50.519744 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 105.288051 146.6 \r\n",
       "L 105.288051 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"105.288051\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"105.288051\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(98.925551 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 156.875108 146.6 \r\n",
       "L 156.875108 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.875108\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"156.875108\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(150.512608 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 208.462165 146.6 \r\n",
       "L 208.462165 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.462165\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.462165\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 30 -->\r\n",
       "      <g transform=\"translate(202.099665 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2597 2516 \r\n",
       "Q 3050 2419 3304 2112 \r\n",
       "Q 3559 1806 3559 1356 \r\n",
       "Q 3559 666 3084 287 \r\n",
       "Q 2609 -91 1734 -91 \r\n",
       "Q 1441 -91 1130 -33 \r\n",
       "Q 819 25 488 141 \r\n",
       "L 488 750 \r\n",
       "Q 750 597 1062 519 \r\n",
       "Q 1375 441 1716 441 \r\n",
       "Q 2309 441 2620 675 \r\n",
       "Q 2931 909 2931 1356 \r\n",
       "Q 2931 1769 2642 2001 \r\n",
       "Q 2353 2234 1838 2234 \r\n",
       "L 1294 2234 \r\n",
       "L 1294 2753 \r\n",
       "L 1863 2753 \r\n",
       "Q 2328 2753 2575 2939 \r\n",
       "Q 2822 3125 2822 3475 \r\n",
       "Q 2822 3834 2567 4026 \r\n",
       "Q 2313 4219 1838 4219 \r\n",
       "Q 1578 4219 1281 4162 \r\n",
       "Q 984 4106 628 3988 \r\n",
       "L 628 4550 \r\n",
       "Q 988 4650 1302 4700 \r\n",
       "Q 1616 4750 1894 4750 \r\n",
       "Q 2613 4750 3031 4423 \r\n",
       "Q 3450 4097 3450 3541 \r\n",
       "Q 3450 3153 3228 2886 \r\n",
       "Q 3006 2619 2597 2516 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 260.049222 146.6 \r\n",
       "L 260.049222 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_14\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.049222\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_15\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.049222\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 40 -->\r\n",
       "      <g transform=\"translate(253.686722 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2419 4116 \r\n",
       "L 825 1625 \r\n",
       "L 2419 1625 \r\n",
       "L 2419 4116 \r\n",
       "z\r\n",
       "M 2253 4666 \r\n",
       "L 3047 4666 \r\n",
       "L 3047 1625 \r\n",
       "L 3713 1625 \r\n",
       "L 3713 1100 \r\n",
       "L 3047 1100 \r\n",
       "L 3047 0 \r\n",
       "L 2419 0 \r\n",
       "L 2419 1100 \r\n",
       "L 313 1100 \r\n",
       "L 313 1709 \r\n",
       "L 2253 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_6\">\r\n",
       "     <g id=\"line2d_16\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 311.636279 146.6 \r\n",
       "L 311.636279 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_17\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"311.636279\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_18\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"311.636279\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <g transform=\"translate(305.273779 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_7\">\r\n",
       "     <g id=\"line2d_19\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 363.223336 146.6 \r\n",
       "L 363.223336 10.7 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_20\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.223336\" xlink:href=\"#me96ca94d56\" y=\"146.6\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_21\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"363.223336\" xlink:href=\"#m2e529a9f88\" y=\"10.7\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 60 -->\r\n",
       "      <g transform=\"translate(356.860836 161.198437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2113 2584 \r\n",
       "Q 1688 2584 1439 2293 \r\n",
       "Q 1191 2003 1191 1497 \r\n",
       "Q 1191 994 1439 701 \r\n",
       "Q 1688 409 2113 409 \r\n",
       "Q 2538 409 2786 701 \r\n",
       "Q 3034 994 3034 1497 \r\n",
       "Q 3034 2003 2786 2293 \r\n",
       "Q 2538 2584 2113 2584 \r\n",
       "z\r\n",
       "M 3366 4563 \r\n",
       "L 3366 3988 \r\n",
       "Q 3128 4100 2886 4159 \r\n",
       "Q 2644 4219 2406 4219 \r\n",
       "Q 1781 4219 1451 3797 \r\n",
       "Q 1122 3375 1075 2522 \r\n",
       "Q 1259 2794 1537 2939 \r\n",
       "Q 1816 3084 2150 3084 \r\n",
       "Q 2853 3084 3261 2657 \r\n",
       "Q 3669 2231 3669 1497 \r\n",
       "Q 3669 778 3244 343 \r\n",
       "Q 2819 -91 2113 -91 \r\n",
       "Q 1303 -91 875 529 \r\n",
       "Q 447 1150 447 2328 \r\n",
       "Q 447 3434 972 4092 \r\n",
       "Q 1497 4750 2381 4750 \r\n",
       "Q 2619 4750 2861 4703 \r\n",
       "Q 3103 4656 3366 4563 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_8\">\r\n",
       "     <!-- Row (position) -->\r\n",
       "     <g transform=\"translate(170.189844 174.876562)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 2841 2188 \r\n",
       "Q 3044 2119 3236 1894 \r\n",
       "Q 3428 1669 3622 1275 \r\n",
       "L 4263 0 \r\n",
       "L 3584 0 \r\n",
       "L 2988 1197 \r\n",
       "Q 2756 1666 2539 1819 \r\n",
       "Q 2322 1972 1947 1972 \r\n",
       "L 1259 1972 \r\n",
       "L 1259 0 \r\n",
       "L 628 0 \r\n",
       "L 628 4666 \r\n",
       "L 2053 4666 \r\n",
       "Q 2853 4666 3247 4331 \r\n",
       "Q 3641 3997 3641 3322 \r\n",
       "Q 3641 2881 3436 2590 \r\n",
       "Q 3231 2300 2841 2188 \r\n",
       "z\r\n",
       "M 1259 4147 \r\n",
       "L 1259 2491 \r\n",
       "L 2053 2491 \r\n",
       "Q 2509 2491 2742 2702 \r\n",
       "Q 2975 2913 2975 3322 \r\n",
       "Q 2975 3731 2742 3939 \r\n",
       "Q 2509 4147 2053 4147 \r\n",
       "L 1259 4147 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1959 3097 \r\n",
       "Q 1497 3097 1228 2736 \r\n",
       "Q 959 2375 959 1747 \r\n",
       "Q 959 1119 1226 758 \r\n",
       "Q 1494 397 1959 397 \r\n",
       "Q 2419 397 2687 759 \r\n",
       "Q 2956 1122 2956 1747 \r\n",
       "Q 2956 2369 2687 2733 \r\n",
       "Q 2419 3097 1959 3097 \r\n",
       "z\r\n",
       "M 1959 3584 \r\n",
       "Q 2709 3584 3137 3096 \r\n",
       "Q 3566 2609 3566 1747 \r\n",
       "Q 3566 888 3137 398 \r\n",
       "Q 2709 -91 1959 -91 \r\n",
       "Q 1206 -91 779 398 \r\n",
       "Q 353 888 353 1747 \r\n",
       "Q 353 2609 779 3096 \r\n",
       "Q 1206 3584 1959 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 269 3500 \r\n",
       "L 844 3500 \r\n",
       "L 1563 769 \r\n",
       "L 2278 3500 \r\n",
       "L 2956 3500 \r\n",
       "L 3675 769 \r\n",
       "L 4391 3500 \r\n",
       "L 4966 3500 \r\n",
       "L 4050 0 \r\n",
       "L 3372 0 \r\n",
       "L 2619 2869 \r\n",
       "L 1863 0 \r\n",
       "L 1184 0 \r\n",
       "L 269 3500 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-77\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1984 4856 \r\n",
       "Q 1566 4138 1362 3434 \r\n",
       "Q 1159 2731 1159 2009 \r\n",
       "Q 1159 1288 1364 580 \r\n",
       "Q 1569 -128 1984 -844 \r\n",
       "L 1484 -844 \r\n",
       "Q 1016 -109 783 600 \r\n",
       "Q 550 1309 550 2009 \r\n",
       "Q 550 2706 781 3412 \r\n",
       "Q 1013 4119 1484 4856 \r\n",
       "L 1984 4856 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-28\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1159 525 \r\n",
       "L 1159 -1331 \r\n",
       "L 581 -1331 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2969 \r\n",
       "Q 1341 3281 1617 3432 \r\n",
       "Q 1894 3584 2278 3584 \r\n",
       "Q 2916 3584 3314 3078 \r\n",
       "Q 3713 2572 3713 1747 \r\n",
       "Q 3713 922 3314 415 \r\n",
       "Q 2916 -91 2278 -91 \r\n",
       "Q 1894 -91 1617 61 \r\n",
       "Q 1341 213 1159 525 \r\n",
       "z\r\n",
       "M 3116 1747 \r\n",
       "Q 3116 2381 2855 2742 \r\n",
       "Q 2594 3103 2138 3103 \r\n",
       "Q 1681 3103 1420 2742 \r\n",
       "Q 1159 2381 1159 1747 \r\n",
       "Q 1159 1113 1420 752 \r\n",
       "Q 1681 391 2138 391 \r\n",
       "Q 2594 391 2855 752 \r\n",
       "Q 3116 1113 3116 1747 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2834 3397 \r\n",
       "L 2834 2853 \r\n",
       "Q 2591 2978 2328 3040 \r\n",
       "Q 2066 3103 1784 3103 \r\n",
       "Q 1356 3103 1142 2972 \r\n",
       "Q 928 2841 928 2578 \r\n",
       "Q 928 2378 1081 2264 \r\n",
       "Q 1234 2150 1697 2047 \r\n",
       "L 1894 2003 \r\n",
       "Q 2506 1872 2764 1633 \r\n",
       "Q 3022 1394 3022 966 \r\n",
       "Q 3022 478 2636 193 \r\n",
       "Q 2250 -91 1575 -91 \r\n",
       "Q 1294 -91 989 -36 \r\n",
       "Q 684 19 347 128 \r\n",
       "L 347 722 \r\n",
       "Q 666 556 975 473 \r\n",
       "Q 1284 391 1588 391 \r\n",
       "Q 1994 391 2212 530 \r\n",
       "Q 2431 669 2431 922 \r\n",
       "Q 2431 1156 2273 1281 \r\n",
       "Q 2116 1406 1581 1522 \r\n",
       "L 1381 1569 \r\n",
       "Q 847 1681 609 1914 \r\n",
       "Q 372 2147 372 2553 \r\n",
       "Q 372 3047 722 3315 \r\n",
       "Q 1072 3584 1716 3584 \r\n",
       "Q 2034 3584 2315 3537 \r\n",
       "Q 2597 3491 2834 3397 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 3500 \r\n",
       "L 1178 3500 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 3500 \r\n",
       "z\r\n",
       "M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 4134 \r\n",
       "L 603 4134 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1172 4494 \r\n",
       "L 1172 3500 \r\n",
       "L 2356 3500 \r\n",
       "L 2356 3053 \r\n",
       "L 1172 3053 \r\n",
       "L 1172 1153 \r\n",
       "Q 1172 725 1289 603 \r\n",
       "Q 1406 481 1766 481 \r\n",
       "L 2356 481 \r\n",
       "L 2356 0 \r\n",
       "L 1766 0 \r\n",
       "Q 1100 0 847 248 \r\n",
       "Q 594 497 594 1153 \r\n",
       "L 594 3053 \r\n",
       "L 172 3053 \r\n",
       "L 172 3500 \r\n",
       "L 594 3500 \r\n",
       "L 594 4494 \r\n",
       "L 1172 4494 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3513 2113 \r\n",
       "L 3513 0 \r\n",
       "L 2938 0 \r\n",
       "L 2938 2094 \r\n",
       "Q 2938 2591 2744 2837 \r\n",
       "Q 2550 3084 2163 3084 \r\n",
       "Q 1697 3084 1428 2787 \r\n",
       "Q 1159 2491 1159 1978 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1366 3272 1645 3428 \r\n",
       "Q 1925 3584 2291 3584 \r\n",
       "Q 2894 3584 3203 3211 \r\n",
       "Q 3513 2838 3513 2113 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 513 4856 \r\n",
       "L 1013 4856 \r\n",
       "Q 1481 4119 1714 3412 \r\n",
       "Q 1947 2706 1947 2009 \r\n",
       "Q 1947 1309 1714 600 \r\n",
       "Q 1481 -109 1013 -844 \r\n",
       "L 513 -844 \r\n",
       "Q 928 -128 1133 580 \r\n",
       "Q 1338 1288 1338 2009 \r\n",
       "Q 1338 2731 1133 3434 \r\n",
       "Q 928 4138 513 4856 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-29\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      <use x=\"64.982422\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"126.164062\" xlink:href=\"#DejaVuSans-77\"/>\r\n",
       "      <use x=\"207.951172\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"239.738281\" xlink:href=\"#DejaVuSans-28\"/>\r\n",
       "      <use x=\"278.751953\" xlink:href=\"#DejaVuSans-70\"/>\r\n",
       "      <use x=\"342.228516\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"403.410156\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "      <use x=\"455.509766\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"483.292969\" xlink:href=\"#DejaVuSans-74\"/>\r\n",
       "      <use x=\"522.501953\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"550.285156\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"611.466797\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"674.845703\" xlink:href=\"#DejaVuSans-29\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_22\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 38.482813 140.422727 \r\n",
       "L 373.282813 140.422727 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_23\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m2c5436e534\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m2c5436e534\" y=\"140.422727\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_24\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 3.5 0 \r\n",
       "\" id=\"m657aae9ef8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"373.282813\" xlink:href=\"#m657aae9ef8\" y=\"140.422727\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- −1.0 -->\r\n",
       "      <g transform=\"translate(7.2 144.221946)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 678 2272 \r\n",
       "L 4684 2272 \r\n",
       "L 4684 1741 \r\n",
       "L 678 1741 \r\n",
       "L 678 2272 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2212\" transform=\"scale(0.015625)\"/>\r\n",
       "        <path d=\"M 684 794 \r\n",
       "L 1344 794 \r\n",
       "L 1344 0 \r\n",
       "L 684 0 \r\n",
       "L 684 794 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_25\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 38.482813 109.536364 \r\n",
       "L 373.282813 109.536364 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_26\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m2c5436e534\" y=\"109.536364\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_27\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"373.282813\" xlink:href=\"#m657aae9ef8\" y=\"109.536364\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- −0.5 -->\r\n",
       "      <g transform=\"translate(7.2 113.335582)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_28\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 38.482813 78.65 \r\n",
       "L 373.282813 78.65 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_29\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m2c5436e534\" y=\"78.65\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_30\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"373.282813\" xlink:href=\"#m657aae9ef8\" y=\"78.65\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 0.0 -->\r\n",
       "      <g transform=\"translate(15.579688 82.449219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_31\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 38.482813 47.763636 \r\n",
       "L 373.282813 47.763636 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_32\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m2c5436e534\" y=\"47.763636\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_33\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"373.282813\" xlink:href=\"#m657aae9ef8\" y=\"47.763636\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 0.5 -->\r\n",
       "      <g transform=\"translate(15.579688 51.562855)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_34\">\r\n",
       "      <path clip-path=\"url(#p352238ddd7)\" d=\"M 38.482813 16.877273 \r\n",
       "L 373.282813 16.877273 \r\n",
       "\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_35\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m2c5436e534\" y=\"16.877273\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"line2d_36\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"373.282813\" xlink:href=\"#m657aae9ef8\" y=\"16.877273\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- 1.0 -->\r\n",
       "      <g transform=\"translate(15.579688 20.676491)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_37\">\r\n",
       "    <path clip-path=\"url(#p352238ddd7)\" d=\"M 53.700994 78.65 \r\n",
       "L 58.8597 67.722887 \r\n",
       "L 64.018406 57.140411 \r\n",
       "L 69.177111 47.236334 \r\n",
       "L 74.335817 38.323035 \r\n",
       "L 79.494523 30.681626 \r\n",
       "L 84.653229 24.553116 \r\n",
       "L 89.811934 20.130798 \r\n",
       "L 94.97064 17.55415 \r\n",
       "L 100.129346 16.904434 \r\n",
       "L 105.288051 18.202142 \r\n",
       "L 110.446757 21.406352 \r\n",
       "L 115.605463 26.416001 \r\n",
       "L 120.764168 33.07308 \r\n",
       "L 125.922874 41.167644 \r\n",
       "L 131.08158 50.444371 \r\n",
       "L 136.240286 60.61069 \r\n",
       "L 141.398991 71.345975 \r\n",
       "L 146.557697 82.31161 \r\n",
       "L 151.716403 93.161775 \r\n",
       "L 156.875108 103.55423 \r\n",
       "L 162.033814 113.161231 \r\n",
       "L 167.19252 121.679753 \r\n",
       "L 172.351225 128.841136 \r\n",
       "L 177.509931 134.419532 \r\n",
       "L 182.668637 138.238964 \r\n",
       "L 187.827343 140.178994 \r\n",
       "L 192.986048 140.178427 \r\n",
       "L 198.144754 138.237281 \r\n",
       "L 203.30346 134.416781 \r\n",
       "L 208.462165 128.837425 \r\n",
       "L 213.620871 121.675187 \r\n",
       "L 218.779577 113.155955 \r\n",
       "L 223.938282 103.548393 \r\n",
       "L 229.096988 93.155575 \r\n",
       "L 234.255694 82.305258 \r\n",
       "L 239.4144 71.339656 \r\n",
       "L 244.573105 60.604589 \r\n",
       "L 249.731811 50.438698 \r\n",
       "L 254.890517 41.162574 \r\n",
       "L 260.049222 33.068787 \r\n",
       "L 265.207928 26.412588 \r\n",
       "L 270.366634 21.403955 \r\n",
       "L 275.525339 18.200831 \r\n",
       "L 280.684045 16.904247 \r\n",
       "L 285.842751 17.555089 \r\n",
       "L 291.001457 20.132831 \r\n",
       "L 296.160162 24.556179 \r\n",
       "L 301.318868 30.685658 \r\n",
       "L 306.477574 38.327873 \r\n",
       "L 311.636279 47.241832 \r\n",
       "L 316.794985 57.146389 \r\n",
       "L 321.953691 67.729157 \r\n",
       "L 327.112396 78.656364 \r\n",
       "L 332.271102 89.58337 \r\n",
       "L 337.429808 100.165543 \r\n",
       "L 342.588514 110.069177 \r\n",
       "L 347.747219 118.98181 \r\n",
       "L 352.905925 126.622402 \r\n",
       "L 358.064631 132.749966 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_38\">\r\n",
       "    <path clip-path=\"url(#p352238ddd7)\" d=\"M 53.700994 16.877273 \r\n",
       "L 58.8597 17.851415 \r\n",
       "L 64.018406 20.743112 \r\n",
       "L 69.177111 25.461171 \r\n",
       "L 74.335817 31.856777 \r\n",
       "L 79.494523 39.728223 \r\n",
       "L 84.653229 48.827242 \r\n",
       "L 89.811934 58.866859 \r\n",
       "L 94.97064 69.530417 \r\n",
       "L 100.129346 80.481611 \r\n",
       "L 105.288051 91.375035 \r\n",
       "L 110.446757 101.867119 \r\n",
       "L 115.605463 111.626952 \r\n",
       "L 120.764168 120.346695 \r\n",
       "L 125.922874 127.751351 \r\n",
       "L 131.08158 133.607369 \r\n",
       "L 136.240286 137.730057 \r\n",
       "L 141.398991 139.989392 \r\n",
       "L 146.557697 140.31411 \r\n",
       "L 151.716403 138.693971 \r\n",
       "L 156.875108 135.180073 \r\n",
       "L 162.033814 129.88324 \r\n",
       "L 167.19252 122.970538 \r\n",
       "L 172.351225 114.659995 \r\n",
       "L 177.509931 105.213683 \r\n",
       "L 182.668637 94.929594 \r\n",
       "L 187.827343 84.132052 \r\n",
       "L 192.986048 73.16161 \r\n",
       "L 198.144754 62.364239 \r\n",
       "L 203.30346 52.080543 \r\n",
       "L 208.462165 42.634835 \r\n",
       "L 213.620871 34.325029 \r\n",
       "L 218.779577 27.413207 \r\n",
       "L 223.938282 22.117357 \r\n",
       "L 229.096988 18.604534 \r\n",
       "L 234.255694 16.985514 \r\n",
       "L 239.4144 17.311359 \r\n",
       "L 244.573105 19.571806 \r\n",
       "L 249.731811 23.695543 \r\n",
       "L 254.890517 29.552518 \r\n",
       "L 260.049222 36.958003 \r\n",
       "L 265.207928 45.678453 \r\n",
       "L 270.366634 55.438792 \r\n",
       "L 275.525339 65.931199 \r\n",
       "L 280.684045 76.824751 \r\n",
       "L 285.842751 87.77587 \r\n",
       "L 291.001457 98.439163 \r\n",
       "L 296.160162 108.478317 \r\n",
       "L 301.318868 117.576744 \r\n",
       "L 306.477574 125.447395 \r\n",
       "L 311.636279 131.842073 \r\n",
       "L 316.794985 136.559108 \r\n",
       "L 321.953691 139.449712 \r\n",
       "L 327.112396 140.422727 \r\n",
       "L 332.271102 139.447462 \r\n",
       "L 337.429808 136.554675 \r\n",
       "L 342.588514 131.835571 \r\n",
       "L 347.747219 125.439044 \r\n",
       "L 352.905925 117.566818 \r\n",
       "L 358.064631 108.46717 \r\n",
       "\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_39\">\r\n",
       "    <path clip-path=\"url(#p352238ddd7)\" d=\"M 53.700994 78.65 \r\n",
       "L 58.8597 72.483017 \r\n",
       "L 64.018406 66.377654 \r\n",
       "L 69.177111 60.39491 \r\n",
       "L 74.335817 54.594566 \r\n",
       "L 79.494523 49.034576 \r\n",
       "L 84.653229 43.770494 \r\n",
       "L 89.811934 38.854918 \r\n",
       "L 94.97064 34.336958 \r\n",
       "L 100.129346 30.261763 \r\n",
       "L 105.288051 26.670044 \r\n",
       "L 110.446757 23.597689 \r\n",
       "L 115.605463 21.075404 \r\n",
       "L 120.764168 19.128382 \r\n",
       "L 125.922874 17.776083 \r\n",
       "L 131.08158 17.032014 \r\n",
       "L 136.240286 16.903613 \r\n",
       "L 141.398991 17.392159 \r\n",
       "L 146.557697 18.492776 \r\n",
       "L 151.716403 20.194463 \r\n",
       "L 156.875108 22.480219 \r\n",
       "L 162.033814 25.3272 \r\n",
       "L 167.19252 28.706975 \r\n",
       "L 172.351225 32.585753 \r\n",
       "L 177.509931 36.924803 \r\n",
       "L 182.668637 41.680745 \r\n",
       "L 187.827343 46.80607 \r\n",
       "L 192.986048 52.249581 \r\n",
       "L 198.144754 57.956865 \r\n",
       "L 203.30346 63.870922 \r\n",
       "L 208.462165 69.932633 \r\n",
       "L 213.620871 76.081443 \r\n",
       "L 218.779577 82.255933 \r\n",
       "L 223.938282 88.394379 \r\n",
       "L 229.096988 94.435477 \r\n",
       "L 234.255694 100.318837 \r\n",
       "L 239.4144 105.985689 \r\n",
       "L 244.573105 111.379426 \r\n",
       "L 249.731811 116.446127 \r\n",
       "L 254.890517 121.135197 \r\n",
       "L 260.049222 125.399754 \r\n",
       "L 265.207928 129.197206 \r\n",
       "L 270.366634 132.489605 \r\n",
       "L 275.525339 135.244073 \r\n",
       "L 280.684045 137.433057 \r\n",
       "L 285.842751 139.034702 \r\n",
       "L 291.001457 140.033001 \r\n",
       "L 296.160162 140.417985 \r\n",
       "L 301.318868 140.185802 \r\n",
       "L 306.477574 139.338775 \r\n",
       "L 311.636279 137.885369 \r\n",
       "L 316.794985 135.840102 \r\n",
       "L 321.953691 133.223409 \r\n",
       "L 327.112396 130.061424 \r\n",
       "L 332.271102 126.385767 \r\n",
       "L 337.429808 122.233148 \r\n",
       "L 342.588514 117.645067 \r\n",
       "L 347.747219 112.667358 \r\n",
       "L 352.905925 107.349734 \r\n",
       "L 358.064631 101.745375 \r\n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"line2d_40\">\r\n",
       "    <path clip-path=\"url(#p352238ddd7)\" d=\"M 53.700994 16.877273 \r\n",
       "L 58.8597 17.185878 \r\n",
       "L 64.018406 18.108613 \r\n",
       "L 69.177111 19.636258 \r\n",
       "L 74.335817 21.753551 \r\n",
       "L 79.494523 24.439332 \r\n",
       "L 84.653229 27.666768 \r\n",
       "L 89.811934 31.403611 \r\n",
       "L 94.97064 35.612526 \r\n",
       "L 100.129346 40.251456 \r\n",
       "L 105.288051 45.274051 \r\n",
       "L 110.446757 50.630131 \r\n",
       "L 115.605463 56.266176 \r\n",
       "L 120.764168 62.125865 \r\n",
       "L 125.922874 68.150665 \r\n",
       "L 131.08158 74.28037 \r\n",
       "L 136.240286 80.453736 \r\n",
       "L 141.398991 86.609079 \r\n",
       "L 146.557697 92.68489 \r\n",
       "L 151.716403 98.620477 \r\n",
       "L 156.875108 104.356526 \r\n",
       "L 162.033814 109.835717 \r\n",
       "L 167.19252 115.003321 \r\n",
       "L 172.351225 119.807684 \r\n",
       "L 177.509931 124.200826 \r\n",
       "L 182.668637 128.138824 \r\n",
       "L 187.827343 131.582353 \r\n",
       "L 192.986048 134.497003 \r\n",
       "L 198.144754 136.853645 \r\n",
       "L 203.30346 138.628734 \r\n",
       "L 208.462165 139.804537 \r\n",
       "L 213.620871 140.369302 \r\n",
       "L 218.779577 140.317391 \r\n",
       "L 223.938282 139.649321 \r\n",
       "L 229.096988 138.371761 \r\n",
       "L 234.255694 136.497483 \r\n",
       "L 239.4144 134.045214 \r\n",
       "L 244.573105 131.03945 \r\n",
       "L 249.731811 127.510236 \r\n",
       "L 254.890517 123.492814 \r\n",
       "L 260.049222 119.027348 \r\n",
       "L 265.207928 114.158448 \r\n",
       "L 270.366634 108.934758 \r\n",
       "L 275.525339 103.408448 \r\n",
       "L 280.684045 97.634784 \r\n",
       "L 285.842751 91.671432 \r\n",
       "L 291.001457 85.577973 \r\n",
       "L 296.160162 79.415293 \r\n",
       "L 301.318868 73.244938 \r\n",
       "L 306.477574 67.128616 \r\n",
       "L 311.636279 61.127412 \r\n",
       "L 316.794985 55.301289 \r\n",
       "L 321.953691 49.708458 \r\n",
       "L 327.112396 44.404774 \r\n",
       "L 332.271102 39.443284 \r\n",
       "L 337.429808 34.873535 \r\n",
       "L 342.588514 30.741185 \r\n",
       "L 347.747219 27.087521 \r\n",
       "L 352.905925 23.949038 \r\n",
       "L 358.064631 21.357124 \r\n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 38.482813 146.6 \r\n",
       "L 38.482813 10.7 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 373.282813 146.6 \r\n",
       "L 373.282813 10.7 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 38.482813 146.6 \r\n",
       "L 373.282812 146.6 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 38.482813 10.7 \r\n",
       "L 373.282812 10.7 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"legend_1\">\r\n",
       "    <g id=\"patch_7\">\r\n",
       "     <path d=\"M 45.482813 141.6 \r\n",
       "L 102.903125 141.6 \r\n",
       "Q 104.903125 141.6 104.903125 139.6 \r\n",
       "L 104.903125 81.8875 \r\n",
       "Q 104.903125 79.8875 102.903125 79.8875 \r\n",
       "L 45.482813 79.8875 \r\n",
       "Q 43.482813 79.8875 43.482813 81.8875 \r\n",
       "L 43.482813 139.6 \r\n",
       "Q 43.482813 141.6 45.482813 141.6 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_41\">\r\n",
       "     <path d=\"M 47.482813 87.985937 \r\n",
       "L 67.482812 87.985937 \r\n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_42\"/>\r\n",
       "    <g id=\"text_14\">\r\n",
       "     <!-- Col 6 -->\r\n",
       "     <g transform=\"translate(75.482812 91.485937)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 4122 4306 \r\n",
       "L 4122 3641 \r\n",
       "Q 3803 3938 3442 4084 \r\n",
       "Q 3081 4231 2675 4231 \r\n",
       "Q 1875 4231 1450 3742 \r\n",
       "Q 1025 3253 1025 2328 \r\n",
       "Q 1025 1406 1450 917 \r\n",
       "Q 1875 428 2675 428 \r\n",
       "Q 3081 428 3442 575 \r\n",
       "Q 3803 722 4122 1019 \r\n",
       "L 4122 359 \r\n",
       "Q 3791 134 3420 21 \r\n",
       "Q 3050 -91 2638 -91 \r\n",
       "Q 1578 -91 968 557 \r\n",
       "Q 359 1206 359 2328 \r\n",
       "Q 359 3453 968 4101 \r\n",
       "Q 1578 4750 2638 4750 \r\n",
       "Q 3056 4750 3426 4639 \r\n",
       "Q 3797 4528 4122 4306 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-43\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\r\n",
       "      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"131.005859\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"158.789062\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-36\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_43\">\r\n",
       "     <path d=\"M 47.482813 102.664062 \r\n",
       "L 67.482812 102.664062 \r\n",
       "\" style=\"fill:none;stroke:#bf00bf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_44\"/>\r\n",
       "    <g id=\"text_15\">\r\n",
       "     <!-- Col 7 -->\r\n",
       "     <g transform=\"translate(75.482812 106.164062)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 525 4666 \r\n",
       "L 3525 4666 \r\n",
       "L 3525 4397 \r\n",
       "L 1831 0 \r\n",
       "L 1172 0 \r\n",
       "L 2766 4134 \r\n",
       "L 525 4134 \r\n",
       "L 525 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\r\n",
       "      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"131.005859\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"158.789062\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-37\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_45\">\r\n",
       "     <path d=\"M 47.482813 117.342187 \r\n",
       "L 67.482812 117.342187 \r\n",
       "\" style=\"fill:none;stroke:#008000;stroke-dasharray:9.6,2.4,1.5,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_46\"/>\r\n",
       "    <g id=\"text_16\">\r\n",
       "     <!-- Col 8 -->\r\n",
       "     <g transform=\"translate(75.482812 120.842187)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 2034 2216 \r\n",
       "Q 1584 2216 1326 1975 \r\n",
       "Q 1069 1734 1069 1313 \r\n",
       "Q 1069 891 1326 650 \r\n",
       "Q 1584 409 2034 409 \r\n",
       "Q 2484 409 2743 651 \r\n",
       "Q 3003 894 3003 1313 \r\n",
       "Q 3003 1734 2745 1975 \r\n",
       "Q 2488 2216 2034 2216 \r\n",
       "z\r\n",
       "M 1403 2484 \r\n",
       "Q 997 2584 770 2862 \r\n",
       "Q 544 3141 544 3541 \r\n",
       "Q 544 4100 942 4425 \r\n",
       "Q 1341 4750 2034 4750 \r\n",
       "Q 2731 4750 3128 4425 \r\n",
       "Q 3525 4100 3525 3541 \r\n",
       "Q 3525 3141 3298 2862 \r\n",
       "Q 3072 2584 2669 2484 \r\n",
       "Q 3125 2378 3379 2068 \r\n",
       "Q 3634 1759 3634 1313 \r\n",
       "Q 3634 634 3220 271 \r\n",
       "Q 2806 -91 2034 -91 \r\n",
       "Q 1263 -91 848 271 \r\n",
       "Q 434 634 434 1313 \r\n",
       "Q 434 1759 690 2068 \r\n",
       "Q 947 2378 1403 2484 \r\n",
       "z\r\n",
       "M 1172 3481 \r\n",
       "Q 1172 3119 1398 2916 \r\n",
       "Q 1625 2713 2034 2713 \r\n",
       "Q 2441 2713 2670 2916 \r\n",
       "Q 2900 3119 2900 3481 \r\n",
       "Q 2900 3844 2670 4047 \r\n",
       "Q 2441 4250 2034 4250 \r\n",
       "Q 1625 4250 1398 4047 \r\n",
       "Q 1172 3844 1172 3481 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\r\n",
       "      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"131.005859\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"158.789062\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-38\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_47\">\r\n",
       "     <path d=\"M 47.482813 132.020312 \r\n",
       "L 67.482812 132.020312 \r\n",
       "\" style=\"fill:none;stroke:#ff0000;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"line2d_48\"/>\r\n",
       "    <g id=\"text_17\">\r\n",
       "     <!-- Col 9 -->\r\n",
       "     <g transform=\"translate(75.482812 135.520312)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 703 97 \r\n",
       "L 703 672 \r\n",
       "Q 941 559 1184 500 \r\n",
       "Q 1428 441 1663 441 \r\n",
       "Q 2288 441 2617 861 \r\n",
       "Q 2947 1281 2994 2138 \r\n",
       "Q 2813 1869 2534 1725 \r\n",
       "Q 2256 1581 1919 1581 \r\n",
       "Q 1219 1581 811 2004 \r\n",
       "Q 403 2428 403 3163 \r\n",
       "Q 403 3881 828 4315 \r\n",
       "Q 1253 4750 1959 4750 \r\n",
       "Q 2769 4750 3195 4129 \r\n",
       "Q 3622 3509 3622 2328 \r\n",
       "Q 3622 1225 3098 567 \r\n",
       "Q 2575 -91 1691 -91 \r\n",
       "Q 1453 -91 1209 -44 \r\n",
       "Q 966 3 703 97 \r\n",
       "z\r\n",
       "M 1959 2075 \r\n",
       "Q 2384 2075 2632 2365 \r\n",
       "Q 2881 2656 2881 3163 \r\n",
       "Q 2881 3666 2632 3958 \r\n",
       "Q 2384 4250 1959 4250 \r\n",
       "Q 1534 4250 1286 3958 \r\n",
       "Q 1038 3666 1038 3163 \r\n",
       "Q 1038 2656 1286 2365 \r\n",
       "Q 1534 2075 1959 2075 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\r\n",
       "      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"131.005859\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"158.789062\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"190.576172\" xlink:href=\"#DejaVuSans-39\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p352238ddd7\">\r\n",
       "   <rect height=\"135.9\" width=\"334.8\" x=\"38.482813\" y=\"10.7\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 432x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 行代表标记在序列中的位置，列代表位置编码的不同维度\n",
    "encoding_dim, num_steps = 32, 60\n",
    "pos_encoding = PositionalEncoding(encoding_dim, 0)\n",
    "pos_encoding.eval()\n",
    "X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\n",
    "P = pos_encoding.P[:, :X.shape[1], :]\n",
    "d2l.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',\n",
    "         figsize=(6, 2.5), legend=[\"Col %d\" % d for d in torch.arange(6, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b0a3e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T03:46:47.462398Z",
     "start_time": "2021-08-30T03:46:47.137375Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<svg height=\"264.183469pt\" version=\"1.1\" viewBox=\"0 0 211.342137 264.183469\" width=\"211.342137pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-08-30T11:46:47.378392</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 264.183469 \r\n",
       "L 211.342137 264.183469 \r\n",
       "L 211.342137 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 40.603125 226.627219 \r\n",
       "L 156.571125 226.627219 \r\n",
       "L 156.571125 9.187219 \r\n",
       "L 40.603125 9.187219 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g clip-path=\"url(#peb71428d61)\">\r\n",
       "    <image height=\"218\" id=\"imagef2973bbbba\" transform=\"scale(1 -1)translate(0 -218)\" width=\"116\" x=\"40.603125\" xlink:href=\"data:image/png;base64,\r\n",
       "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\" y=\"-8.627219\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"mf60d344e78\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.415125\" xlink:href=\"#mf60d344e78\" y=\"226.627219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(39.233875 241.225656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2034 4250 \r\n",
       "Q 1547 4250 1301 3770 \r\n",
       "Q 1056 3291 1056 2328 \r\n",
       "Q 1056 1369 1301 889 \r\n",
       "Q 1547 409 2034 409 \r\n",
       "Q 2525 409 2770 889 \r\n",
       "Q 3016 1369 3016 2328 \r\n",
       "Q 3016 3291 2770 3770 \r\n",
       "Q 2525 4250 2034 4250 \r\n",
       "z\r\n",
       "M 2034 4750 \r\n",
       "Q 2819 4750 3233 4129 \r\n",
       "Q 3647 3509 3647 2328 \r\n",
       "Q 3647 1150 3233 529 \r\n",
       "Q 2819 -91 2034 -91 \r\n",
       "Q 1250 -91 836 529 \r\n",
       "Q 422 1150 422 2328 \r\n",
       "Q 422 3509 836 4129 \r\n",
       "Q 1250 4750 2034 4750 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"114.895125\" xlink:href=\"#mf60d344e78\" y=\"226.627219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(108.532625 241.225656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 1228 531 \r\n",
       "L 3431 531 \r\n",
       "L 3431 0 \r\n",
       "L 469 0 \r\n",
       "L 469 531 \r\n",
       "Q 828 903 1448 1529 \r\n",
       "Q 2069 2156 2228 2338 \r\n",
       "Q 2531 2678 2651 2914 \r\n",
       "Q 2772 3150 2772 3378 \r\n",
       "Q 2772 3750 2511 3984 \r\n",
       "Q 2250 4219 1831 4219 \r\n",
       "Q 1534 4219 1204 4116 \r\n",
       "Q 875 4013 500 3803 \r\n",
       "L 500 4441 \r\n",
       "Q 881 4594 1212 4672 \r\n",
       "Q 1544 4750 1819 4750 \r\n",
       "Q 2544 4750 2975 4387 \r\n",
       "Q 3406 4025 3406 3419 \r\n",
       "Q 3406 3131 3298 2873 \r\n",
       "Q 3191 2616 2906 2266 \r\n",
       "Q 2828 2175 2409 1742 \r\n",
       "Q 1991 1309 1228 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_3\">\r\n",
       "     <!-- Column (encoding dimension) -->\r\n",
       "     <g transform=\"translate(23.498844 254.903781)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 4122 4306 \r\n",
       "L 4122 3641 \r\n",
       "Q 3803 3938 3442 4084 \r\n",
       "Q 3081 4231 2675 4231 \r\n",
       "Q 1875 4231 1450 3742 \r\n",
       "Q 1025 3253 1025 2328 \r\n",
       "Q 1025 1406 1450 917 \r\n",
       "Q 1875 428 2675 428 \r\n",
       "Q 3081 428 3442 575 \r\n",
       "Q 3803 722 4122 1019 \r\n",
       "L 4122 359 \r\n",
       "Q 3791 134 3420 21 \r\n",
       "Q 3050 -91 2638 -91 \r\n",
       "Q 1578 -91 968 557 \r\n",
       "Q 359 1206 359 2328 \r\n",
       "Q 359 3453 968 4101 \r\n",
       "Q 1578 4750 2638 4750 \r\n",
       "Q 3056 4750 3426 4639 \r\n",
       "Q 3797 4528 4122 4306 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-43\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1959 3097 \r\n",
       "Q 1497 3097 1228 2736 \r\n",
       "Q 959 2375 959 1747 \r\n",
       "Q 959 1119 1226 758 \r\n",
       "Q 1494 397 1959 397 \r\n",
       "Q 2419 397 2687 759 \r\n",
       "Q 2956 1122 2956 1747 \r\n",
       "Q 2956 2369 2687 2733 \r\n",
       "Q 2419 3097 1959 3097 \r\n",
       "z\r\n",
       "M 1959 3584 \r\n",
       "Q 2709 3584 3137 3096 \r\n",
       "Q 3566 2609 3566 1747 \r\n",
       "Q 3566 888 3137 398 \r\n",
       "Q 2709 -91 1959 -91 \r\n",
       "Q 1206 -91 779 398 \r\n",
       "Q 353 888 353 1747 \r\n",
       "Q 353 2609 779 3096 \r\n",
       "Q 1206 3584 1959 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 544 1381 \r\n",
       "L 544 3500 \r\n",
       "L 1119 3500 \r\n",
       "L 1119 1403 \r\n",
       "Q 1119 906 1312 657 \r\n",
       "Q 1506 409 1894 409 \r\n",
       "Q 2359 409 2629 706 \r\n",
       "Q 2900 1003 2900 1516 \r\n",
       "L 2900 3500 \r\n",
       "L 3475 3500 \r\n",
       "L 3475 0 \r\n",
       "L 2900 0 \r\n",
       "L 2900 538 \r\n",
       "Q 2691 219 2414 64 \r\n",
       "Q 2138 -91 1772 -91 \r\n",
       "Q 1169 -91 856 284 \r\n",
       "Q 544 659 544 1381 \r\n",
       "z\r\n",
       "M 1991 3584 \r\n",
       "L 1991 3584 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-75\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3328 2828 \r\n",
       "Q 3544 3216 3844 3400 \r\n",
       "Q 4144 3584 4550 3584 \r\n",
       "Q 5097 3584 5394 3201 \r\n",
       "Q 5691 2819 5691 2113 \r\n",
       "L 5691 0 \r\n",
       "L 5113 0 \r\n",
       "L 5113 2094 \r\n",
       "Q 5113 2597 4934 2840 \r\n",
       "Q 4756 3084 4391 3084 \r\n",
       "Q 3944 3084 3684 2787 \r\n",
       "Q 3425 2491 3425 1978 \r\n",
       "L 3425 0 \r\n",
       "L 2847 0 \r\n",
       "L 2847 2094 \r\n",
       "Q 2847 2600 2669 2842 \r\n",
       "Q 2491 3084 2119 3084 \r\n",
       "Q 1678 3084 1418 2786 \r\n",
       "Q 1159 2488 1159 1978 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1356 3278 1631 3431 \r\n",
       "Q 1906 3584 2284 3584 \r\n",
       "Q 2666 3584 2933 3390 \r\n",
       "Q 3200 3197 3328 2828 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6d\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3513 2113 \r\n",
       "L 3513 0 \r\n",
       "L 2938 0 \r\n",
       "L 2938 2094 \r\n",
       "Q 2938 2591 2744 2837 \r\n",
       "Q 2550 3084 2163 3084 \r\n",
       "Q 1697 3084 1428 2787 \r\n",
       "Q 1159 2491 1159 1978 \r\n",
       "L 1159 0 \r\n",
       "L 581 0 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2956 \r\n",
       "Q 1366 3272 1645 3428 \r\n",
       "Q 1925 3584 2291 3584 \r\n",
       "Q 2894 3584 3203 3211 \r\n",
       "Q 3513 2838 3513 2113 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-6e\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1984 4856 \r\n",
       "Q 1566 4138 1362 3434 \r\n",
       "Q 1159 2731 1159 2009 \r\n",
       "Q 1159 1288 1364 580 \r\n",
       "Q 1569 -128 1984 -844 \r\n",
       "L 1484 -844 \r\n",
       "Q 1016 -109 783 600 \r\n",
       "Q 550 1309 550 2009 \r\n",
       "Q 550 2706 781 3412 \r\n",
       "Q 1013 4119 1484 4856 \r\n",
       "L 1984 4856 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-28\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3597 1894 \r\n",
       "L 3597 1613 \r\n",
       "L 953 1613 \r\n",
       "Q 991 1019 1311 708 \r\n",
       "Q 1631 397 2203 397 \r\n",
       "Q 2534 397 2845 478 \r\n",
       "Q 3156 559 3463 722 \r\n",
       "L 3463 178 \r\n",
       "Q 3153 47 2828 -22 \r\n",
       "Q 2503 -91 2169 -91 \r\n",
       "Q 1331 -91 842 396 \r\n",
       "Q 353 884 353 1716 \r\n",
       "Q 353 2575 817 3079 \r\n",
       "Q 1281 3584 2069 3584 \r\n",
       "Q 2775 3584 3186 3129 \r\n",
       "Q 3597 2675 3597 1894 \r\n",
       "z\r\n",
       "M 3022 2063 \r\n",
       "Q 3016 2534 2758 2815 \r\n",
       "Q 2500 3097 2075 3097 \r\n",
       "Q 1594 3097 1305 2825 \r\n",
       "Q 1016 2553 972 2059 \r\n",
       "L 3022 2063 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 3122 3366 \r\n",
       "L 3122 2828 \r\n",
       "Q 2878 2963 2633 3030 \r\n",
       "Q 2388 3097 2138 3097 \r\n",
       "Q 1578 3097 1268 2742 \r\n",
       "Q 959 2388 959 1747 \r\n",
       "Q 959 1106 1268 751 \r\n",
       "Q 1578 397 2138 397 \r\n",
       "Q 2388 397 2633 464 \r\n",
       "Q 2878 531 3122 666 \r\n",
       "L 3122 134 \r\n",
       "Q 2881 22 2623 -34 \r\n",
       "Q 2366 -91 2075 -91 \r\n",
       "Q 1284 -91 818 406 \r\n",
       "Q 353 903 353 1747 \r\n",
       "Q 353 2603 823 3093 \r\n",
       "Q 1294 3584 2113 3584 \r\n",
       "Q 2378 3584 2631 3529 \r\n",
       "Q 2884 3475 3122 3366 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2906 2969 \r\n",
       "L 2906 4863 \r\n",
       "L 3481 4863 \r\n",
       "L 3481 0 \r\n",
       "L 2906 0 \r\n",
       "L 2906 525 \r\n",
       "Q 2725 213 2448 61 \r\n",
       "Q 2172 -91 1784 -91 \r\n",
       "Q 1150 -91 751 415 \r\n",
       "Q 353 922 353 1747 \r\n",
       "Q 353 2572 751 3078 \r\n",
       "Q 1150 3584 1784 3584 \r\n",
       "Q 2172 3584 2448 3432 \r\n",
       "Q 2725 3281 2906 2969 \r\n",
       "z\r\n",
       "M 947 1747 \r\n",
       "Q 947 1113 1208 752 \r\n",
       "Q 1469 391 1925 391 \r\n",
       "Q 2381 391 2643 752 \r\n",
       "Q 2906 1113 2906 1747 \r\n",
       "Q 2906 2381 2643 2742 \r\n",
       "Q 2381 3103 1925 3103 \r\n",
       "Q 1469 3103 1208 2742 \r\n",
       "Q 947 2381 947 1747 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-64\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 603 3500 \r\n",
       "L 1178 3500 \r\n",
       "L 1178 0 \r\n",
       "L 603 0 \r\n",
       "L 603 3500 \r\n",
       "z\r\n",
       "M 603 4863 \r\n",
       "L 1178 4863 \r\n",
       "L 1178 4134 \r\n",
       "L 603 4134 \r\n",
       "L 603 4863 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2906 1791 \r\n",
       "Q 2906 2416 2648 2759 \r\n",
       "Q 2391 3103 1925 3103 \r\n",
       "Q 1463 3103 1205 2759 \r\n",
       "Q 947 2416 947 1791 \r\n",
       "Q 947 1169 1205 825 \r\n",
       "Q 1463 481 1925 481 \r\n",
       "Q 2391 481 2648 825 \r\n",
       "Q 2906 1169 2906 1791 \r\n",
       "z\r\n",
       "M 3481 434 \r\n",
       "Q 3481 -459 3084 -895 \r\n",
       "Q 2688 -1331 1869 -1331 \r\n",
       "Q 1566 -1331 1297 -1286 \r\n",
       "Q 1028 -1241 775 -1147 \r\n",
       "L 775 -588 \r\n",
       "Q 1028 -725 1275 -790 \r\n",
       "Q 1522 -856 1778 -856 \r\n",
       "Q 2344 -856 2625 -561 \r\n",
       "Q 2906 -266 2906 331 \r\n",
       "L 2906 616 \r\n",
       "Q 2728 306 2450 153 \r\n",
       "Q 2172 0 1784 0 \r\n",
       "Q 1141 0 747 490 \r\n",
       "Q 353 981 353 1791 \r\n",
       "Q 353 2603 747 3093 \r\n",
       "Q 1141 3584 1784 3584 \r\n",
       "Q 2172 3584 2450 3431 \r\n",
       "Q 2728 3278 2906 2969 \r\n",
       "L 2906 3500 \r\n",
       "L 3481 3500 \r\n",
       "L 3481 434 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-67\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 2834 3397 \r\n",
       "L 2834 2853 \r\n",
       "Q 2591 2978 2328 3040 \r\n",
       "Q 2066 3103 1784 3103 \r\n",
       "Q 1356 3103 1142 2972 \r\n",
       "Q 928 2841 928 2578 \r\n",
       "Q 928 2378 1081 2264 \r\n",
       "Q 1234 2150 1697 2047 \r\n",
       "L 1894 2003 \r\n",
       "Q 2506 1872 2764 1633 \r\n",
       "Q 3022 1394 3022 966 \r\n",
       "Q 3022 478 2636 193 \r\n",
       "Q 2250 -91 1575 -91 \r\n",
       "Q 1294 -91 989 -36 \r\n",
       "Q 684 19 347 128 \r\n",
       "L 347 722 \r\n",
       "Q 666 556 975 473 \r\n",
       "Q 1284 391 1588 391 \r\n",
       "Q 1994 391 2212 530 \r\n",
       "Q 2431 669 2431 922 \r\n",
       "Q 2431 1156 2273 1281 \r\n",
       "Q 2116 1406 1581 1522 \r\n",
       "L 1381 1569 \r\n",
       "Q 847 1681 609 1914 \r\n",
       "Q 372 2147 372 2553 \r\n",
       "Q 372 3047 722 3315 \r\n",
       "Q 1072 3584 1716 3584 \r\n",
       "Q 2034 3584 2315 3537 \r\n",
       "Q 2597 3491 2834 3397 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 513 4856 \r\n",
       "L 1013 4856 \r\n",
       "Q 1481 4119 1714 3412 \r\n",
       "Q 1947 2706 1947 2009 \r\n",
       "Q 1947 1309 1714 600 \r\n",
       "Q 1481 -109 1013 -844 \r\n",
       "L 513 -844 \r\n",
       "Q 928 -128 1133 580 \r\n",
       "Q 1338 1288 1338 2009 \r\n",
       "Q 1338 2731 1133 3434 \r\n",
       "Q 928 4138 513 4856 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-29\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\r\n",
       "      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"131.005859\" xlink:href=\"#DejaVuSans-6c\"/>\r\n",
       "      <use x=\"158.789062\" xlink:href=\"#DejaVuSans-75\"/>\r\n",
       "      <use x=\"222.167969\" xlink:href=\"#DejaVuSans-6d\"/>\r\n",
       "      <use x=\"319.580078\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"382.958984\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"414.746094\" xlink:href=\"#DejaVuSans-28\"/>\r\n",
       "      <use x=\"453.759766\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"515.283203\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"578.662109\" xlink:href=\"#DejaVuSans-63\"/>\r\n",
       "      <use x=\"633.642578\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"694.824219\" xlink:href=\"#DejaVuSans-64\"/>\r\n",
       "      <use x=\"758.300781\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"786.083984\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"849.462891\" xlink:href=\"#DejaVuSans-67\"/>\r\n",
       "      <use x=\"912.939453\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"944.726562\" xlink:href=\"#DejaVuSans-64\"/>\r\n",
       "      <use x=\"1008.203125\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"1035.986328\" xlink:href=\"#DejaVuSans-6d\"/>\r\n",
       "      <use x=\"1133.398438\" xlink:href=\"#DejaVuSans-65\"/>\r\n",
       "      <use x=\"1194.921875\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"1258.300781\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "      <use x=\"1310.400391\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"1338.183594\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"1399.365234\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"1462.744141\" xlink:href=\"#DejaVuSans-29\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m1315a2f8c5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m1315a2f8c5\" y=\"10.999219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(27.240625 14.798437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m1315a2f8c5\" y=\"47.239219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(20.878125 51.038437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 794 531 \r\n",
       "L 1825 531 \r\n",
       "L 1825 4091 \r\n",
       "L 703 3866 \r\n",
       "L 703 4441 \r\n",
       "L 1819 4666 \r\n",
       "L 2450 4666 \r\n",
       "L 2450 531 \r\n",
       "L 3481 531 \r\n",
       "L 3481 0 \r\n",
       "L 794 0 \r\n",
       "L 794 531 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m1315a2f8c5\" y=\"83.479219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(20.878125 87.278437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m1315a2f8c5\" y=\"119.719219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 30 -->\r\n",
       "      <g transform=\"translate(20.878125 123.518437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2597 2516 \r\n",
       "Q 3050 2419 3304 2112 \r\n",
       "Q 3559 1806 3559 1356 \r\n",
       "Q 3559 666 3084 287 \r\n",
       "Q 2609 -91 1734 -91 \r\n",
       "Q 1441 -91 1130 -33 \r\n",
       "Q 819 25 488 141 \r\n",
       "L 488 750 \r\n",
       "Q 750 597 1062 519 \r\n",
       "Q 1375 441 1716 441 \r\n",
       "Q 2309 441 2620 675 \r\n",
       "Q 2931 909 2931 1356 \r\n",
       "Q 2931 1769 2642 2001 \r\n",
       "Q 2353 2234 1838 2234 \r\n",
       "L 1294 2234 \r\n",
       "L 1294 2753 \r\n",
       "L 1863 2753 \r\n",
       "Q 2328 2753 2575 2939 \r\n",
       "Q 2822 3125 2822 3475 \r\n",
       "Q 2822 3834 2567 4026 \r\n",
       "Q 2313 4219 1838 4219 \r\n",
       "Q 1578 4219 1281 4162 \r\n",
       "Q 984 4106 628 3988 \r\n",
       "L 628 4550 \r\n",
       "Q 988 4650 1302 4700 \r\n",
       "Q 1616 4750 1894 4750 \r\n",
       "Q 2613 4750 3031 4423 \r\n",
       "Q 3450 4097 3450 3541 \r\n",
       "Q 3450 3153 3228 2886 \r\n",
       "Q 3006 2619 2597 2516 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m1315a2f8c5\" y=\"155.959219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 40 -->\r\n",
       "      <g transform=\"translate(20.878125 159.758437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 2419 4116 \r\n",
       "L 825 1625 \r\n",
       "L 2419 1625 \r\n",
       "L 2419 4116 \r\n",
       "z\r\n",
       "M 2253 4666 \r\n",
       "L 3047 4666 \r\n",
       "L 3047 1625 \r\n",
       "L 3713 1625 \r\n",
       "L 3713 1100 \r\n",
       "L 3047 1100 \r\n",
       "L 3047 0 \r\n",
       "L 2419 0 \r\n",
       "L 2419 1100 \r\n",
       "L 313 1100 \r\n",
       "L 313 1709 \r\n",
       "L 2253 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m1315a2f8c5\" y=\"192.199219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <g transform=\"translate(20.878125 195.998437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 691 4666 \r\n",
       "L 3169 4666 \r\n",
       "L 3169 4134 \r\n",
       "L 1269 4134 \r\n",
       "L 1269 2991 \r\n",
       "Q 1406 3038 1543 3061 \r\n",
       "Q 1681 3084 1819 3084 \r\n",
       "Q 2600 3084 3056 2656 \r\n",
       "Q 3513 2228 3513 1497 \r\n",
       "Q 3513 744 3044 326 \r\n",
       "Q 2575 -91 1722 -91 \r\n",
       "Q 1428 -91 1123 -41 \r\n",
       "Q 819 9 494 109 \r\n",
       "L 494 744 \r\n",
       "Q 775 591 1075 516 \r\n",
       "Q 1375 441 1709 441 \r\n",
       "Q 2250 441 2565 725 \r\n",
       "Q 2881 1009 2881 1497 \r\n",
       "Q 2881 1984 2565 2268 \r\n",
       "Q 2250 2553 1709 2553 \r\n",
       "Q 1456 2553 1204 2497 \r\n",
       "Q 953 2441 691 2322 \r\n",
       "L 691 4666 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_10\">\r\n",
       "     <!-- Row (position) -->\r\n",
       "     <g transform=\"translate(14.798438 153.600187)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 2841 2188 \r\n",
       "Q 3044 2119 3236 1894 \r\n",
       "Q 3428 1669 3622 1275 \r\n",
       "L 4263 0 \r\n",
       "L 3584 0 \r\n",
       "L 2988 1197 \r\n",
       "Q 2756 1666 2539 1819 \r\n",
       "Q 2322 1972 1947 1972 \r\n",
       "L 1259 1972 \r\n",
       "L 1259 0 \r\n",
       "L 628 0 \r\n",
       "L 628 4666 \r\n",
       "L 2053 4666 \r\n",
       "Q 2853 4666 3247 4331 \r\n",
       "Q 3641 3997 3641 3322 \r\n",
       "Q 3641 2881 3436 2590 \r\n",
       "Q 3231 2300 2841 2188 \r\n",
       "z\r\n",
       "M 1259 4147 \r\n",
       "L 1259 2491 \r\n",
       "L 2053 2491 \r\n",
       "Q 2509 2491 2742 2702 \r\n",
       "Q 2975 2913 2975 3322 \r\n",
       "Q 2975 3731 2742 3939 \r\n",
       "Q 2509 4147 2053 4147 \r\n",
       "L 1259 4147 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 269 3500 \r\n",
       "L 844 3500 \r\n",
       "L 1563 769 \r\n",
       "L 2278 3500 \r\n",
       "L 2956 3500 \r\n",
       "L 3675 769 \r\n",
       "L 4391 3500 \r\n",
       "L 4966 3500 \r\n",
       "L 4050 0 \r\n",
       "L 3372 0 \r\n",
       "L 2619 2869 \r\n",
       "L 1863 0 \r\n",
       "L 1184 0 \r\n",
       "L 269 3500 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-77\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1159 525 \r\n",
       "L 1159 -1331 \r\n",
       "L 581 -1331 \r\n",
       "L 581 3500 \r\n",
       "L 1159 3500 \r\n",
       "L 1159 2969 \r\n",
       "Q 1341 3281 1617 3432 \r\n",
       "Q 1894 3584 2278 3584 \r\n",
       "Q 2916 3584 3314 3078 \r\n",
       "Q 3713 2572 3713 1747 \r\n",
       "Q 3713 922 3314 415 \r\n",
       "Q 2916 -91 2278 -91 \r\n",
       "Q 1894 -91 1617 61 \r\n",
       "Q 1341 213 1159 525 \r\n",
       "z\r\n",
       "M 3116 1747 \r\n",
       "Q 3116 2381 2855 2742 \r\n",
       "Q 2594 3103 2138 3103 \r\n",
       "Q 1681 3103 1420 2742 \r\n",
       "Q 1159 2381 1159 1747 \r\n",
       "Q 1159 1113 1420 752 \r\n",
       "Q 1681 391 2138 391 \r\n",
       "Q 2594 391 2855 752 \r\n",
       "Q 3116 1113 3116 1747 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-70\" transform=\"scale(0.015625)\"/>\r\n",
       "       <path d=\"M 1172 4494 \r\n",
       "L 1172 3500 \r\n",
       "L 2356 3500 \r\n",
       "L 2356 3053 \r\n",
       "L 1172 3053 \r\n",
       "L 1172 1153 \r\n",
       "Q 1172 725 1289 603 \r\n",
       "Q 1406 481 1766 481 \r\n",
       "L 2356 481 \r\n",
       "L 2356 0 \r\n",
       "L 1766 0 \r\n",
       "Q 1100 0 847 248 \r\n",
       "Q 594 497 594 1153 \r\n",
       "L 594 3053 \r\n",
       "L 172 3053 \r\n",
       "L 172 3500 \r\n",
       "L 594 3500 \r\n",
       "L 594 4494 \r\n",
       "L 1172 4494 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      <use x=\"64.982422\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"126.164062\" xlink:href=\"#DejaVuSans-77\"/>\r\n",
       "      <use x=\"207.951172\" xlink:href=\"#DejaVuSans-20\"/>\r\n",
       "      <use x=\"239.738281\" xlink:href=\"#DejaVuSans-28\"/>\r\n",
       "      <use x=\"278.751953\" xlink:href=\"#DejaVuSans-70\"/>\r\n",
       "      <use x=\"342.228516\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"403.410156\" xlink:href=\"#DejaVuSans-73\"/>\r\n",
       "      <use x=\"455.509766\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"483.292969\" xlink:href=\"#DejaVuSans-74\"/>\r\n",
       "      <use x=\"522.501953\" xlink:href=\"#DejaVuSans-69\"/>\r\n",
       "      <use x=\"550.285156\" xlink:href=\"#DejaVuSans-6f\"/>\r\n",
       "      <use x=\"611.466797\" xlink:href=\"#DejaVuSans-6e\"/>\r\n",
       "      <use x=\"674.845703\" xlink:href=\"#DejaVuSans-29\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 40.603125 226.627219 \r\n",
       "L 40.603125 9.187219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 156.571125 226.627219 \r\n",
       "L 156.571125 9.187219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 40.603125 226.627219 \r\n",
       "L 156.571125 226.627219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 40.603125 9.187219 \r\n",
       "L 156.571125 9.187219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_2\">\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path d=\"M 166.336125 183.139219 \r\n",
       "L 172.859325 183.139219 \r\n",
       "L 172.859325 52.675219 \r\n",
       "L 166.336125 52.675219 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path clip-path=\"url(#p33881ca11b)\" d=\"M 166.336125 183.139219 \r\n",
       "L 166.336125 182.629594 \r\n",
       "L 166.336125 53.184844 \r\n",
       "L 166.336125 52.675219 \r\n",
       "L 172.859325 52.675219 \r\n",
       "L 172.859325 53.184844 \r\n",
       "L 172.859325 182.629594 \r\n",
       "L 172.859325 183.139219 \r\n",
       "L 172.859325 183.139219 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n",
       "   </g>\r\n",
       "   <image height=\"131\" id=\"image057f566b22\" transform=\"scale(1 -1)translate(0 -131)\" width=\"7\" x=\"166\" xlink:href=\"data:image/png;base64,\r\n",
       "iVBORw0KGgoAAAANSUhEUgAAAAcAAACDCAYAAABBcwEdAAAAqElEQVR4nO2WQQoEMQgEXcj/vzuHTXRfYAVaJBnYuTbVapuE+TzfCEu+4blmA7QLSScyXkVel+0J0pgE8V3LRnLJthtSr3mCTLW+mlC0VDPVbCyqybZOtkROnBNt5YTQdtNQS7YoTjlbPkO47EK2PQ0dqFl4GPUzJI/yF82Ge35ZNluB29vVbRRGAVG3RZL/MA401EQWEiLSfMni7LHtEddtDeli5Pv8AVjrYLu4ozIGAAAAAElFTkSuQmCC\" y=\"-52\"/>\r\n",
       "   <g id=\"matplotlib.axis_3\"/>\r\n",
       "   <g id=\"matplotlib.axis_4\">\r\n",
       "    <g id=\"ytick_7\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 3.5 0 \r\n",
       "\" id=\"m05702784ab\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.859325\" xlink:href=\"#m05702784ab\" y=\"183.139219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- −1.0 -->\r\n",
       "      <g transform=\"translate(179.859325 186.938437)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 678 2272 \r\n",
       "L 4684 2272 \r\n",
       "L 4684 1741 \r\n",
       "L 678 1741 \r\n",
       "L 678 2272 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2212\" transform=\"scale(0.015625)\"/>\r\n",
       "        <path d=\"M 684 794 \r\n",
       "L 1344 794 \r\n",
       "L 1344 0 \r\n",
       "L 684 0 \r\n",
       "L 684 794 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_8\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.859325\" xlink:href=\"#m05702784ab\" y=\"150.523219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- −0.5 -->\r\n",
       "      <g transform=\"translate(179.859325 154.322437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\r\n",
       "       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_9\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.859325\" xlink:href=\"#m05702784ab\" y=\"117.907219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_13\">\r\n",
       "      <!-- 0.0 -->\r\n",
       "      <g transform=\"translate(179.859325 121.706437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_10\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.859325\" xlink:href=\"#m05702784ab\" y=\"85.291219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_14\">\r\n",
       "      <!-- 0.5 -->\r\n",
       "      <g transform=\"translate(179.859325 89.090437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_11\">\r\n",
       "     <g id=\"line2d_13\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.859325\" xlink:href=\"#m05702784ab\" y=\"52.675219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_15\">\r\n",
       "      <!-- 1.0 -->\r\n",
       "      <g transform=\"translate(179.859325 56.474437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"LineCollection_1\"/>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path d=\"M 166.336125 183.139219 \r\n",
       "L 166.336125 182.629594 \r\n",
       "L 166.336125 53.184844 \r\n",
       "L 166.336125 52.675219 \r\n",
       "L 172.859325 52.675219 \r\n",
       "L 172.859325 53.184844 \r\n",
       "L 172.859325 182.629594 \r\n",
       "L 172.859325 183.139219 \r\n",
       "z\r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"peb71428d61\">\r\n",
       "   <rect height=\"217.44\" width=\"115.968\" x=\"40.603125\" y=\"9.187219\"/>\r\n",
       "  </clipPath>\r\n",
       "  <clipPath id=\"p33881ca11b\">\r\n",
       "   <rect height=\"130.464\" width=\"6.5232\" x=\"166.336125\" y=\"52.675219\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 252x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 在编码维度上降低频率\n",
    "P = P[0, :, :].unsqueeze(0).unsqueeze(0)\n",
    "d2l.show_heatmaps(P, xlabel='Column (encoding dimension)',\n",
    "                  ylabel='Row (position)', figsize=(3.5, 4), cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d4c43",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d60e82",
   "metadata": {
    "hidden": true
   },
   "source": [
    "多头就是用多个，试用多个不同初始化的注意力，比如让某些抽短距离某些抽长距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a9b4622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:27:50.271255Z",
     "start_time": "2021-08-30T04:27:50.260254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b931d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "在实现过程中，我们选择缩放点积注意力作为每一个注意力头。为了避免计算成本和参数数量的大幅增长，我们设定  pq=pk=pv=po/h 。值得注意的是，如果我们将查询、键和值的线性变换的输出数量设置为  pqh=pkh=pvh=po ，则可以并行计算  h  个头。在下面的实现中， po  是通过参数 num_hiddens 指定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae43cdd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:28:54.741460Z",
     "start_time": "2021-08-30T04:28:54.721459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#选择缩放点积注意力作为每一个注意力头\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = d2l.DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # `queries`, `keys`, or `values` 的形状:\n",
    "        # (`batch_size`, 查询或者“键－值”对的个数, `num_hiddens`)\n",
    "        # `valid_lens`　的形状:\n",
    "        # (`batch_size`,) or (`batch_size`, 查询的个数)\n",
    "        # 经过变换后，输出的 `queries`, `keys`, or `values`　的形状:\n",
    "        # (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        # 不用for loop，用reshape并行做完\n",
    "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # 在轴 0，将第一项（标量或者矢量）复制 `num_heads` 次，\n",
    "            # 然后如此复制第二项，然后诸如此类。\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # `output` 的形状: (`batch_size` * `num_heads`, 查询的个数,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # `output_concat` 的形状: (`batch_size`, 查询的个数, `num_hiddens`)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98029a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "为了能够使多个头并行计算，上面的 MultiHeadAttention 类使用了下面定义的两个转置函数。具体来说，transpose_output 函数反转了 transpose_qkv 函数的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fb27989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:28:56.479588Z",
     "start_time": "2021-08-30T04:28:56.465587Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def transpose_qkv(X, num_heads):\n",
    "    # 输入 `X` 的形状: (`batch_size`, 查询或者“键－值”对的个数, `num_hiddens`).\n",
    "    # 输出 `X` 的形状: (`batch_size`, 查询或者“键－值”对的个数, `num_heads`,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "\n",
    "    # 输出 `X` 的形状: (`batch_size`, `num_heads`, 查询或者“键－值”对的个数,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "\n",
    "    # `output` 的形状: (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,\n",
    "    # `num_hiddens` / `num_heads`)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "\n",
    "#@save\n",
    "def transpose_output(X, num_heads):\n",
    "    \"\"\"逆转 `transpose_qkv` 函数的操作\"\"\"\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4abd51e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "让我们使用键和值相同的小例子来测试我们编写的 MultiHeadAttention 类。多头注意力输出的形状是 (batch_size, num_queries, num_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6db97fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:28:58.185719Z",
     "start_time": "2021-08-30T04:28:58.176719Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (attention): DotProductAttention(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (W_q): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_k): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_v): Linear(in_features=100, out_features=100, bias=False)\n",
       "  (W_o): Linear(in_features=100, out_features=100, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens, num_heads = 100, 5\n",
    "attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,\n",
    "                               num_hiddens, num_heads, 0.5)\n",
    "attention.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "461cb4a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:29:06.052685Z",
     "start_time": "2021-08-30T04:29:06.033175Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 100])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_queries, num_kvpairs, valid_lens = 2, 4, 6, torch.tensor([3, 2])\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
    "attention(X, Y, Y, valid_lens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972f858",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbbd23c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:55.319924Z",
     "start_time": "2021-08-30T08:52:51.257470Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b0a6c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "基于位置的前馈网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5794d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:55.350926Z",
     "start_time": "2021-08-30T08:52:55.340924Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbce5a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:55.398929Z",
     "start_time": "2021-08-30T08:52:55.370929Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5152, -0.2346, -0.6906,  0.3856, -0.0729, -0.9465, -0.5521, -0.2345],\n",
       "        [-0.5152, -0.2346, -0.6906,  0.3856, -0.0729, -0.9465, -0.5521, -0.2345],\n",
       "        [-0.5152, -0.2346, -0.6906,  0.3856, -0.0729, -0.9465, -0.5521, -0.2345]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改变张量的最里层维度的尺寸\n",
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2, 3, 4)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9d113b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:55.621947Z",
     "start_time": "2021-08-30T08:52:55.600945Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 对比不同维度的层归一化和批量归一化的效果\n",
    "ln = nn.LayerNorm(2)\n",
    "bn = nn.BatchNorm1d(2)\n",
    "X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf101f9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:57.061052Z",
     "start_time": "2021-08-30T08:52:57.040053Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 使用残差连接和层归一化\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc13c148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:58.530160Z",
     "start_time": "2021-08-30T08:52:58.516159Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法操作后输出张量的形状相同\n",
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45093f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "实现编码器中的一个层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b82d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:52:59.329222Z",
     "start_time": "2021-08-30T08:52:59.323221Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = d2l.MultiHeadAttention(key_size, query_size,\n",
    "                                                value_size, num_hiddens,\n",
    "                                                num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens)) # self-attetion就是X自己qkv三连\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125af29",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Transformer编码器中的任何层都不会改变其输入的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974d3ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:53:00.589316Z",
     "start_time": "2021-08-30T08:53:00.548315Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c26c8a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Transformer编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374ba526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:53:01.739404Z",
     "start_time": "2021-08-30T08:53:01.710401Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(d2l.Encoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                \"block\" + str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens)) # 乘法是为了规范化\n",
    "        self.attention_weights = [None] * len(self.blks) # 为了可视化弄得\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens) # 每次钻一下\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "950893fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:53:03.016496Z",
     "start_time": "2021-08-30T08:53:02.947493Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个两层的Transformer编码器\n",
    "encoder = TransformerEncoder(200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2,\n",
    "                             0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198bde78",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Transformer解码器也是由多个相同的层组成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b9ebad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:53:04.579865Z",
     "start_time": "2021-08-30T08:53:04.556865Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第 i 个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = d2l.MultiHeadAttention(key_size, query_size,\n",
    "                                                 value_size, num_hiddens,\n",
    "                                                 num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = d2l.MultiHeadAttention(key_size, query_size,\n",
    "                                                 value_size, num_hiddens,\n",
    "                                                 num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(1, num_steps + 1,\n",
    "                                          device=X.device).repeat(\n",
    "                                              batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fcd3681",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T04:59:17.154062Z",
     "start_time": "2021-08-30T04:59:17.090061Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编码器和解码器的特征维度都是num_hiddens\n",
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
    "decoder_blk.eval()\n",
    "X = torch.ones((2, 100, 24))\n",
    "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aab435",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Transformer解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bdaa6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:53:06.670020Z",
     "start_time": "2021-08-30T08:53:06.644018Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                \"block\" + str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size) # 英语法语翻译，用vocab\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range(2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306646a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:53:20.202459Z",
     "start_time": "2021-08-30T08:53:09.148208Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 16, 1, 0.1, 8, 10\n",
    "lr, num_epochs, device = 0.005, 2, d2l.try_gpu()\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "encoder = TransformerEncoder(len(src_vocab), key_size, query_size, value_size,\n",
    "                             num_hiddens, norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "decoder = TransformerDecoder(len(tgt_vocab), key_size, query_size, value_size,\n",
    "                             num_hiddens, norm_shape, ffn_num_input,\n",
    "                             ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325ab45",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 将一些英语句子翻译成法语\n",
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {d2l.bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450896d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:54:29.515128Z",
     "start_time": "2021-08-30T08:54:29.494128Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 可视化Transformer 的注意力权重\n",
    "enc_attention_weights = torch.cat(net.encoder.attention_weights, 0).reshape(\n",
    "    (num_layers, num_heads, -1, num_steps))\n",
    "enc_attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb18b77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d2l.show_heatmaps(enc_attention_weights.cpu(), xlabel='Key positions',\n",
    "                  ylabel='Query positions',\n",
    "                  titles=['Head %d' % i\n",
    "                          for i in range(1, 5)], figsize=(7, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63092f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:54:59.091003Z",
     "start_time": "2021-08-30T08:54:59.069003Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 为了可视化解码器的自注意力权重和“编码器－解码器”的注意力权重，我们需要完成更多的数据操作工作\n",
    "dec_attention_weights_2d = [\n",
    "    head[0].tolist() for step in dec_attention_weight_seq for attn in step\n",
    "    for blk in attn for head in blk]\n",
    "dec_attention_weights_filled = torch.tensor(\n",
    "    pd.DataFrame(dec_attention_weights_2d).fillna(0.0).values)\n",
    "dec_attention_weights = dec_attention_weights_filled.reshape(\n",
    "    (-1, 2, num_layers, num_heads, num_steps))\n",
    "dec_self_attention_weights, dec_inter_attention_weights = \\\n",
    "    dec_attention_weights.permute(1, 2, 3, 0, 4)\n",
    "dec_self_attention_weights.shape, dec_inter_attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e4802",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d2l.show_heatmaps(\n",
    "    dec_self_attention_weights[:, :, :, :len(translation.split()) + 1],\n",
    "    xlabel='Key positions', ylabel='Query positions',\n",
    "    titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae67c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 输出序列的查询不会与输入序列中填充位置的标记进行注意力计算\n",
    "d2l.show_heatmaps(dec_inter_attention_weights, xlabel='Key positions',\n",
    "                  ylabel='Query positions',\n",
    "                  titles=['Head %d' % i\n",
    "                          for i in range(1, 5)], figsize=(7, 3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f2a0f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3f8f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Bidirectional Encoder Representations from Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa105211",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4990e2ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:59:14.453064Z",
     "start_time": "2021-08-30T08:59:14.444068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d533188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:59:26.886502Z",
     "start_time": "2021-08-30T08:59:26.875503Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Input Representation\n",
    "def get_tokens_and_segments(tokens_a, tokens_b=None):\n",
    "    \"\"\"Get tokens of the BERT input sequence and their segment IDs.\"\"\"\n",
    "    tokens = ['<cls>'] + tokens_a + ['<sep>']\n",
    "    segments = [0] * (len(tokens_a) + 2) # 加2是两个<>\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<sep>']\n",
    "        segments += [1] * (len(tokens_b) + 1)\n",
    "    return tokens, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0910eba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:59:39.374560Z",
     "start_time": "2021-08-30T08:59:39.357560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# BERTEncoder class\n",
    "class BERTEncoder(nn.Module):\n",
    "    \"\"\"BERT encoder.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 **kwargs):\n",
    "        super(BERTEncoder, self).__init__(**kwargs)\n",
    "        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.segment_embedding = nn.Embedding(2, num_hiddens)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(f\"{i}\", d2l.EncoderBlock( # transformer encoder搬过来\n",
    "                key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))\n",
    "        # 让它可学，就随机初始化就可以了，包进parameter\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n",
    "                                                      num_hiddens))\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens):\n",
    "        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n",
    "        X = X + self.pos_embedding.data[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d91bad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T08:59:50.101277Z",
     "start_time": "2021-08-30T08:59:49.860260Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference of BERTEncoder\n",
    "vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4\n",
    "norm_shape, ffn_num_input, num_layers, dropout = [768], 768, 2, 0.2\n",
    "encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                      ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "\n",
    "tokens = torch.randint(0, vocab_size, (2, 8)) # batchs_size-2，句子长度-8\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = encoder(tokens, segments, None)\n",
    "encoded_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a783506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:36:54.340626Z",
     "start_time": "2021-08-30T12:36:54.323626Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Masked Language Modeling - 多分类\n",
    "class MaskLM(nn.Module):\n",
    "    \"\"\"The masked language model task of BERT.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "        self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens), # BERT后面接MLP\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.LayerNorm(num_hiddens),\n",
    "                                 nn.Linear(num_hiddens, vocab_size)) # 做vocab_size大小的分类\n",
    "\n",
    "    def forward(self, X, pred_positions): # X为BERT_ENCODER的输出\n",
    "        num_pred_positions = pred_positions.shape[1]\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        batch_size = X.shape[0]\n",
    "        batch_idx = torch.arange(0, batch_size)\n",
    "        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n",
    "        masked_X = X[batch_idx, pred_positions] # 把masked 位置的特征拿出来\n",
    "        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n",
    "        mlm_Y_hat = self.mlp(masked_X) # 特征丢进去做预测\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bce55d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:44:44.992841Z",
     "start_time": "2021-08-30T12:44:44.842830Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The forward inference of MaskLM\n",
    "mlm = MaskLM(vocab_size, num_hiddens)\n",
    "mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])\n",
    "mlm_Y_hat = mlm(encoded_X, mlm_positions)\n",
    "mlm_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb86042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:44:50.671829Z",
     "start_time": "2021-08-30T12:44:50.648306Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))\n",
    "mlm_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "700a4496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:49:19.506617Z",
     "start_time": "2021-08-30T12:49:19.489614Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Next Sentence Prediction - 二分类\n",
    "class NextSentencePred(nn.Module):\n",
    "    \"\"\"The next sentence prediction task of BERT.\"\"\"\n",
    "    def __init__(self, num_inputs, **kwargs):\n",
    "        super(NextSentencePred, self).__init__(**kwargs)\n",
    "        self.output = nn.Linear(num_inputs, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a85a04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:49:20.049159Z",
     "start_time": "2021-08-30T12:49:20.031160Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The forward inference of an NextSentencePred\n",
    "encoded_X = torch.flatten(encoded_X, start_dim=1)\n",
    "nsp = NextSentencePred(encoded_X.shape[-1])\n",
    "nsp_Y_hat = nsp(encoded_X)\n",
    "nsp_Y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d968b0b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:49:25.792427Z",
     "start_time": "2021-08-30T12:49:25.776431Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsp_y = torch.tensor([0, 1])\n",
    "nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "nsp_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f9670",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Putting All Things Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ffd540b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T12:51:15.568981Z",
     "start_time": "2021-08-30T12:51:15.553983Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class BERTModel(nn.Module):\n",
    "    \"\"\"The BERT model.\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 hid_in_features=768, mlm_in_features=768,\n",
    "                 nsp_in_features=768):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape,\n",
    "                    ffn_num_input, ffn_num_hiddens, num_heads, num_layers,\n",
    "                    dropout, max_len=max_len, key_size=key_size,\n",
    "                    query_size=query_size, value_size=value_size)\n",
    "        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n",
    "                                    nn.Tanh()) # 给nsp用的\n",
    "        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n",
    "        self.nsp = NextSentencePred(nsp_in_features)\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):\n",
    "        encoded_X = self.encoder(tokens, segments, valid_lens)\n",
    "        if pred_positions is not None:\n",
    "            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n",
    "        else:\n",
    "            mlm_Y_hat = None\n",
    "        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :])) # 将所有[cls]的向量抽出来\n",
    "        return encoded_X, mlm_Y_hat, nsp_Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0586a801",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dataset for Pretrain BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c353cf7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3f141",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The WikiText-2 dataset - 几百MB小型wiki数据集\n",
    "d2l.DATA_HUB['wikitext-2'] = (\n",
    "    'https://s3.amazonaws.com/research.metamind.io/wikitext/'\n",
    "    'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n",
    "\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    paragraphs = [line.strip().lower().split(' . ')\n",
    "                  for line in lines if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a5f225",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generating the Next Sentence Prediction Task\n",
    "def _get_next_sentence(sentence, next_sentence, paragraphs):\n",
    "    if random.random() < 0.5:\n",
    "        is_next = True\n",
    "    else:\n",
    "        next_sentence = random.choice(random.choice(paragraphs))\n",
    "        is_next = False\n",
    "    return sentence, next_sentence, is_next\n",
    "\n",
    "def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n",
    "    nsp_data_from_paragraph = []\n",
    "    for i in range(len(paragraph) - 1):\n",
    "        tokens_a, tokens_b, is_next = _get_next_sentence(\n",
    "            paragraph[i], paragraph[i + 1], paragraphs)\n",
    "        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n",
    "            continue\n",
    "        tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "        nsp_data_from_paragraph.append((tokens, segments, is_next))\n",
    "    return nsp_data_from_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5d57d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generating the Masked Language Modeling Task\n",
    "def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,\n",
    "                        vocab):\n",
    "    mlm_input_tokens = [token for token in tokens]\n",
    "    pred_positions_and_labels = []\n",
    "    random.shuffle(candidate_pred_positions)\n",
    "    for mlm_pred_position in candidate_pred_positions:\n",
    "        if len(pred_positions_and_labels) >= num_mlm_preds:\n",
    "            break\n",
    "        masked_token = None\n",
    "        if random.random() < 0.8:\n",
    "            masked_token = '<mask>'\n",
    "        else:\n",
    "            if random.random() < 0.5:\n",
    "                masked_token = tokens[mlm_pred_position]\n",
    "            else:\n",
    "                masked_token = random.randint(0, len(vocab) - 1)\n",
    "        mlm_input_tokens[mlm_pred_position] = masked_token\n",
    "        pred_positions_and_labels.append(\n",
    "            (mlm_pred_position, tokens[mlm_pred_position]))\n",
    "    return mlm_input_tokens, pred_positions_and_labels\n",
    "\n",
    "def _get_mlm_data_from_tokens(tokens, vocab):\n",
    "    candidate_pred_positions = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in ['<cls>', '<sep>']:\n",
    "            continue\n",
    "        candidate_pred_positions.append(i)\n",
    "    num_mlm_preds = max(1, round(len(tokens) * 0.15))\n",
    "    mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(\n",
    "        tokens, candidate_pred_positions, num_mlm_preds, vocab)\n",
    "    pred_positions_and_labels = sorted(pred_positions_and_labels,\n",
    "                                       key=lambda x: x[0])\n",
    "    pred_positions = [v[0] for v in pred_positions_and_labels]\n",
    "    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n",
    "    return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4f091",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Append the special “<mask>” tokens to the inputs\n",
    "def _pad_bert_inputs(examples, max_len, vocab):\n",
    "    max_num_mlm_preds = round(max_len * 0.15)\n",
    "    all_token_ids, all_segments, valid_lens,  = [], [], []\n",
    "    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n",
    "    nsp_labels = []\n",
    "    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n",
    "         is_next) in examples:\n",
    "        all_token_ids.append(torch.tensor(token_ids + [vocab['<pad>']] * (\n",
    "            max_len - len(token_ids)), dtype=torch.long))\n",
    "        all_segments.append(torch.tensor(segments + [0] * (\n",
    "            max_len - len(segments)), dtype=torch.long))\n",
    "        valid_lens.append(torch.tensor(len(token_ids), dtype=torch.float32))\n",
    "        all_pred_positions.append(torch.tensor(pred_positions + [0] * (\n",
    "            max_num_mlm_preds - len(pred_positions)), dtype=torch.long))\n",
    "        all_mlm_weights.append(\n",
    "            torch.tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * (\n",
    "                max_num_mlm_preds - len(pred_positions)),\n",
    "                dtype=torch.float32))\n",
    "        all_mlm_labels.append(torch.tensor(mlm_pred_label_ids + [0] * (\n",
    "            max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=torch.long))\n",
    "        nsp_labels.append(torch.tensor(is_next, dtype=torch.long))\n",
    "    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n",
    "            all_mlm_weights, all_mlm_labels, nsp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580677a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The WikiText-2 dataset for pretraining BERT\n",
    "class _WikiTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paragraphs, max_len):\n",
    "        paragraphs = [d2l.tokenize(\n",
    "            paragraph, token='word') for paragraph in paragraphs]\n",
    "        sentences = [sentence for paragraph in paragraphs\n",
    "                     for sentence in paragraph]\n",
    "        self.vocab = d2l.Vocab(sentences, min_freq=5, reserved_tokens=[\n",
    "            '<pad>', '<mask>', '<cls>', '<sep>'])\n",
    "        examples = []\n",
    "        for paragraph in paragraphs:\n",
    "            examples.extend(_get_nsp_data_from_paragraph(\n",
    "                paragraph, paragraphs, self.vocab, max_len))\n",
    "        examples = [(_get_mlm_data_from_tokens(tokens, self.vocab)\n",
    "                      + (segments, is_next))\n",
    "                     for tokens, segments, is_next in examples]\n",
    "        (self.all_token_ids, self.all_segments, self.valid_lens,\n",
    "         self.all_pred_positions, self.all_mlm_weights,\n",
    "         self.all_mlm_labels, self.nsp_labels) = _pad_bert_inputs(\n",
    "            examples, max_len, self.vocab)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.all_token_ids[idx], self.all_segments[idx],\n",
    "                self.valid_lens[idx], self.all_pred_positions[idx],\n",
    "                self.all_mlm_weights[idx], self.all_mlm_labels[idx],\n",
    "                self.nsp_labels[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558dfd9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Download and WikiText-2 dataset and generate pretraining examples\n",
    "def load_data_wiki(batch_size, max_len):\n",
    "    \"\"\"Load the WikiText-2 dataset.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    data_dir = d2l.download_extract('wikitext-2', 'wikitext-2')\n",
    "    paragraphs = _read_wiki(data_dir)\n",
    "    train_set = _WikiTextDataset(paragraphs, max_len)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                        shuffle=True, num_workers=num_workers)\n",
    "    return train_iter, train_set.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a4f63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Print out the shapes of a minibatch of BERT pretraining examples\n",
    "batch_size, max_len = 512, 64\n",
    "train_iter, vocab = load_data_wiki(batch_size, max_len)\n",
    "\n",
    "for (tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X,\n",
    "     mlm_Y, nsp_y) in train_iter:\n",
    "    print(tokens_X.shape, segments_X.shape, valid_lens_x.shape,\n",
    "          pred_positions_X.shape, mlm_weights_X.shape, mlm_Y.shape,\n",
    "          nsp_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd7d6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df842dd7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pretrain BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a7ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:48:46.414484Z",
     "start_time": "2021-08-30T13:48:40.323641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, max_len = 512, 64\n",
    "train_iter, vocab = d2l.load_data_wiki(batch_size, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5586c33",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A small BERT, using 2 layers, 128 hidden units, and 2 self-attention heads\n",
    "net = d2l.BERTModel(len(vocab), num_hiddens=128, norm_shape=[128],\n",
    "                    ffn_num_input=128, ffn_num_hiddens=256, num_heads=2,\n",
    "                    num_layers=2, dropout=0.2, key_size=128, query_size=128,\n",
    "                    value_size=128, hid_in_features=128, mlm_in_features=128,\n",
    "                    nsp_in_features=128)\n",
    "devices = d2l.try_all_gpus()\n",
    "loss = nn.CrossEntropyLoss() # 本质pretrain的也是分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf620d16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computes the loss for both the masked language modeling and next sentence prediction tasks\n",
    "def _get_batch_loss_bert(net, loss, vocab_size, tokens_X,\n",
    "                         segments_X, valid_lens_x,\n",
    "                         pred_positions_X, mlm_weights_X,\n",
    "                         mlm_Y, nsp_y):\n",
    "    _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,\n",
    "                                  valid_lens_x.reshape(-1),\n",
    "                                  pred_positions_X)\n",
    "    mlm_l = loss(mlm_Y_hat.reshape(-1, vocab_size), mlm_Y.reshape(-1)) *\\\n",
    "    mlm_weights_X.reshape(-1, 1) # 被pad的东西就不去预测\n",
    "    mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)\n",
    "    nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "    l = mlm_l + nsp_l\n",
    "    return mlm_l, nsp_l, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e1c55",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pretrain BERT (net) on the WikiText-2 (train_iter) dataset\n",
    "def train_bert(train_iter, net, loss, vocab_size, devices, num_steps):\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    step, timer = 0, d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='step', ylabel='loss',\n",
    "                            xlim=[1, num_steps], legend=['mlm', 'nsp'])\n",
    "    metric = d2l.Accumulator(4)\n",
    "    num_steps_reached = False\n",
    "    while step < num_steps and not num_steps_reached: # pretrain数据太大，所以不用epoch，step其实就是batch\n",
    "        for tokens_X, segments_X, valid_lens_x, pred_positions_X,\\\n",
    "            mlm_weights_X, mlm_Y, nsp_y in train_iter:\n",
    "            tokens_X = tokens_X.to(devices[0])\n",
    "            segments_X = segments_X.to(devices[0])\n",
    "            valid_lens_x = valid_lens_x.to(devices[0])\n",
    "            pred_positions_X = pred_positions_X.to(devices[0])\n",
    "            mlm_weights_X = mlm_weights_X.to(devices[0])\n",
    "            mlm_Y, nsp_y = mlm_Y.to(devices[0]), nsp_y.to(devices[0])\n",
    "            trainer.zero_grad()\n",
    "            timer.start()\n",
    "            mlm_l, nsp_l, l = _get_batch_loss_bert(\n",
    "                net, loss, vocab_size, tokens_X, segments_X, valid_lens_x,\n",
    "                pred_positions_X, mlm_weights_X, mlm_Y, nsp_y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            metric.add(mlm_l, nsp_l, tokens_X.shape[0], 1)\n",
    "            timer.stop()\n",
    "            animator.add(step + 1,\n",
    "                         (metric[0] / metric[3], metric[1] / metric[3]))\n",
    "            step += 1\n",
    "            if step == num_steps:\n",
    "                num_steps_reached = True\n",
    "                break\n",
    "\n",
    "    print(f'MLM loss {metric[0] / metric[3]:.3f}, '\n",
    "          f'NSP loss {metric[1] / metric[3]:.3f}')\n",
    "    print(f'{metric[2] / timer.sum():.1f} sentence pairs/sec on '\n",
    "          f'{str(devices)}')\n",
    "\n",
    "train_bert(train_iter, net, loss, len(vocab), devices, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fad9a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Representing Text with BERT - BERT其实也是特征抽取器，本质为一个高级encoder\n",
    "def get_bert_encoding(net, tokens_a, tokens_b=None):\n",
    "    tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "    token_ids = torch.tensor(vocab[tokens], device=devices[0]).unsqueeze(0)\n",
    "    segments = torch.tensor(segments, device=devices[0]).unsqueeze(0)\n",
    "    valid_len = torch.tensor(len(tokens), device=devices[0]).unsqueeze(0)\n",
    "    encoded_X, _, _ = net(token_ids, segments, valid_len)\n",
    "    return encoded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8bb10",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Consider the sentence \"a crane is flying\"\n",
    "tokens_a = ['a', 'crane', 'is', 'flying']\n",
    "encoded_text = get_bert_encoding(net, tokens_a)\n",
    "encoded_text_cls = encoded_text[:, 0, :] # 拿出所有cls\n",
    "encoded_text_crane = encoded_text[:, 2, :]\n",
    "encoded_text.shape, encoded_text_cls.shape, encoded_text_crane[0][:3]\n",
    "# 应该是1，6，128和1，128，因为还有两个分隔符，每个token一个hidden vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59740cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now consider a sentence pair \"a crane driver came\" and \"he just left\"\n",
    "tokens_a, tokens_b = ['a', 'crane', 'driver', 'came'], ['he', 'just', 'left']\n",
    "encoded_pair = get_bert_encoding(net, tokens_a, tokens_b)\n",
    "encoded_pair_cls = encoded_pair[:, 0, :]\n",
    "encoded_pair_crane = encoded_pair[:, 2, :]\n",
    "encoded_pair.shape, encoded_pair_cls.shape, encoded_pair_crane[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df4686",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### fine-tune BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc0ae9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Natural Language Inference and the Dataset\n",
    "Stanford Natural Language Inference (SNLI) Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8efcdc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "d2l.DATA_HUB['SNLI'] = (\n",
    "    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n",
    "    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n",
    "\n",
    "data_dir = d2l.download_extract('SNLI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68865067",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reading the Dataset\n",
    "def read_snli(data_dir, is_train):\n",
    "    \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.\"\"\"\n",
    "    def extract_text(s):\n",
    "        s = re.sub('\\\\(', '', s)\n",
    "        s = re.sub('\\\\)', '', s)\n",
    "        s = re.sub('\\\\s{2,}', ' ', s)\n",
    "        return s.strip()\n",
    "    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n",
    "                             if is_train else 'snli_1.0_test.txt')\n",
    "    with open(file_name, 'r') as f:\n",
    "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
    "    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n",
    "    hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n",
    "    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n",
    "    return premises, hypotheses, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e8968",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Print the first 3 pairs\n",
    "train_data = read_snli(data_dir, is_train=True)\n",
    "for x0, x1, y in zip(train_data[0][:3], train_data[1][:3], train_data[2][:3]):\n",
    "    print('premise:', x0)\n",
    "    print('hypothesis:', x1)\n",
    "    print('label:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c444e7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Labels \"entailment\", \"contradiction\", and \"neutral\" are balanced\n",
    "test_data = read_snli(data_dir, is_train=False)\n",
    "for data in [train_data, test_data]:\n",
    "    print([[row for row in data[2]].count(i) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949564a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Defining a Class for Loading the Dataset\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, num_steps, vocab=None):\n",
    "        self.num_steps = num_steps\n",
    "        all_premise_tokens = d2l.tokenize(dataset[0])\n",
    "        all_hypothesis_tokens = d2l.tokenize(dataset[1])\n",
    "        if vocab is None:\n",
    "            self.vocab = d2l.Vocab(all_premise_tokens + all_hypothesis_tokens,\n",
    "                                   min_freq=5, reserved_tokens=['<pad>'])\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "        self.premises = self._pad(all_premise_tokens)\n",
    "        self.hypotheses = self._pad(all_hypothesis_tokens)\n",
    "        self.labels = torch.tensor(dataset[2])\n",
    "        print('read ' + str(len(self.premises)) + ' examples')\n",
    "\n",
    "    def _pad(self, lines):\n",
    "        return torch.tensor([d2l.truncate_pad(\n",
    "            self.vocab[line], self.num_steps, self.vocab['<pad>'])\n",
    "                         for line in lines])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.premises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608164e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Putting All Things Together\n",
    "def load_data_snli(batch_size, num_steps=50):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    data_dir = d2l.download_extract('SNLI')\n",
    "    train_data = read_snli(data_dir, True)\n",
    "    test_data = read_snli(data_dir, False)\n",
    "    train_set = SNLIDataset(train_data, num_steps)\n",
    "    test_set = SNLIDataset(test_data, num_steps, train_set.vocab)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(test_set, batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=num_workers)\n",
    "    return train_iter, test_iter, train_set.vocab\n",
    "\n",
    "train_iter, test_iter, vocab = load_data_snli(128, 50)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013d4cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for X, Y in train_iter:\n",
    "    print(X[0].shape)\n",
    "    print(X[1].shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac909d6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### fine-tune BERT on SNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ecd1a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c71304",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading Pretrained BERT\n",
    "d2l.DATA_HUB['bert.base'] = (d2l.DATA_URL + 'bert.base.torch.zip',\n",
    "                             '225d66f04cae318b841a13d32af3acc165f253ac')\n",
    "d2l.DATA_HUB['bert.small'] = (d2l.DATA_URL + 'bert.small.torch.zip',\n",
    "                              'c72329e68a732bef0452e4b96a1c341c8910f81f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb646281",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load pretrained BERT parameters\n",
    "def load_pretrained_model(pretrained_model, num_hiddens, ffn_num_hiddens,\n",
    "                          num_heads, num_layers, dropout, max_len, devices):\n",
    "    data_dir = d2l.download_extract(pretrained_model)\n",
    "    vocab = d2l.Vocab()\n",
    "    vocab.idx_to_token = json.load(open(os.path.join(data_dir, 'vocab.json')))\n",
    "    vocab.token_to_idx = {token: idx for idx, token in enumerate(\n",
    "        vocab.idx_to_token)}\n",
    "    bert = d2l.BERTModel(len(vocab), num_hiddens, norm_shape=[256],\n",
    "                         ffn_num_input=256, ffn_num_hiddens=ffn_num_hiddens,\n",
    "                         num_heads=4, num_layers=2, dropout=0.2,\n",
    "                         max_len=max_len, key_size=256, query_size=256,\n",
    "                         value_size=256, hid_in_features=256,\n",
    "                         mlm_in_features=256, nsp_in_features=256)\n",
    "    bert.load_state_dict(torch.load(os.path.join(data_dir,\n",
    "                                                 'pretrained.params')))\n",
    "    return bert, vocab\n",
    "\n",
    "devices = d2l.try_all_gpus()\n",
    "bert, vocab = load_pretrained_model(\n",
    "    'bert.small', num_hiddens=256, ffn_num_hiddens=512, num_heads=4,\n",
    "    num_layers=2, dropout=0.1, max_len=512, devices=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd1825",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The Dataset for Fine-Tuning BERT\n",
    "class SNLIBERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, max_len, vocab=None):\n",
    "        all_premise_hypothesis_tokens = [[\n",
    "            p_tokens, h_tokens] for p_tokens, h_tokens in zip(\n",
    "            *[d2l.tokenize([s.lower() for s in sentences])\n",
    "              for sentences in dataset[:2]])]\n",
    "\n",
    "        self.labels = torch.tensor(dataset[2])\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        (self.all_token_ids, self.all_segments,\n",
    "         self.valid_lens) = self._preprocess(all_premise_hypothesis_tokens)\n",
    "        print('read ' + str(len(self.all_token_ids)) + ' examples')\n",
    "\n",
    "    def _preprocess(self, all_premise_hypothesis_tokens):\n",
    "        pool = multiprocessing.Pool(4)# NLP的预处理很慢，所以必须用多进程，CV的operator都是C++写的\n",
    "        out = pool.map(self._mp_worker, all_premise_hypothesis_tokens)\n",
    "        all_token_ids = [\n",
    "            token_ids for token_ids, segments, valid_len in out]\n",
    "        all_segments = [segments for token_ids, segments, valid_len in out]\n",
    "        valid_lens = [valid_len for token_ids, segments, valid_len in out]\n",
    "        return (torch.tensor(all_token_ids, dtype=torch.long),\n",
    "                torch.tensor(all_segments, dtype=torch.long),\n",
    "                torch.tensor(valid_lens))\n",
    "\n",
    "    def _mp_worker(self, premise_hypothesis_tokens):\n",
    "        p_tokens, h_tokens = premise_hypothesis_tokens\n",
    "        self._truncate_pair_of_tokens(p_tokens, h_tokens)\n",
    "        tokens, segments = d2l.get_tokens_and_segments(p_tokens, h_tokens)\n",
    "        token_ids = self.vocab[tokens] + [self.vocab['<pad>']] \\\n",
    "                             * (self.max_len - len(tokens))\n",
    "        segments = segments + [0] * (self.max_len - len(segments))\n",
    "        valid_len = len(tokens)\n",
    "        return token_ids, segments, valid_len\n",
    "\n",
    "    def _truncate_pair_of_tokens(self, p_tokens, h_tokens):\n",
    "        while len(p_tokens) + len(h_tokens) > self.max_len - 3:\n",
    "            if len(p_tokens) > len(h_tokens):\n",
    "                p_tokens.pop()\n",
    "            else:\n",
    "                h_tokens.pop()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.all_token_ids[idx], self.all_segments[idx],\n",
    "                self.valid_lens[idx]), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650385b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This MLP transforms the BERT representation of the special “<cls>” token into three outputs of natural language inference\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.encoder = bert.encoder\n",
    "        self.hidden = bert.hidden\n",
    "        self.output = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        tokens_X, segments_X, valid_lens_x = inputs\n",
    "        encoded_X = self.encoder(tokens_X, segments_X, valid_lens_x)\n",
    "        return self.output(self.hidden(encoded_X[:, 0, :])) # 拿到CLS\n",
    "\n",
    "net = BERTClassifier(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12a9e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The training\n",
    "lr, num_epochs = 1e-4, 5\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7d9fe",
   "metadata": {},
   "source": [
    "# torch_hand_written_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa582e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pytorch代码Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c8fbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''数据准备'''\n",
    "# Starting Reference: http://nlp.seas.harvard.edu/2018/04/03/attention.html#greedy-decoding\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "             # Encoder_input    Decoder_input        Decoder_output\n",
    "sentences = [['我 是 学 生 P' , 'S I am a student'   , 'I am a student E'],         # S: 开始符号\n",
    "             ['我 喜 欢 学 习', 'S I like learning P', 'I like learning P E'],      # E: 结束符号\n",
    "             ['我 是 男 生 P' , 'S I am a boy'       , 'I am a boy E']]             # P: 占位符号，如果当前句子不足固定长度用P占位\n",
    "\n",
    "src_vocab = {'P':0, '我':1, '是':2, '学':3, '生':4, '喜':5, '欢':6,'习':7,'男':8}   # 词源字典  字：索引\n",
    "src_idx2word = {src_vocab[key]: key for key in src_vocab}\n",
    "src_vocab_size = len(src_vocab)                                                     # 字典字的个数\n",
    "tgt_vocab = {'S':0, 'E':1, 'P':2, 'I':3, 'am':4, 'a':5, 'student':6, 'like':7, 'learning':8, 'boy':9}\n",
    "idx2word = {tgt_vocab[key]: key for key in tgt_vocab}                               # 把目标字典转换成 索引：字的形式\n",
    "tgt_vocab_size = len(tgt_vocab)                                                     # 目标字典尺寸\n",
    "src_len = len(sentences[0][0].split(\" \"))                                           # Encoder输入的最大长度\n",
    "tgt_len = len(sentences[0][1].split(\" \"))                                           # Decoder输入输出最大长度\n",
    "\n",
    "# 把sentences 转换成字典索引\n",
    "def make_data(sentences):\n",
    "    enc_inputs, dec_inputs, dec_outputs = [], [], []\n",
    "    for i in range(len(sentences)):\n",
    "      enc_input = [[src_vocab[n] for n in sentences[i][0].split()]] \n",
    "      dec_input = [[tgt_vocab[n] for n in sentences[i][1].split()]] \n",
    "      dec_output = [[tgt_vocab[n] for n in sentences[i][2].split()]] \n",
    "      enc_inputs.extend(enc_input)\n",
    "      dec_inputs.extend(dec_input)\n",
    "      dec_outputs.extend(dec_output)\n",
    "    return torch.LongTensor(enc_inputs), torch.LongTensor(dec_inputs), torch.LongTensor(dec_outputs)\n",
    "enc_inputs, dec_inputs, dec_outputs = make_data(sentences)\n",
    "\n",
    "#自定义数据集函数\n",
    "class MyDataSet(Data.Dataset):\n",
    "  def __init__(self, enc_inputs, dec_inputs, dec_outputs):\n",
    "    super(MyDataSet, self).__init__()\n",
    "    self.enc_inputs = enc_inputs\n",
    "    self.dec_inputs = dec_inputs\n",
    "    self.dec_outputs = dec_outputs\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.enc_inputs.shape[0]\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]\n",
    "\n",
    "loader = Data.DataLoader(MyDataSet(enc_inputs, dec_inputs, dec_outputs), 2, True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1be51",
   "metadata": {
    "hidden": true
   },
   "source": [
    "sentences 里一共有三个训练数据，中文->英文。把Encoder_input、Decoder_input、Decoder_output转换成字典索引，例如\"学\"->3、\"student\"->6。再把数据转换成batch大小为2的分组数据，3句话一共可以分成两组，一组2句话、一组1句话。src_len表示中文句子固定最大长度，tgt_len 表示英文句子固定最大长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c6297",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''参数设置'''\n",
    "d_model = 512   # 字 Embedding 的维度\n",
    "d_ff = 2048     # 前向传播隐藏层维度\n",
    "d_k = d_v = 64  # K(=Q), V的维度 \n",
    "n_layers = 6    # 有多少个encoder和decoder\n",
    "n_heads = 8     # Multi-Head Attention设置为8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9010c70",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''sin位置信息：生成位置信息矩阵，直接加上输入的Embedding上，得到带有位置信息的词嵌入'''\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout) \n",
    "        pos_table = np.array([\n",
    "        [pos / np.power(10000, 2 * i / d_model) for i in range(d_model)]\n",
    "        if pos != 0 else np.zeros(d_model) for pos in range(max_len)])\n",
    "        pos_table[1:, 0::2] = np.sin(pos_table[1:, 0::2])                  # 字嵌入维度为偶数时\n",
    "        pos_table[1:, 1::2] = np.cos(pos_table[1:, 1::2])                  # 字嵌入维度为奇数时\n",
    "        self.pos_table = torch.LongTensor(pos_table).unsqueeze(1).cuda()\n",
    "\n",
    "    def forward(self, enc_inputs):                                         # enc_inputs: [seq_len, batch_size, d_model]\n",
    "        enc_inputs += self.pos_table[:enc_inputs.size(0), :]\n",
    "        return self.dropout(enc_inputs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da9bb9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''Mask掉停用词：Mask句子中没有实际意义的占位符，例如'我 是 学 生 P' ，P对应句子没有实际意义，随意需要被Mask，Encoder_input 和Decoder_input占位符都需要被Mask '''\n",
    "def get_attn_pad_mask(seq_q, seq_k):                       # seq_q: [batch_size, seq_len] ,seq_k: [batch_size, seq_len]\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)          # 判断 输入那些含有P(=0),用1标记 ,[batch_size, 1, len_k]\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # 扩展成多维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840184ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''Decoder 输入 Mask'''\n",
    "def get_attn_subsequence_mask(seq):                               # seq: [batch_size, tgt_len]\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1)          # 生成上三角矩阵,[batch_size, tgt_len, tgt_len]\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()  #  [batch_size, tgt_len, tgt_len]\n",
    "    return subsequence_mask       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7dd01",
   "metadata": {
    "hidden": true
   },
   "source": [
    "用来Mask未来输入信息，返回的是一个上三角矩阵。比如我们在中英文翻译时候，会先把\"我是学生\"整个句子输入到Encoder中，得到最后一层的输出后，才会在Decoder输入\"S I am a student\"（s表示开始）,但是\"S I am a student\"这个句子我们不会一起输入，而是在T0时刻先输入\"S\"预测，预测第一个词\"I\"；在下一个T1时刻，同时输入\"S\"和\"I\"到Decoder预测下一个单词\"am\"；然后在T2时刻把\"S,I,am\"同时输入到Decoder预测下一个单词\"a\"，依次把整个句子输入到Decoder,预测出\"I am a student E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc4a8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''计算注意力信息、残差和归一化'''\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):                             # Q: [batch_size, n_heads, len_q, d_k]\n",
    "                                                                       # K: [batch_size, n_heads, len_k, d_k]\n",
    "                                                                       # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "                                                                       # attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)   # scores : [batch_size, n_heads, len_q, len_k]\n",
    "        scores.masked_fill_(attn_mask, -1e9)                           # 如果时停用词P就等于 0 \n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)                                # [batch_size, n_heads, len_q, d_v]\n",
    "        return context, attn\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "        \n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):    # input_Q: [batch_size, len_q, d_model]\n",
    "                                                                # input_K: [batch_size, len_k, d_model]\n",
    "                                                                # input_V: [batch_size, len_v(=len_k), d_model]\n",
    "                                                                # attn_mask: [batch_size, seq_len, seq_len]\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)              # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)          # context: [batch_size, n_heads, len_q, d_v]\n",
    "                                                                                 # attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) # context: [batch_size, len_q, n_heads * d_v]\n",
    "        output = self.fc(context)                                                # [batch_size, len_q, d_model]\n",
    "        return nn.LayerNorm(d_model).cuda()(output + residual), attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b46a5b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "计算注意力信息，W^Q,W^K,W^V矩阵会拆分成8个小矩阵。细节请看2.2章。注意传入的input_Q, input_K, input_V，在Encoder和Decoder的第一次调用传入的三个矩阵是相同的，但Decoder的第二次调用传入的三个矩阵input_Q 等于 input_K 不等于 input_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba0c56",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''前馈神经网络FeedForwardNet'''\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False))\n",
    "        \n",
    "    def forward(self, inputs):                             # inputs: [batch_size, seq_len, d_model]\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(d_model).cuda()(output + residual)   # [batch_size, seq_len, d_model]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86f0092",
   "metadata": {
    "hidden": true
   },
   "source": [
    "输入inputs ，经过两个全连接成，得到的结果再加上 inputs ，再做LayerNorm归一化。LayerNorm归一化可以理解层是把Batch中每一句话进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e96756",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''单个encoder'''\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()                                     # 多头注意力机制\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()                                        # 前馈神经网络\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):                                # enc_inputs: [batch_size, src_len, d_model]\n",
    "        #输入3个enc_inputs分别与W_q、W_k、W_v相乘得到Q、K、V                          # enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs,    # enc_outputs: [batch_size, src_len, d_model], \n",
    "                                               enc_self_attn_mask)                    # attn: [batch_size, n_heads, src_len, src_len]                                                                   \n",
    "        enc_outputs = self.pos_ffn(enc_outputs)                                       # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff6058",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''整个Encoder'''\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)                     # 把字转换字向量 \n",
    "        self.pos_emb = PositionalEncoding(d_model)                               # 加入位置信息\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):                                               # enc_inputs: [batch_size, src_len]\n",
    "        enc_outputs = self.src_emb(enc_inputs)                                   # enc_outputs: [batch_size, src_len, d_model]\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1)  # enc_outputs: [batch_size, src_len, d_model]   \n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)           # enc_self_attn_mask: [batch_size, src_len, src_len]\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)  # enc_outputs :   [batch_size, src_len, d_model], \n",
    "                                                                                 # enc_self_attn : [batch_size, n_heads, src_len, src_len]\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf6900",
   "metadata": {
    "hidden": true
   },
   "source": [
    "第一步，中文字索引进行Embedding，转换成512维度的字向量。第二步，在子向量上面加上位置信息。第三步，Mask掉句子中的占位符号。第四步，通过6层的encoder（上一层的输出作为下一层的输入）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb3388",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''单个decoder'''\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.dec_enc_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask): # dec_inputs: [batch_size, tgt_len, d_model]\n",
    "                                                                                       # enc_outputs: [batch_size, src_len, d_model]\n",
    "                                                                                       # dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "                                                                                       # dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, \n",
    "                                                 dec_inputs, dec_self_attn_mask)   # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "                                                                                   # dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, \n",
    "                                                enc_outputs, dec_enc_attn_mask)    # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "                                                                                   # dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)                                    # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae83e7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "decoder两次调用MultiHeadAttention时，第一次调用传入的 Q，K，V 的值是相同的，都等于dec_inputs，第二次调用 Q 矩阵是来自Decoder的输入。K，V 两个矩阵是来自Encoder的输出，等于enc_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea089f95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''整个Decoder'''\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):                               # dec_inputs: [batch_size, tgt_len]\n",
    "                                                                                          # enc_intpus: [batch_size, src_len]\n",
    "                                                                                          # enc_outputs: [batsh_size, src_len, d_model]\n",
    "        dec_outputs = self.tgt_emb(dec_inputs)                                            # [batch_size, tgt_len, d_model]       \n",
    "        dec_outputs = self.pos_emb(dec_outputs.transpose(0, 1)).transpose(0, 1).cuda()    # [batch_size, tgt_len, d_model]\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).cuda()         # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs).cuda()     # [batch_size, tgt_len, tgt_len]\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + \n",
    "                                       dec_self_attn_subsequence_mask), 0).cuda()         # [batch_size, tgt_len, tgt_len]\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)                     # [batc_size, tgt_len, src_len]\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:                             # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "                                                              # dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "                                                              # dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e952de6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "第一步，英文字索引进行Embedding，转换成512维度的字向量。第二步，在子向量上面加上位置信息。第三步，Mask掉句子中的占位符号和输出顺序细节见3.1。第四步，通过6层的decoder（上一层的输出作为下一层的输入）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55a548",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''Trasformer'''\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.Encoder = Encoder().cuda()\n",
    "        self.Decoder = Decoder().cuda()\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False).cuda()\n",
    "    def forward(self, enc_inputs, dec_inputs):                         # enc_inputs: [batch_size, src_len]  \n",
    "                                                                       # dec_inputs: [batch_size, tgt_len]\n",
    "        enc_outputs, enc_self_attns = self.Encoder(enc_inputs)         # enc_outputs: [batch_size, src_len, d_model], \n",
    "                                                                       # enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.Decoder(\n",
    "            dec_inputs, enc_inputs, enc_outputs)                       # dec_outpus    : [batch_size, tgt_len, d_model], \n",
    "                                                                       # dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], \n",
    "                                                                       # dec_enc_attn  : [n_layers, batch_size, tgt_len, src_len]\n",
    "        dec_logits = self.projection(dec_outputs)                      # dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5a77b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Trasformer的整体结构，输入数据先通过Encoder，再同个Decoder，最后把输出进行多分类，分类数为英文字典长度，也就是判断每一个字的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14266d71",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''定义网络'''\n",
    "model = Transformer().cuda()\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)     #忽略 占位符 索引为0.\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ef111",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''训练Transformer'''\n",
    "for epoch in range(50):\n",
    "    for enc_inputs, dec_inputs, dec_outputs in loader:         # enc_inputs : [batch_size, src_len]\n",
    "                                                               # dec_inputs : [batch_size, tgt_len]\n",
    "                                                               # dec_outputs: [batch_size, tgt_len]\n",
    "      \n",
    "      enc_inputs, dec_inputs, dec_outputs = enc_inputs.cuda(), dec_inputs.cuda(), dec_outputs.cuda()                                                             \n",
    "      outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "                                                               # outputs: [batch_size * tgt_len, tgt_vocab_size]\n",
    "      loss = criterion(outputs, dec_outputs.view(-1))\n",
    "      print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84438de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''测试网络'''\n",
    "def test(model, enc_input, start_symbol):\n",
    "    # Starting Reference: http://nlp.seas.harvard.edu/2018/04/03/attention.html#greedy-decoding\n",
    "    enc_outputs, enc_self_attns = model.Encoder(enc_input)\n",
    "    dec_input = torch.zeros(1, tgt_len).type_as(enc_input.data)\n",
    "    next_symbol = start_symbol\n",
    "    for i in range(0, tgt_len):\n",
    "        dec_input[0][i] = next_symbol\n",
    "        dec_outputs, _, _ = model.Decoder(dec_input, enc_input, enc_outputs)\n",
    "        projected = model.projection(dec_outputs)\n",
    "        prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]\n",
    "        next_word = prob.data[i]\n",
    "        next_symbol = next_word.item()\n",
    "    return dec_input\n",
    "\n",
    "enc_inputs, _, _ = next(iter(loader))\n",
    "predict_dec_input = test(model, enc_inputs[0].view(1, -1).cuda(), start_symbol=tgt_vocab[\"S\"])\n",
    "predict, _, _, _ = model(enc_inputs[0].view(1, -1).cuda(), predict_dec_input)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "\n",
    "print([src_idx2word[int(i)] for i in enc_inputs[0]], '->', \n",
    "[idx2word[n.item()] for n in predict.squeeze()])\n",
    "# ['我', '是', '男', '生', 'P'] -> ['I', 'am', 'a', 'boy', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb990c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''打印Transformer模型'''\n",
    "print(model)\n",
    "'''\n",
    "Transformer(\n",
    "(Encoder): Encoder(\n",
    "(src_emb): Embedding(9, 512)\n",
    "(pos_emb): PositionalEncoding(\n",
    "(dropout): Dropout(p=0.1, inplace=False)\n",
    ")\n",
    "(layers): ModuleList(\n",
    "(0): EncoderLayer(\n",
    "(enc_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(1): EncoderLayer(\n",
    "(enc_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(2): EncoderLayer(\n",
    "(enc_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(3): EncoderLayer(\n",
    "(enc_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(4): EncoderLayer(\n",
    "(enc_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(5): EncoderLayer(\n",
    "(enc_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    ")\n",
    ")\n",
    "(Decoder): Decoder(\n",
    "(tgt_emb): Embedding(10, 512)\n",
    "(pos_emb): PositionalEncoding(\n",
    "(dropout): Dropout(p=0.1, inplace=False)\n",
    ")\n",
    "(layers): ModuleList(\n",
    "(0): DecoderLayer(\n",
    "(dec_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(dec_enc_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(1): DecoderLayer(\n",
    "(dec_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(dec_enc_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(2): DecoderLayer(\n",
    "(dec_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(dec_enc_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(3): DecoderLayer(\n",
    "(dec_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(dec_enc_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(4): DecoderLayer(\n",
    "(dec_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(dec_enc_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    "(5): DecoderLayer(\n",
    "(dec_self_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(dec_enc_attn): MultiHeadAttention(\n",
    "(W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_K): Linear(in_features=512, out_features=512, bias=False)\n",
    "(W_V): Linear(in_features=512, out_features=512, bias=False)\n",
    "(fc): Linear(in_features=512, out_features=512, bias=False)\n",
    ")\n",
    "(pos_ffn): PoswiseFeedForwardNet(\n",
    "(fc): Sequential(\n",
    "(0): Linear(in_features=512, out_features=2048, bias=False)\n",
    "(1): ReLU()\n",
    "(2): Linear(in_features=2048, out_features=512, bias=False)\n",
    ")\n",
    ")\n",
    ")\n",
    ")\n",
    ")\n",
    "(projection): Linear(in_features=512, out_features=10, bias=False)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85195b43",
   "metadata": {},
   "source": [
    "## pytorch预训练BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c01d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T16:16:17.725203Z",
     "start_time": "2021-09-14T16:16:17.700202Z"
    }
   },
   "outputs": [],
   "source": [
    "'''头文件'''\n",
    "import copy\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from random import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''设置的参数'''\n",
    "class BertConfig():\n",
    "    def __init__(self):\n",
    "          self.attention_probs_dropout_prob= 0.1           # 注意力处dropout值\n",
    "          self.hidden_act= \"gelu\"                          # 隐藏层使用的激活函数\n",
    "          self.hidden_dropout_prob= 0.1                    # 隐藏层处dropout的值\n",
    "          self.hidden_size= 1024                           # 隐藏层大小，字向量长度\n",
    "          self.initializer_range= 0.02                     # bert模型初始化方差值\n",
    "          self.intermediate_size= 4096                     # 前向传播隐藏层大小\n",
    "          self.max_position_embeddings= 512                # 位置信息长度 512\n",
    "          self.num_attention_heads= 16                     # 注意力头的个数\n",
    "          self.num_hidden_layers= 24                       # encoder 层数\n",
    "          self.type_vocab_size= 2                          # 句子类型，标记第一句话和第二句话\n",
    "          self.vocab_size= 21128                           # 字典大小21128\n",
    "          self.seq_length = 40                             # tokens总长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d83aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''数据的预处理'''\n",
    "config = BertConfig()\n",
    "data = ['有生之年',\n",
    "        '愿你勇敢',\n",
    "        '愿你平安',\n",
    "        '愿你没有苦难',\n",
    "        '活的简单',\n",
    "        '愿你累了倦了有人为你分担',\n",
    "        '愿你每个夜晚都会有美梦作伴',\n",
    "        '愿你长路漫漫得偿所愿',\n",
    "        '愿这世间烦恼从此与你无关',\n",
    "        '愿你遇事全部得你心欢',\n",
    "        '愿你前程似锦',\n",
    "        '不凡此生']\n",
    "\n",
    "#建立字典 编号 <--> 字 的对应关系\n",
    "s = set([ i for j in data for i in j])\n",
    "                                                  # 字典大小\n",
    "word2idx = {'PAD' : 0, 'CLS' : 1, 'SEP' : 2, 'MASK' : 3}             # 特殊字符\n",
    "for idx, word in enumerate(s):\n",
    "    word2idx[word] = idx+4                                           # 字   -> 编号\n",
    "idx2word = {word2idx[key]:key for key in word2idx}                   # 编号 -> 字\n",
    "vocab_size = len(idx2word)\n",
    "\n",
    "#把句子的字变成编号\n",
    "sentences = []\n",
    "for sentence in data:\n",
    "    tmp = []\n",
    "    for i, word in enumerate(sentence):\n",
    "        tmp.append(word2idx[word])\n",
    "    sentences.append(tmp)\n",
    "\n",
    "# 自定义Dataset\n",
    "batch_size = 32\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.sentences = []\n",
    "        for sentence in data:\n",
    "            tmp = []\n",
    "            for i, word in enumerate(sentence):\n",
    "                tmp.append(word2idx[word])\n",
    "            self.sentences.append(tmp)\n",
    "        self.sentences_len = len(self.sentences)\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)*2-2  \n",
    "    def __getitem__(self, idx):\n",
    "        sentences = copy.deepcopy(self.sentences)       \n",
    "        input_ids = []\n",
    "        token_type_ids = []\n",
    "        next_sentence_label = []\n",
    "\n",
    "        if idx%2 == 0:\n",
    "            s = [word2idx['CLS']] + sentences[int(idx//2)] + [word2idx['SEP']] + sentences[int(idx//2)+1] + [word2idx['SEP']]\n",
    "            input_ids = s+[0]*(config.seq_length-len(s))\n",
    "            token_type_ids = [0]*(1+len(sentences[int(idx//2)])+1) + [1]*(len(sentences[int(idx//2+1)])+1) + [0]*(config.seq_length-len(s))\n",
    "            next_sentence_label = [1]\n",
    "        else:\n",
    "            rand = int(idx//2)+1\n",
    "            while rand ==  idx//2+1:\n",
    "                rand = randint(0, self.sentences_len-1)\n",
    "            s =[word2idx['CLS']] + sentences[int(idx//2)] + [word2idx['SEP']] + sentences[rand] + [word2idx['SEP']]\n",
    "            input_ids = s+[0]*(config.seq_length-len(s))\n",
    "            token_type_ids = [0]*(1+len(sentences[int(idx//2)])+1) + [1]*(len(sentences[rand])+1) + [0]*(config.seq_length-len(s))\n",
    "            next_sentence_label = [0]\n",
    "            \n",
    "        attention_mask = []\n",
    "        masked_lm_labels = []\n",
    "        for pos, value in enumerate(input_ids):\n",
    "            rand = random()\n",
    "            if value == 0:\n",
    "                attention_mask.append(0) \n",
    "            else:\n",
    "                attention_mask.append(1)\n",
    "            if value != 0 and value != 1 and value != 2 and rand < 0.15:   \n",
    "                    masked_lm_labels.append(input_ids[pos]) \n",
    "                    if rand < 0.15*0.8:\n",
    "                        input_ids[pos] = word2idx[\"MASK\"]\n",
    "                    elif rand > 0.15*0.9:\n",
    "                        input_ids[pos] = randint(4, vocab_size)           \n",
    "            else:  \n",
    "                masked_lm_labels.append(-1)          \n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "        next_sentence_label = torch.tensor(next_sentence_label)\n",
    "        attention_mask = torch.tensor(attention_mask)\n",
    "        masked_lm_labels = torch.tensor(masked_lm_labels)\n",
    "        return input_ids, token_type_ids, attention_mask, masked_lm_labels, next_sentence_label\n",
    "data_loader = Data.DataLoader(MyDataSet(data), batch_size, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b557f",
   "metadata": {},
   "source": [
    "数据预处是采用动态Mask和动态下句随机匹配，每一次迭代，epoch的数据都不同。\n",
    "\n",
    "    input_ids : 句子的字典索引\n",
    "    token_type_ids：用1和0区分第一个句子和第二个句子\n",
    "    attention_mask：标记句子中选出15%的token。\n",
    "    masked_lm_labels:标记被mask的真实字典索引值。\n",
    "    next_sentence_label：标记两句话是否连续\n",
    "建议读者一步一步打印每一个变量输出，对照上文观察得到的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684eda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义激活函数和归一化'''\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
    "\n",
    "class BertLayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        super(BertLayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):                                  \n",
    "        u = x.mean(-1, keepdim=True)                          # 最后一个维度上求均值，可以理解在字向量上\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)             # 最后一个维度上求均值，可以理解在字向量上\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BertEmbeddings'''\n",
    "# Bert的输入\n",
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):  # input_ids:(batch, seq_length)    token_type_ids:(batch, seq_length) \n",
    "        seq_length = input_ids.size(1)                                      \n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)   # (seq_length)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)                        # (batch, seq_length)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        words_embeddings = self.word_embeddings(input_ids)                                   # (batch, seq_length, hidden_size)\n",
    "        position_embeddings = self.position_embeddings(position_ids)                         # (batch, seq_length, hidden_size)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)                   # (batch, seq_length, hidden_size)\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)                                              # 最后一个维度求归一化\n",
    "        embeddings = self.dropout(embeddings)                                                    \n",
    "        return embeddings   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30276f",
   "metadata": {},
   "source": [
    "    Token Embeddings：是数据预处理后语句的字典索引。\n",
    "    Segment Embeddings：标记那些是第一句话，那些是第二句话。\n",
    "    Position Embeddings：标记这个token在这句话处的位置。\n",
    "把它们映射到维度相同高维空间，再加起来，input = Token Embeddings + Segment Embeddings + Position Embeddings，得到Encoder的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4828d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Encoder的Self-Attention Mechanism'''\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertSelfAttention, self).__init__()\n",
    "        self.num_attention_heads = config.num_attention_heads                            # num_attention_heads个注意力\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)  # 每一个注意力大小1024/16=64\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size         # all_head_size：16*64=1024\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)                   # (hidden_size，attention_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)                     # (hidden_size，attention_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)                   # (hidden_size，attention_head_size)\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):              # q, k, v 改变形状\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size) \n",
    "                                                                                   #  new_x_shape:元组(batch，seq_len, num_attention_heads,attention_head_size)\n",
    "        x = x.view(*new_x_shape)                                                   # (batch，seq_len, num_attention_heads, attention_head_size)\n",
    "        return x.permute(0, 2, 1, 3)                                               # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):                              # (batch, seq_length, hidden_size)，(batch,1,1,sqe_len)\n",
    "        mixed_query_layer = self.query(hidden_states)                              # (batch, seq_len, hidden_size)\n",
    "        mixed_key_layer = self.key(hidden_states)                                  # (batch, seq_len, hidden_size)\n",
    "        mixed_value_layer = self.value(hidden_states)                              # (batch, seq_len, hidden_size)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)                 # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)                     # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)                 # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))  # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)  # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_scores = attention_scores + attention_mask                       # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)                     # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_probs = self.dropout(attention_probs)                            # (batch, num_attention_heads, seq_len, seq_len)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)                 # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()             # (batch, seq_len，num_attention_heads, attention_head_size)\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)# (batch, seq_len，hidden_size)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)               # (batch, seq_len，hidden_size)\n",
    "        return context_layer                                                       # (batch, seq_len，hidden_size)\n",
    "\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertSelfOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):                   # (batch, seq_len，hidden_size),(batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dense(hidden_states)                     # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dropout(hidden_states)                   # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)  # (batch, seq_len，hidden_size)\n",
    "        return hidden_states                                          # (batch, seq_len，hidden_size)\n",
    "\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertAttention, self).__init__()\n",
    "        self.self = BertSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "\n",
    "    def forward(self, input_tensor, attention_mask):  # hidden_states:(batch, seq_length, hidden_size)，attention_mask:(batch,1,1,sqe_len)\n",
    "        self_output = self.self(input_tensor, attention_mask)         # (batch, seq_len，hidden_size)\n",
    "        attention_output = self.output(self_output, input_tensor)     # (batch, seq_len，hidden_size)\n",
    "        return attention_output                                       # (batch, seq_len，hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a791a3c",
   "metadata": {},
   "source": [
    "先计算出第一个token与句子中的每一个token的注意力分数（包括第一个token），再用计算出的注意力分数乘以对应token的信息，然后加在一起，得到的结果就是第一个token与句子中所有token的加权和信息，依次更新每一个token与句子的注意力信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b292108",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Encoder的Add & Layer normalization:利用了残差网络可能增加网络深度性，归一化可以加快网络收敛'''\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertIntermediate, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states):                               # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dense(hidden_states)                   # (batch, seq_len，intermediate_size)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)     # (batch, seq_len，intermediate_size)\n",
    "        return hidden_states\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):                 # (batch, seq_len，intermediate_size)\n",
    "        hidden_states = self.dense(hidden_states)                   # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dropout(hidden_states)                 # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)# (batch, seq_len，hidden_size)\n",
    "        return hidden_states                                        # (batch, seq_len，hidden_size)\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertLayer, self).__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):  # hidden_states:(batch, seq_length, hidden_size)，attention_mask:(batch,1,1,sqe_len)\n",
    "        attention_output = self.attention(hidden_states, attention_mask)      # (batch, seq_len，hidden_size)\n",
    "        intermediate_output = self.intermediate(attention_output)             # (batch, seq_len，intermediate_size)\n",
    "        layer_output = self.output(intermediate_output, attention_output)     # (batch, seq_len，hidden_size)\n",
    "        return layer_output                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01e82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Encoder : 组合成24层的Encoder'''\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        layer = BertLayer(config)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):  # hidden_states:(batch, seq_length, hidden_size)，attention_mask:(batch,1,1,sqe_len)      \n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)        # (batch, seq_len，hidden_size)\n",
    "            if output_all_encoded_layers:                                      # 输出每一层的内容\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:                                      # 输出最后一层的内容                  \n",
    "            all_encoder_layers.append(hidden_states)                           # (batch, seq_len，hidden_size)\n",
    "        return all_encoder_layers                                              # (batch, seq_len，hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BertPooler（处理CLS信息）: 获取Encoder最后已层输出的第一个token，也就是\"CLS\"的编码后的特征信息'''\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):                          # (batch, seq_length, hidden_size)\n",
    "        first_token_tensor = hidden_states[:, 0]               # 每个句子的第一个token (batch, hidden_size)\n",
    "        pooled_output = self.dense(first_token_tensor)         # (batch, hidden_size)\n",
    "        pooled_output = self.activation(pooled_output)         # (batch, hidden_size)\n",
    "        return pooled_output                                   # (batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8377d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''预训练模型加载，保存'''\n",
    "class BertPreTrainedModel(nn.Module):\n",
    "    #处理权重和下载、加载模型\n",
    "    def __init__(self, config, *inputs, **kwargs):\n",
    "        super(BertPreTrainedModel, self).__init__()\n",
    "        if not isinstance(config, BertConfig):\n",
    "            raise ValueError(\n",
    "                \"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"\n",
    "                \"To create a model from a Google pretrained model use \"\n",
    "                \"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(\n",
    "                    self.__class__.__name__, self.__class__.__name__\n",
    "                ))\n",
    "        self.config = config\n",
    "\n",
    "    def init_bert_weights(self, module):\n",
    "        # 初始化权重\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        elif isinstance(module, BertLayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n",
    "       # 预先训练的模型下载并缓存预先训练的模型文件。\n",
    "        state_dict = kwargs.get('state_dict', None)\n",
    "        kwargs.pop('state_dict', None)\n",
    "        cache_dir = kwargs.get('cache_dir', None)\n",
    "        kwargs.pop('cache_dir', None)\n",
    "        from_tf = kwargs.get('from_tf', False)\n",
    "        kwargs.pop('from_tf', None)\n",
    "\n",
    "        if pretrained_model_name_or_path in PRETRAINED_MODEL_ARCHIVE_MAP:\n",
    "            archive_file = PRETRAINED_MODEL_ARCHIVE_MAP[pretrained_model_name_or_path]\n",
    "        else:\n",
    "            archive_file = pretrained_model_name_or_path\n",
    "        try:\n",
    "            resolved_archive_file = cached_path(archive_file, cache_dir=cache_dir)\n",
    "        except EnvironmentError:\n",
    "            logger.error(\n",
    "                \"Model name '{}' was not found in model name list ({}). \"\n",
    "                \"We assumed '{}' was a path or url but couldn't find any file \"\n",
    "                \"associated to this path or url.\".format(\n",
    "                    pretrained_model_name_or_path,\n",
    "                    ', '.join(PRETRAINED_MODEL_ARCHIVE_MAP.keys()),archive_file))\n",
    "            return None\n",
    "        if resolved_archive_file == archive_file:\n",
    "            logger.info(\"loading archive file {}\".format(archive_file))\n",
    "        else:\n",
    "            logger.info(\"loading archive file {} from cache at {}\".format(archive_file, resolved_archive_file))\n",
    "        tempdir = None\n",
    "        if os.path.isdir(resolved_archive_file) or from_tf:\n",
    "            serialization_dir = resolved_archive_file\n",
    "        else:\n",
    "            tempdir = tempfile.mkdtemp()\n",
    "            logger.info(\"extracting archive file {} to temp dir {}\".format(resolved_archive_file, tempdir))\n",
    "            with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
    "                archive.extractall(tempdir)\n",
    "            serialization_dir = tempdir\n",
    "        config_file = os.path.join(serialization_dir, CONFIG_NAME)   # 加载 config文件\n",
    "        if not os.path.exists(config_file):\n",
    "            config_file = os.path.join(serialization_dir, BERT_CONFIG_NAME)\n",
    "        config = BertConfig.from_json_file(config_file)\n",
    "        logger.info(\"Model config {}\".format(config))\n",
    "        model = cls(config, *inputs, **kwargs)\n",
    "        if state_dict is None and not from_tf:\n",
    "            weights_path = os.path.join(serialization_dir, WEIGHTS_NAME)\n",
    "            state_dict = torch.load(weights_path, map_location='cpu')\n",
    "        if tempdir:\n",
    "            # Clean up temp dir\n",
    "            shutil.rmtree(tempdir)\n",
    "        if from_tf:\n",
    "            weights_path = os.path.join(serialization_dir, TF_WEIGHTS_NAME)\n",
    "            return load_tf_weights_in_bert(model, weights_path)\n",
    "        old_keys = []\n",
    "        new_keys = []\n",
    "        for key in state_dict.keys():\n",
    "            new_key = None\n",
    "            if 'gamma' in key:\n",
    "                new_key = key.replace('gamma', 'weight')\n",
    "            if 'beta' in key:\n",
    "                new_key = key.replace('beta', 'bias')\n",
    "            if new_key:\n",
    "                old_keys.append(key)\n",
    "                new_keys.append(new_key)\n",
    "        for old_key, new_key in zip(old_keys, new_keys):\n",
    "            state_dict[new_key] = state_dict.pop(old_key)\n",
    "\n",
    "        missing_keys = []\n",
    "        unexpected_keys = []\n",
    "        error_msgs = []\n",
    "        metadata = getattr(state_dict, '_metadata', None)\n",
    "        state_dict = state_dict.copy()\n",
    "        if metadata is not None:\n",
    "            state_dict._metadata = metadata\n",
    "\n",
    "        def load(module, prefix=''):\n",
    "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
    "            module._load_from_state_dict(\n",
    "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "            for name, child in module._modules.items():\n",
    "                if child is not None:\n",
    "                    load(child, prefix + name + '.')\n",
    "        start_prefix = ''\n",
    "        if not hasattr(model, 'bert') and any(s.startswith('bert.') for s in state_dict.keys()):\n",
    "            start_prefix = 'bert.'\n",
    "        load(model, prefix=start_prefix)\n",
    "        if len(missing_keys) > 0:\n",
    "            logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(model.__class__.__name__, missing_keys))\n",
    "        if len(unexpected_keys) > 0:\n",
    "            logger.info(\"Weights from pretrained model not used in {}: {}\".format(model.__class__.__name__, unexpected_keys))\n",
    "        if len(error_msgs) > 0:\n",
    "            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(model.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BertModel :把前面定义的类组合成Bert '''\n",
    "class BertModel(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertModel, self).__init__(config)\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)                        # (batch,1,1,sqe_len)\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # (batch,1,1,sqe_len)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0                      # 只计算被标记的位置(batch,1,1,sqe_len)\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)                             # (batch, seq_length, hidden_size)\n",
    "        encoded_layers = self.encoder(embedding_output,                                           # (batch, seq_length, hidden_size)\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
    "        sequence_output = encoded_layers[-1]                                                      # 取出encoder最后一层输出(batch, seq_length, hidden_size)           \n",
    "        pooled_output = self.pooler(sequence_output)                                              # 返回CLS的特征(batch, hidden_size)\n",
    "        if not output_all_encoded_layers:\n",
    "            encoded_layers = encoded_layers[-1]\n",
    "        return encoded_layers, pooled_output            #  返回最后一层的数据：(batch, seq_length, hidden_size),返回CLS的特征(batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''预训练BertPreTrainingHeads（可以理解成bert接的下游任务）: \n",
    "对预训练做准备，把\"CLS\"转换成大小为（batch, 2）。把Bert整个输出转换成大小为(batch, seq_length,vocab_size)，方便后面做损失'''\n",
    "class BertPredictionHeadTransform(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPredictionHeadTransform, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
    "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.transform_act_fn = config.hidden_act\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "\n",
    "    def forward(self, hidden_states):                                     # bert输出(batch, seq_length, hidden_size)\n",
    "        hidden_states = self.dense(hidden_states)                         # bert输出(batch, seq_length, hidden_size)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)              # 激活函数\n",
    "        hidden_states = self.LayerNorm(hidden_states)                     # 归一化\n",
    "        return hidden_states                                              # (batch, seq_length, hidden_size)\n",
    "\n",
    "class BertLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config, bert_model_embedding_weights):\n",
    "        super(BertLMPredictionHead, self).__init__()\n",
    "        self.transform = BertPredictionHeadTransform(config)\n",
    "        self.decoder = nn.Linear(bert_model_embedding_weights.size(1),\n",
    "                                 bert_model_embedding_weights.size(0),\n",
    "                                 bias=False)\n",
    "        self.decoder.weight = bert_model_embedding_weights\n",
    "        self.bias = nn.Parameter(torch.zeros(bert_model_embedding_weights.size(0)))\n",
    "\n",
    "    def forward(self, hidden_states):                                      # bert输出(batch, seq_length, hidden_size)\n",
    "        hidden_states = self.transform(hidden_states)                      # (batch, seq_length, hidden_size)\n",
    "        hidden_states = self.decoder(hidden_states) + self.bias            # (batch, seq_length,vocab_size)   \n",
    "        return hidden_states                                               # (batch, seq_length,vocab_size) \n",
    "\n",
    "class BertPreTrainingHeads(nn.Module):\n",
    "    def __init__(self, config, bert_model_embedding_weights):\n",
    "        super(BertPreTrainingHeads, self).__init__()\n",
    "        self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
    "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, sequence_output, pooled_output):                # bert输出(batch, seq_length, hidden_size),CLS的特征(batch, hidden_size)\n",
    "        prediction_scores = self.predictions(sequence_output)         # (batch, seq_length,vocab_size) \n",
    "        seq_relationship_score = self.seq_relationship(pooled_output) # (batch, 2)\n",
    "        return prediction_scores, seq_relationship_score              # (batch, seq_length,vocab_size) ,(batch, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2eec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''预训练模型定义'''\n",
    "class BertForPreTraining(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForPreTraining, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertPreTrainingHeads(config, self.bert.embeddings.word_embeddings.weight)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, masked_lm_labels=None, next_sentence_label=None):\n",
    "        sequence_output, pooled_output = self.bert(input_ids, token_type_ids, attention_mask,output_all_encoded_layers=False)\n",
    "        # 返回encoder最后一层(batch, seq_length, hidden_size),返回CLS的特征(batch, hidden_size)\n",
    "        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)    # (batch, seq_length, vocab_size) ,(batch, 2)\n",
    "        if masked_lm_labels is not None and next_sentence_label is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)                                     # 忽略标签为-1的loss\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1))\n",
    "                                                                                                # 计算Mask的loss的平均值                \n",
    "            next_sentence_loss = loss_fct(seq_relationship_score.view(-1, 2), next_sentence_label.view(-1))\n",
    "                                                                                                # 计算两句话是否连续\n",
    "            total_loss = masked_lm_loss + next_sentence_loss                                    # 俩个loss加起来\n",
    "            return total_loss\n",
    "        else:\n",
    "            return prediction_scores, seq_relationship_score                                    # (batch, seq_length, vocab_size) ,(batch, 2)\n",
    "config = BertConfig()\n",
    "model = BertForPreTraining(config).to(device)\n",
    "learnrate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learnrate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learnrate, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85efad1",
   "metadata": {},
   "source": [
    "定义模型，计算损失：第一部分masked_lm_loss 计算被mask的token，第二部分next_sentence_loss 计算是否两句话是连续，然后加在一起做返回。total_loss = masked_lm_loss + next_sentence_loss 。\n",
    "\n",
    "注意nn.CrossEntropyLoss(ignore_index=-1)是忽略标签为-1的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a31807",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''训练'''\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for input_ids, token_type_ids, attention_mask, masked_lm_labels, next_sentence_label in data_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        masked_lm_labels = masked_lm_labels.to(device)\n",
    "        next_sentence_label = next_sentence_label.to(device)\n",
    "        loss = model(input_ids, token_type_ids, attention_mask, masked_lm_labels, next_sentence_label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4089e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## pytorch微调BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519ef77",
   "metadata": {
    "hidden": true
   },
   "source": [
    "情感分析数据集 链接：https://pan.baidu.com/s/1qT1B5vpRP7z2hNu7gQjMGg\n",
    "提取码：1111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ba8db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''数据预处理'''\n",
    "import pandas\n",
    "from random import *\n",
    "import re\n",
    "f = pandas.read_csv(\"Data.csv\")\n",
    "x = pandas.concat((f.iloc[:, 1:], f.iloc[:, :1]),axis = 1, ignore_index = False)\n",
    "x = list(x.values)\n",
    "shuffle(x)\n",
    "y = []\n",
    "g = []\n",
    "for i in x:\n",
    "    y = re.sub(\"[.,!?\\\\-。，？~！\\\" ]\", \"\", str(i[0]))\n",
    "    y = y + \"\\t\" + str(i[1])\n",
    "    g.append(y)\n",
    "g = pandas.DataFrame(g)\n",
    "train = g[:8000]\n",
    "dev = g[8000:10000]\n",
    "test = g[10000:]\n",
    "train.to_csv(\"train.txt\", header=0, index=0)\n",
    "dev.to_csv(\"dev.txt\", header=0, index=0)\n",
    "test.to_csv(\"test.txt\", header=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3e3bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''头文件'''\n",
    "import math\n",
    "import tqdm\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from random import *\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce223dc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''模型参数（结构相关的参数都不能修改）'''\n",
    "class BertConfig():\n",
    "    def __init__(self):\n",
    "          self.attention_probs_dropout_prob= 0.1           # 注意力处dropout值\n",
    "          self.hidden_act= \"gelu\"                          # 隐藏层使用的激活函数\n",
    "          self.hidden_dropout_prob= 0.1                    # 隐藏层处dropout的值\n",
    "          self.hidden_size= 1024                           # 隐藏层大小，字向量长度\n",
    "          self.initializer_range= 0.02                     # bert模型初始化方差值\n",
    "          self.intermediate_size= 4096                     # 前向传播隐藏层大小\n",
    "          self.max_position_embeddings= 512                # 位置信息长度 512\n",
    "          self.num_attention_heads= 16                     # 注意力头的个数\n",
    "          self.num_hidden_layers= 24                       # encoder 层数\n",
    "          self.type_vocab_size= 2                          # 句子类型，标记第一句话和第二句话\n",
    "          self.vocab_size= 21128                           # 字典大小21128\n",
    "          self.seq_length = 40                             # tokens总长度\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bb67d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''数据加载'''\n",
    "def load_dataset(path, pad_size=32):\n",
    "    contents = []\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    with open(\"./vocab.txt\", 'r', encoding='UTF-8') as f:\n",
    "        idx2word = {idx: line.strip() for idx, line in  enumerate(tqdm.tqdm(f))}\n",
    "        word2idx = {idx2word[key]: key for key in  idx2word}\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        for line in tqdm.tqdm(f):\n",
    "            token_ids = []\n",
    "            lin = line.strip()\n",
    "            if not lin:\n",
    "                continue\n",
    "            content, label = lin.split('\\t')\n",
    "            token_ids.append (word2idx['[CLS]'])\n",
    "            for key in content:\n",
    "                token_ids.append(word2idx.get(key, 0))\n",
    "            seq_len = len(token_ids)\n",
    "            mask = []\n",
    "            if pad_size:\n",
    "                if seq_len < pad_size:\n",
    "                    mask = [1] * len(token_ids) + [0] * (pad_size - seq_len)\n",
    "                    token_ids += ([0] * (pad_size - seq_len))\n",
    "                else:\n",
    "                    mask = [1] * pad_size\n",
    "                    token_ids = token_ids[:pad_size]\n",
    "                    seq_len = pad_size\n",
    "            contents.append((numpy.array(token_ids), int(label), seq_len, numpy.array(mask)))\n",
    "    return contents\n",
    "train = load_dataset(\"./train.txt\")\n",
    "dev = load_dataset(\"./dev.txt\")\n",
    "test = load_dataset(\"./test.txt\")\n",
    "\n",
    "train_input_ids, train_label, seq_len, train_attention_mask = zip(*train)\n",
    "dev_input_ids, dev_label, seq_len, dev_attention_mask = zip(*dev)\n",
    "test_input_ids, test_label, seq_len, test_attention_mask = zip(*test)\n",
    "\n",
    "train_input_ids, train_label, train_attention_mask = torch.tensor(train_input_ids), torch.tensor(train_label), torch.tensor(train_attention_mask)\n",
    "dev_input_ids, dev_label, dev_attention_mask = torch.tensor(dev_input_ids), torch.tensor(dev_label), torch.tensor(dev_attention_mask)\n",
    "test_input_ids, test_label, test_attention_mask = torch.tensor(test_input_ids), torch.tensor(test_label), torch.tensor(test_attention_mask)\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "  def __init__(self, input_ids, label, attention_mask):\n",
    "    self.input_ids = input_ids\n",
    "    self.label = label\n",
    "    self.attention_mask = attention_mask\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.label[idx], self.attention_mask[idx]\n",
    "\n",
    "train_loader = Data.DataLoader(MyDataSet(train_input_ids, train_label, train_attention_mask), batch_size, True)\n",
    "dev_loader = Data.DataLoader(MyDataSet(dev_input_ids, dev_label, dev_attention_mask), batch_size, True)\n",
    "test_loader = Data.DataLoader(MyDataSet(test_input_ids, test_label, test_attention_mask), batch_size, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9fb399",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    train_input_ids：训练数据每个token的字典索引\n",
    "    train_label：记录数据是消极还是积极\n",
    "    seq_len：句子非pad长度\n",
    "    train_attention_mask ：记录句子非pad的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd343c30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''定义激活函数和归一化函数'''\n",
    "def gelu(x):\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "def swish(x):\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n",
    "\n",
    "class BertLayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, eps=1e-12):\n",
    "        super(BertLayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):                                  \n",
    "        u = x.mean(-1, keepdim=True)                          # 最后一个维度上求均值，可以理解在字向量上\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)             # 最后一个维度上求均值，可以理解在字向量上\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb01e0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''BertEmbeddings'''\n",
    "class BertEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEmbeddings, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=0)\n",
    "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None):  # input_ids:(batch, seq_length)    token_type_ids:(batch, seq_length) \n",
    "        seq_length = input_ids.size(1)                                      \n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)   # (seq_length)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)                        # (batch, seq_length)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        words_embeddings = self.word_embeddings(input_ids)                                   # (batch, seq_length, hidden_size)\n",
    "        position_embeddings = self.position_embeddings(position_ids)                         # (batch, seq_length, hidden_size)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)                   # (batch, seq_length, hidden_size)\n",
    "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)                                              # 最后一个维度求归一化\n",
    "        embeddings = self.dropout(embeddings)                                                    \n",
    "        return embeddings      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f0cd8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    Token Embeddings：是数据预处理后语句的字典索引。\n",
    "    Segment Embeddings：标记那些是第一句话，那些是第二句话。\n",
    "    Position Embeddings：标记这个token在这句话处的位置。\n",
    "把它们映射到维度相同高维空间，再加起来，input = Token Embeddings + Segment Embeddings + Position Embeddings，得到Encoder的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483479e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''Encoder的Self-Attention Mechanism'''\n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertSelfAttention, self).__init__()\n",
    "        self.num_attention_heads = config.num_attention_heads                            # num_attention_heads个注意力\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)  # 每一个注意力大小1024/16=64\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size         # all_head_size：16*64=1024\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)                   # (hidden_size，attention_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)                     # (hidden_size，attention_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)                   # (hidden_size，attention_head_size)\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "\n",
    "    def transpose_for_scores(self, x):              # q, k, v 改变形状\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size) \n",
    "                                                                                   #  new_x_shape:元组(batch，seq_len, num_attention_heads,attention_head_size)\n",
    "        x = x.view(*new_x_shape)                                                   # (batch，seq_len, num_attention_heads, attention_head_size)\n",
    "        return x.permute(0, 2, 1, 3)                                               # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):                              # (batch, seq_length, hidden_size)，(batch,1,1,sqe_len)\n",
    "        mixed_query_layer = self.query(hidden_states)                              # (batch, seq_len, hidden_size)\n",
    "        mixed_key_layer = self.key(hidden_states)                                  # (batch, seq_len, hidden_size)\n",
    "        mixed_value_layer = self.value(hidden_states)                              # (batch, seq_len, hidden_size)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)                 # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)                     # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)                 # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))  # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)  # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_scores = attention_scores + attention_mask                       # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)                     # (batch, num_attention_heads, seq_len, seq_len)\n",
    "        attention_probs = self.dropout(attention_probs)                            # (batch, num_attention_heads, seq_len, seq_len)\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)                 # (batch, num_attention_heads, seq_len, attention_head_size)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()             # (batch, seq_len，num_attention_heads, attention_head_size)\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)# (batch, seq_len，hidden_size)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)               # (batch, seq_len，hidden_size)\n",
    "        return context_layer                                                       # (batch, seq_len，hidden_size)\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertSelfOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):                   # (batch, seq_len，hidden_size),(batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dense(hidden_states)                     # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dropout(hidden_states)                   # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)  # (batch, seq_len，hidden_size)\n",
    "        return hidden_states                                          # (batch, seq_len，hidden_size)\n",
    "\n",
    "\n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertAttention, self).__init__()\n",
    "        self.self = BertSelfAttention(config)\n",
    "        self.output = BertSelfOutput(config)\n",
    "\n",
    "    def forward(self, input_tensor, attention_mask):  # hidden_states:(batch, seq_length, hidden_size)，attention_mask:(batch,1,1,sqe_len)\n",
    "        self_output = self.self(input_tensor, attention_mask)         # (batch, seq_len，hidden_size)\n",
    "        attention_output = self.output(self_output, input_tensor)     # (batch, seq_len，hidden_size)\n",
    "        return attention_output                                       # (batch, seq_len，hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189c4f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "可以理解成：先计算出第一个token与句子中的每一个token的注意力分数（包括第一个token），再用计算出的注意力分数乘以对应token的信息，然后加在一起，得到的结果就是第一个token与句子中所有token的加权和信息，依次更新每一个token与句子的注意力信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4e79f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''Encoder的Add & Layer normalization : 利用了残差网络可能增加网络深度性，归一化可以加快网络收敛'''\n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertIntermediate, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states):                               # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dense(hidden_states)                   # (batch, seq_len，intermediate_size)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)     # (batch, seq_len，intermediate_size)\n",
    "        return hidden_states\n",
    "\n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertOutput, self).__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states, input_tensor):                 # (batch, seq_len，intermediate_size)\n",
    "        hidden_states = self.dense(hidden_states)                   # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.dropout(hidden_states)                 # (batch, seq_len，hidden_size)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)# (batch, seq_len，hidden_size)\n",
    "        return hidden_states                                        # (batch, seq_len，hidden_size)\n",
    "\n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertLayer, self).__init__()\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask):  # hidden_states:(batch, seq_length, hidden_size)，attention_mask:(batch,1,1,sqe_len)\n",
    "        attention_output = self.attention(hidden_states, attention_mask)      # (batch, seq_len，hidden_size)\n",
    "        intermediate_output = self.intermediate(attention_output)             # (batch, seq_len，intermediate_size)\n",
    "        layer_output = self.output(intermediate_output, attention_output)     # (batch, seq_len，hidden_size)\n",
    "        return layer_output                                                   # (batch, seq_len，hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810698e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''Encoder'''\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__()\n",
    "        layer = BertLayer(config)\n",
    "        self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):  # hidden_states:(batch, seq_length, hidden_size)，attention_mask:(batch,1,1,sqe_len)      \n",
    "        all_encoder_layers = []\n",
    "        for layer_module in self.layer:\n",
    "            hidden_states = layer_module(hidden_states, attention_mask)        # (batch, seq_len，hidden_size)\n",
    "            if output_all_encoded_layers:                                      # 输出每一层的内容\n",
    "                all_encoder_layers.append(hidden_states)\n",
    "        if not output_all_encoded_layers:                                      # 输出最后一层的内容                  \n",
    "            all_encoder_layers.append(hidden_states)                           # (batch, seq_len，hidden_size)\n",
    "        return all_encoder_layers                                              # (batch, seq_len，hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd5078",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''BertPooler（处理CLS信息）: 获取Encoder最后已层输出的第一个token，也就是\"CLS\"的编码后的特征信息'''\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):                          # (batch, seq_length, hidden_size)\n",
    "        first_token_tensor = hidden_states[:, 0]               # 每个句子的第一个token (batch, hidden_size)\n",
    "        pooled_output = self.dense(first_token_tensor)         # (batch, hidden_size)\n",
    "        pooled_output = self.activation(pooled_output)         # (batch, hidden_size)\n",
    "        return pooled_output                                   # (batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678ca7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''预训练模型加载，保存'''\n",
    "class BertPreTrainedModel(nn.Module):\n",
    "    #处理权重和下载、加载模型\n",
    "    def __init__(self, config, *inputs, **kwargs):\n",
    "        super(BertPreTrainedModel, self).__init__()\n",
    "        if not isinstance(config, BertConfig):\n",
    "            raise ValueError(\n",
    "                \"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"\n",
    "                \"To create a model from a Google pretrained model use \"\n",
    "                \"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(\n",
    "                    self.__class__.__name__, self.__class__.__name__\n",
    "                ))\n",
    "        self.config = config\n",
    "\n",
    "    def init_bert_weights(self, module):\n",
    "        # 初始化权重\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        elif isinstance(module, BertLayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n",
    "       # 预先训练的模型下载并缓存预先训练的模型文件。\n",
    "        state_dict = kwargs.get('state_dict', None)\n",
    "        kwargs.pop('state_dict', None)\n",
    "        cache_dir = kwargs.get('cache_dir', None)\n",
    "        kwargs.pop('cache_dir', None)\n",
    "        from_tf = kwargs.get('from_tf', False)\n",
    "        kwargs.pop('from_tf', None)\n",
    "\n",
    "        if pretrained_model_name_or_path in PRETRAINED_MODEL_ARCHIVE_MAP:\n",
    "            archive_file = PRETRAINED_MODEL_ARCHIVE_MAP[pretrained_model_name_or_path]\n",
    "        else:\n",
    "            archive_file = pretrained_model_name_or_path\n",
    "        try:\n",
    "            resolved_archive_file = cached_path(archive_file, cache_dir=cache_dir)\n",
    "        except EnvironmentError:\n",
    "            logger.error(\n",
    "                \"Model name '{}' was not found in model name list ({}). \"\n",
    "                \"We assumed '{}' was a path or url but couldn't find any file \"\n",
    "                \"associated to this path or url.\".format(\n",
    "                    pretrained_model_name_or_path,\n",
    "                    ', '.join(PRETRAINED_MODEL_ARCHIVE_MAP.keys()),archive_file))\n",
    "            return None\n",
    "        if resolved_archive_file == archive_file:\n",
    "            logger.info(\"loading archive file {}\".format(archive_file))\n",
    "        else:\n",
    "            logger.info(\"loading archive file {} from cache at {}\".format(archive_file, resolved_archive_file))\n",
    "        tempdir = None\n",
    "        if os.path.isdir(resolved_archive_file) or from_tf:\n",
    "            serialization_dir = resolved_archive_file\n",
    "        else:\n",
    "            tempdir = tempfile.mkdtemp()\n",
    "            logger.info(\"extracting archive file {} to temp dir {}\".format(resolved_archive_file, tempdir))\n",
    "            with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
    "                archive.extractall(tempdir)\n",
    "            serialization_dir = tempdir\n",
    "        config_file = os.path.join(serialization_dir, CONFIG_NAME)   # 加载 config文件\n",
    "        if not os.path.exists(config_file):\n",
    "            config_file = os.path.join(serialization_dir, BERT_CONFIG_NAME)\n",
    "        config = BertConfig.from_json_file(config_file)\n",
    "        logger.info(\"Model config {}\".format(config))\n",
    "        model = cls(config, *inputs, **kwargs)\n",
    "        if state_dict is None and not from_tf:\n",
    "            weights_path = os.path.join(serialization_dir, WEIGHTS_NAME)\n",
    "            state_dict = torch.load(weights_path, map_location='cpu')\n",
    "        if tempdir:\n",
    "            # Clean up temp dir\n",
    "            shutil.rmtree(tempdir)\n",
    "        if from_tf:\n",
    "            weights_path = os.path.join(serialization_dir, TF_WEIGHTS_NAME)\n",
    "            return load_tf_weights_in_bert(model, weights_path)\n",
    "        old_keys = []\n",
    "        new_keys = []\n",
    "        for key in state_dict.keys():\n",
    "            new_key = None\n",
    "            if 'gamma' in key:\n",
    "                new_key = key.replace('gamma', 'weight')\n",
    "            if 'beta' in key:\n",
    "                new_key = key.replace('beta', 'bias')\n",
    "            if new_key:\n",
    "                old_keys.append(key)\n",
    "                new_keys.append(new_key)\n",
    "        for old_key, new_key in zip(old_keys, new_keys):\n",
    "            state_dict[new_key] = state_dict.pop(old_key)\n",
    "\n",
    "        missing_keys = []\n",
    "        unexpected_keys = []\n",
    "        error_msgs = []\n",
    "        metadata = getattr(state_dict, '_metadata', None)\n",
    "        state_dict = state_dict.copy()\n",
    "        if metadata is not None:\n",
    "            state_dict._metadata = metadata\n",
    "\n",
    "        def load(module, prefix=''):\n",
    "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
    "            module._load_from_state_dict(\n",
    "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "            for name, child in module._modules.items():\n",
    "                if child is not None:\n",
    "                    load(child, prefix + name + '.')\n",
    "        start_prefix = ''\n",
    "        if not hasattr(model, 'bert') and any(s.startswith('bert.') for s in state_dict.keys()):\n",
    "            start_prefix = 'bert.'\n",
    "        load(model, prefix=start_prefix)\n",
    "        if len(missing_keys) > 0:\n",
    "            logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(model.__class__.__name__, missing_keys))\n",
    "        if len(unexpected_keys) > 0:\n",
    "            logger.info(\"Weights from pretrained model not used in {}: {}\".format(model.__class__.__name__, unexpected_keys))\n",
    "        if len(error_msgs) > 0:\n",
    "            raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(model.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba7a6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''BertModel'''\n",
    "class BertModel(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertModel, self).__init__(config)\n",
    "        self.embeddings = BertEmbeddings(config)\n",
    "        self.encoder = BertEncoder(config)\n",
    "        self.pooler = BertPooler(config)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
    "        if attention_mask is None:\n",
    "            attention_mask = torch.ones_like(input_ids)\n",
    "        if token_type_ids is None:\n",
    "            token_type_ids = torch.zeros_like(input_ids)\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)                        # (batch,1,1,sqe_len)\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # (batch,1,1,sqe_len)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0                      # 只计算被标记的位置(batch,1,1,sqe_len)\n",
    "        embedding_output = self.embeddings(input_ids, token_type_ids)                             # (batch, seq_length, hidden_size)\n",
    "        encoded_layers = self.encoder(embedding_output,                                           # (batch, seq_length, hidden_size)\n",
    "                                      extended_attention_mask,\n",
    "                                      output_all_encoded_layers=output_all_encoded_layers)\n",
    "        sequence_output = encoded_layers[-1]                                                      # 取出encoder最后一层输出(batch, seq_length, hidden_size)           \n",
    "        pooled_output = self.pooler(sequence_output)                                              # 返回CLS的特征(batch, hidden_size)\n",
    "        if not output_all_encoded_layers:\n",
    "            encoded_layers = encoded_layers[-1]\n",
    "        return encoded_layers, pooled_output            #  返回最后一层的数据：(batch, seq_length, hidden_size),返回CLS的特征(batch, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d703d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''预训练BertPreTrainingHeads（可以理解成bert接的下游任务）'''\n",
    "class BertPredictionHeadTransform(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPredictionHeadTransform, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        if isinstance(config.hidden_act, str) or (sys.version_info[0] == 2 and isinstance(config.hidden_act, unicode)):\n",
    "            self.transform_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.transform_act_fn = config.hidden_act\n",
    "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
    "\n",
    "    def forward(self, hidden_states):                                     # bert输出(batch, seq_length, hidden_size)\n",
    "        hidden_states = self.dense(hidden_states)                         # bert输出(batch, seq_length, hidden_size)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)              # 激活函数\n",
    "        hidden_states = self.LayerNorm(hidden_states)                     # 归一化\n",
    "        return hidden_states                                              # (batch, seq_length, hidden_size)\n",
    "\n",
    "class BertLMPredictionHead(nn.Module):\n",
    "    def __init__(self, config, bert_model_embedding_weights):\n",
    "        super(BertLMPredictionHead, self).__init__()\n",
    "        self.transform = BertPredictionHeadTransform(config)\n",
    "        self.decoder = nn.Linear(bert_model_embedding_weights.size(1),\n",
    "                                 bert_model_embedding_weights.size(0),\n",
    "                                 bias=False)\n",
    "        self.decoder.weight = bert_model_embedding_weights\n",
    "        self.bias = nn.Parameter(torch.zeros(bert_model_embedding_weights.size(0)))\n",
    "\n",
    "    def forward(self, hidden_states):                                      # bert输出(batch, seq_length, hidden_size)\n",
    "        hidden_states = self.transform(hidden_states)                      # (batch, seq_length, hidden_size)\n",
    "        hidden_states = self.decoder(hidden_states) + self.bias            # (batch, seq_length,vocab_size)   \n",
    "        return hidden_states                                               # (batch, seq_length,vocab_size) \n",
    "\n",
    "class BertPreTrainingHeads(nn.Module):\n",
    "    def __init__(self, config, bert_model_embedding_weights):\n",
    "        super(BertPreTrainingHeads, self).__init__()\n",
    "        self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
    "        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, sequence_output, pooled_output):                # bert输出(batch, seq_length, hidden_size),CLS的特征(batch, hidden_size)\n",
    "        prediction_scores = self.predictions(sequence_output)         # (batch, seq_length,vocab_size) \n",
    "        seq_relationship_score = self.seq_relationship(pooled_output) # (batch, 2)\n",
    "        return prediction_scores, seq_relationship_score              # (batch, seq_length,vocab_size) ,(batch, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dce7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''定义模型和加载模型'''\n",
    "class BertForPreTraining(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertForPreTraining, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.cls = BertPreTrainingHeads(config, self.bert.embeddings.word_embeddings.weight)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, masked_lm_labels=None, next_sentence_label=None):\n",
    "        sequence_output, pooled_output = self.bert(input_ids, token_type_ids, attention_mask,output_all_encoded_layers=False)\n",
    "        # 返回encoder最后一层(batch, seq_length, hidden_size),返回CLS的特征(batch, hidden_size)\n",
    "        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)    # (batch, seq_length, vocab_size) ,(batch, 2)\n",
    "        if masked_lm_labels is not None and next_sentence_label is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=-1)                                     # 忽略标签为-1的loss\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1))\n",
    "                                                                                                # 计算Mask的loss的平均值                \n",
    "            next_sentence_loss = loss_fct(seq_relationship_score.view(-1, 2), next_sentence_label.view(-1))\n",
    "                                                                                                # 计算两句话是否连续\n",
    "            total_loss = masked_lm_loss + next_sentence_loss                                    # 俩个loss加起来\n",
    "            return total_loss\n",
    "        else:\n",
    "            return prediction_scores, seq_relationship_score                                    # (batch, seq_length, vocab_size) ,(batch, 2)\n",
    "config = BertConfig()\n",
    "model = BertForPreTraining(config).to(device)\n",
    "learnrate = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learnrate)\n",
    "loss_fct = nn.CrossEntropyLoss() \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learnrate, momentum=0.99)\n",
    "model.load_state_dict(torch.load('pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3da130",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''模型训练'''\n",
    "epochs = 2\n",
    "train_l = []\n",
    "dev_l = []\n",
    "train_accuracy =[]\n",
    "dev_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    l = 0\n",
    "    accuracy =0\n",
    "    for input_ids, label, attention_mask in train_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        label = label.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        _, score_label = model(input_ids, attention_mask=attention_mask, next_sentence_label=label)\n",
    "        accuracy += torch.sum(score_label.argmax(dim = 1).view(-1) == label.view(-1)).item()\n",
    "        loss = loss_fct(score_label, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        l += loss.item()\n",
    "    train_l.append(l/len(train_input_ids))\n",
    "    train_accuracy.append(accuracy/len(train_input_ids))\n",
    "    print('Epoch Train:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(l/len(train_input_ids)),'acc =', '{:.6f}'.format(accuracy/len(train_input_ids)))\n",
    "    l = 0\n",
    "    accuracy = 0\n",
    "    for input_ids, label, attention_mask in dev_loader:\n",
    "        with torch.no_grad():\n",
    "            input_ids = input_ids.to(device)\n",
    "            label = label.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            _, score_label = model(input_ids, attention_mask=attention_mask, next_sentence_label=label)\n",
    "            accuracy += torch.sum(score_label.argmax(dim = 1).view(-1) == label.view(-1)).item()\n",
    "            loss = loss_fct(score_label, label)\n",
    "            l += loss.item()\n",
    "    dev_l.append(l/len(dev_input_ids))  \n",
    "    dev_accuracy.append(accuracy/len(dev_input_ids))  \n",
    "    print('Epoch  dev :', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(l/len(dev_input_ids)),'acc =', '{:.6f}'.format(accuracy/len(dev_input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed74bde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''模型测试'''\n",
    "accuracy = 0\n",
    "ls = 0\n",
    "accuracy =0\n",
    "for input_ids, label, attention_mask in dev_loader:\n",
    "    with torch.no_grad():\n",
    "        input_ids = input_ids.to(device)\n",
    "        label = label.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        _, score_label = model(input_ids, attention_mask=attention_mask, next_sentence_label=label)\n",
    "        accuracy += torch.sum(score_label.argmax(dim = 1).view(-1) == label.view(-1)).item()\n",
    "        loss = loss_fct(score_label, label)\n",
    "        l += loss.item()\n",
    "print('loss =', '{:.6f}'.format(l/len(dev_input_ids)),'  acc =', '{:.6f}'.format(accuracy/len(test_input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317bbd2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5420c95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Deep]",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
